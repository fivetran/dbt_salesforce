{"nodes": {"model.salesforce.salesforce_sales_snapshot": {"raw_sql": "with salesforce_opportunity_enhanced as (\n    \n    select *\n    from {{ ref('salesforce_opportunity_enhanced') }}\n\n), pipeline as (\n\n  select \n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n\n), bookings as (\n\n  select \n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n\n), lost as (\n\n  select \n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n\n)\n\nselect \n  bookings.*,\n  pipeline.*,\n  lost.*,\n  round((bookings.bookings_amount_closed_this_month / (bookings.bookings_amount_closed_this_month + lost.lost_amount_this_month)) * 100, 2 ) as win_percent_this_month,\n  round((bookings.bookings_amount_closed_this_quarter / (bookings.bookings_amount_closed_this_quarter + lost.lost_amount_this_quarter)) * 100, 2 ) as win_percent_this_quarter,\n  round((bookings.total_bookings_amount / (bookings.total_bookings_amount + lost.total_lost_amount)) * 100, 2) as win_percent_all_time\nfrom bookings, pipeline, lost", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "salesforce_sales_snapshot"], "unique_id": "model.salesforce.salesforce_sales_snapshot", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "salesforce_sales_snapshot.sql", "original_file_path": "models/salesforce_sales_snapshot.sql", "name": "salesforce_sales_snapshot", "resource_type": "model", "alias": "salesforce_sales_snapshot", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [["salesforce_opportunity_enhanced"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.salesforce.salesforce_opportunity_enhanced"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/salesforce_sales_snapshot.sql", "compiled": true, "compiled_sql": "with salesforce_opportunity_enhanced as (\n    \n    select *\n    from `digital-arbor-400`.`dbt_kristin_test`.`salesforce_opportunity_enhanced`\n\n), pipeline as (\n\n  select \n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n\n), bookings as (\n\n  select \n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n\n), lost as (\n\n  select \n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n\n)\n\nselect \n  bookings.*,\n  pipeline.*,\n  lost.*,\n  round((bookings.bookings_amount_closed_this_month / (bookings.bookings_amount_closed_this_month + lost.lost_amount_this_month)) * 100, 2 ) as win_percent_this_month,\n  round((bookings.bookings_amount_closed_this_quarter / (bookings.bookings_amount_closed_this_quarter + lost.lost_amount_this_quarter)) * 100, 2 ) as win_percent_this_quarter,\n  round((bookings.total_bookings_amount / (bookings.total_bookings_amount + lost.total_lost_amount)) * 100, 2) as win_percent_all_time\nfrom bookings, pipeline, lost", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "with salesforce_opportunity_enhanced as (\n    \n    select *\n    from `digital-arbor-400`.`dbt_kristin_test`.`salesforce_opportunity_enhanced`\n\n), pipeline as (\n\n  select \n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n\n), bookings as (\n\n  select \n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n\n), lost as (\n\n  select \n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n\n)\n\nselect \n  bookings.*,\n  pipeline.*,\n  lost.*,\n  round((bookings.bookings_amount_closed_this_month / (bookings.bookings_amount_closed_this_month + lost.lost_amount_this_month)) * 100, 2 ) as win_percent_this_month,\n  round((bookings.bookings_amount_closed_this_quarter / (bookings.bookings_amount_closed_this_quarter + lost.lost_amount_this_quarter)) * 100, 2 ) as win_percent_this_quarter,\n  round((bookings.total_bookings_amount / (bookings.total_bookings_amount + lost.total_lost_amount)) * 100, 2) as win_percent_all_time\nfrom bookings, pipeline, lost", "wrapped_sql": null}, "model.salesforce.salesforce_owner_performance": {"raw_sql": "with opportunity_aggregation_by_owner as (\n    \n    select *\n    from {{ ref('opportunity_aggregation_by_owner') }}\n  \n), user as (\n\n    select *\n    from {{ ref('stg_salesforce_user') }}\n  \n)\n\nselect \n  opportunity_aggregation_by_owner.*,\n\tuser.name as owner_name,\n  user.city as owner_city,\n  user.state as owner_state,\n  case when (bookings_amount_closed_this_month + lost_amount_this_month) > 0 then\n        bookings_amount_closed_this_month / \n          (bookings_amount_closed_this_month + lost_amount_this_month) * 100\n          else 0 end as win_percent_this_month,\n  case when (bookings_amount_closed_this_quarter + lost_amount_this_quarter) > 0 then\n        bookings_amount_closed_this_quarter / \n          (bookings_amount_closed_this_quarter + lost_amount_this_quarter) * 100\n          else 0 end as win_percent_this_quarter,\n  case when (total_bookings_amount + total_lost_amount) > 0 then \n        total_bookings_amount / (total_bookings_amount + total_lost_amount) * 100\n        else 0 end as total_win_percent\n\nfrom opportunity_aggregation_by_owner\njoin user on user.user_id = opportunity_aggregation_by_owner.owner_id", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "salesforce_owner_performance"], "unique_id": "model.salesforce.salesforce_owner_performance", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "salesforce_owner_performance.sql", "original_file_path": "models/salesforce_owner_performance.sql", "name": "salesforce_owner_performance", "resource_type": "model", "alias": "salesforce_owner_performance", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [["opportunity_aggregation_by_owner"], ["stg_salesforce_user"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.salesforce.opportunity_aggregation_by_owner", "model.salesforce.stg_salesforce_user"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/salesforce_owner_performance.sql", "compiled": true, "compiled_sql": "with opportunity_aggregation_by_owner as (\n    \n    select *\n    from __dbt__CTE__opportunity_aggregation_by_owner\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n)\n\nselect \n  opportunity_aggregation_by_owner.*,\n\tuser.name as owner_name,\n  user.city as owner_city,\n  user.state as owner_state,\n  case when (bookings_amount_closed_this_month + lost_amount_this_month) > 0 then\n        bookings_amount_closed_this_month / \n          (bookings_amount_closed_this_month + lost_amount_this_month) * 100\n          else 0 end as win_percent_this_month,\n  case when (bookings_amount_closed_this_quarter + lost_amount_this_quarter) > 0 then\n        bookings_amount_closed_this_quarter / \n          (bookings_amount_closed_this_quarter + lost_amount_this_quarter) * 100\n          else 0 end as win_percent_this_quarter,\n  case when (total_bookings_amount + total_lost_amount) > 0 then \n        total_bookings_amount / (total_bookings_amount + total_lost_amount) * 100\n        else 0 end as total_win_percent\n\nfrom opportunity_aggregation_by_owner\njoin user on user.user_id = opportunity_aggregation_by_owner.owner_id", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_user", "sql": " __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)"}, {"id": "model.salesforce.opportunity_aggregation_by_owner", "sql": " __dbt__CTE__opportunity_aggregation_by_owner as (\nwith salesforce_opportunity_enhanced as (\n    \n    select *\n    from `digital-arbor-400`.`dbt_kristin_test`.`salesforce_opportunity_enhanced`\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), booking_by_owner as (\n\n  select \n    opportunity_manager_id as b_manager_id,\n    opportunity_owner_id as b_owner_id,\n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n  group by 1, 2\n\n), lost_by_owner as (\n\n  select \n    opportunity_manager_id as l_manager_id,\n    opportunity_owner_id as l_owner_id,\n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n  group by 1, 2\n\n), pipeline_by_owner as (\n\n  select \n    opportunity_manager_id as p_manager_id,\n    opportunity_owner_id as p_owner_id,\n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n  group by 1, 2\n)\n\nselect \n  user.user_id as owner_id,\n  coalesce(p_manager_id, b_manager_id, l_manager_id) as manager_id,\n  booking_by_owner.*,\n  lost_by_owner.*,\n  pipeline_by_owner.*\nfrom user \nleft join booking_by_owner on booking_by_owner.b_owner_id = user.user_id\nleft join lost_by_owner on lost_by_owner.l_owner_id = user.user_id\nleft join pipeline_by_owner on pipeline_by_owner.p_owner_id = user.user_id\n)"}], "injected_sql": "with  __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n),  __dbt__CTE__opportunity_aggregation_by_owner as (\nwith salesforce_opportunity_enhanced as (\n    \n    select *\n    from `digital-arbor-400`.`dbt_kristin_test`.`salesforce_opportunity_enhanced`\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), booking_by_owner as (\n\n  select \n    opportunity_manager_id as b_manager_id,\n    opportunity_owner_id as b_owner_id,\n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n  group by 1, 2\n\n), lost_by_owner as (\n\n  select \n    opportunity_manager_id as l_manager_id,\n    opportunity_owner_id as l_owner_id,\n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n  group by 1, 2\n\n), pipeline_by_owner as (\n\n  select \n    opportunity_manager_id as p_manager_id,\n    opportunity_owner_id as p_owner_id,\n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n  group by 1, 2\n)\n\nselect \n  user.user_id as owner_id,\n  coalesce(p_manager_id, b_manager_id, l_manager_id) as manager_id,\n  booking_by_owner.*,\n  lost_by_owner.*,\n  pipeline_by_owner.*\nfrom user \nleft join booking_by_owner on booking_by_owner.b_owner_id = user.user_id\nleft join lost_by_owner on lost_by_owner.l_owner_id = user.user_id\nleft join pipeline_by_owner on pipeline_by_owner.p_owner_id = user.user_id\n),opportunity_aggregation_by_owner as (\n    \n    select *\n    from __dbt__CTE__opportunity_aggregation_by_owner\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n)\n\nselect \n  opportunity_aggregation_by_owner.*,\n\tuser.name as owner_name,\n  user.city as owner_city,\n  user.state as owner_state,\n  case when (bookings_amount_closed_this_month + lost_amount_this_month) > 0 then\n        bookings_amount_closed_this_month / \n          (bookings_amount_closed_this_month + lost_amount_this_month) * 100\n          else 0 end as win_percent_this_month,\n  case when (bookings_amount_closed_this_quarter + lost_amount_this_quarter) > 0 then\n        bookings_amount_closed_this_quarter / \n          (bookings_amount_closed_this_quarter + lost_amount_this_quarter) * 100\n          else 0 end as win_percent_this_quarter,\n  case when (total_bookings_amount + total_lost_amount) > 0 then \n        total_bookings_amount / (total_bookings_amount + total_lost_amount) * 100\n        else 0 end as total_win_percent\n\nfrom opportunity_aggregation_by_owner\njoin user on user.user_id = opportunity_aggregation_by_owner.owner_id", "wrapped_sql": null}, "model.salesforce.salesforce_manager_performance": {"raw_sql": "with opportunity_aggregation_by_owner as (\n    \n    select *\n    from {{ ref('opportunity_aggregation_by_owner') }}\n  \n), user as (\n\n    select *\n    from {{ ref('stg_salesforce_user') }}\n  \n), user_role as (\n\n    select *\n    from {{ ref('stg_salesforce_user_role') }}\n  \n)\n\nselect \n\n  coalesce(manager.name, 'No Manager Assigned') as manager_name,\n  manager.city as manager_city,\n  manager.state as manager_state,\n  user_role.role_name as manager_position,\n  count(distinct owner_id) as number_of_direct_reports,\n  coalesce(sum(bookings_amount_closed_this_month), 0) as bookings_amount_closed_this_month,\n  coalesce(sum(bookings_amount_closed_this_quarter), 0) as bookings_amount_closed_this_quarter,\n  coalesce(sum(total_number_bookings), 0) as total_number_bookings,\n  coalesce(sum(total_bookings_amount), 0) as total_bookings_amount,\n  coalesce(sum(bookings_count_closed_this_month), 0) as bookings_count_closed_this_month,\n  coalesce(sum(bookings_count_closed_this_quarter), 0) as bookings_count_closed_this_quarter,\n  coalesce(max(largest_booking), 0) as largest_booking,\n  coalesce(sum(lost_amount_this_month), 0) as lost_amount_this_month,\n  coalesce(sum(lost_amount_this_quarter), 0) as lost_amount_this_quarter,\n  coalesce(sum(total_number_lost), 0) as total_number_lost,\n  coalesce(sum(total_lost_amount), 0) as total_lost_amount,\n  coalesce(sum(lost_count_this_month), 0) as lost_count_this_month,\n  coalesce(sum(lost_count_this_quarter), 0) as lost_count_this_quarter,\n  coalesce(sum(pipeline_created_amount_this_month), 0) as pipeline_created_amount_this_month,\n  coalesce(sum(pipeline_created_amount_this_quarter), 0) as pipeline_created_amount_this_quarter,\n  coalesce(sum(pipeline_created_forecast_amount_this_month), 0) as pipeline_created_forecast_amount_this_month,\n  coalesce(sum(pipeline_created_forecast_amount_this_quarter), 0) as pipeline_created_forecast_amount_this_quarter,\n  coalesce(sum(pipeline_count_created_this_month), 0) as pipeline_count_created_this_month,\n  coalesce(sum(pipeline_count_created_this_quarter), 0) as pipeline_count_created_this_quarter,\n  coalesce(sum(total_number_pipeline), 0) as total_number_pipeline,\n  coalesce(sum(total_pipeline_amount), 0) as total_pipeline_amount,\n  coalesce(sum(total_pipeline_forecast_amount), 0) as total_pipeline_forecast_amount,\n  coalesce(max(largest_deal_in_pipeline), 0) as largest_deal_in_pipeline,\n  round(case when sum(bookings_amount_closed_this_month + lost_amount_this_month) > 0 then \n            sum(bookings_amount_closed_this_month) / sum(bookings_amount_closed_this_month + lost_amount_this_month) * 100\n            else 0 end, 2) as win_percent_this_month,\n  round(case when sum(bookings_amount_closed_this_quarter + lost_amount_this_quarter) > 0 then\n            sum(bookings_amount_closed_this_quarter) / sum(bookings_amount_closed_this_quarter + lost_amount_this_quarter) * 100\n            else 0 end, 2) as win_percent_this_quarter,\n  round(case when sum(total_bookings_amount + total_lost_amount) > 0 then \n            sum(total_bookings_amount) / sum(total_bookings_amount + total_lost_amount) * 100\n            else 0 end, 2) as total_win_percent\n\nfrom opportunity_aggregation_by_owner\nleft join user as manager on manager.user_id = opportunity_aggregation_by_owner.manager_id\nleft join user_role on user_role.user_role_id = manager.user_role_id\ngroup by 1, 2, 3, 4\nhaving number_of_direct_reports > 0", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "salesforce_manager_performance"], "unique_id": "model.salesforce.salesforce_manager_performance", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "salesforce_manager_performance.sql", "original_file_path": "models/salesforce_manager_performance.sql", "name": "salesforce_manager_performance", "resource_type": "model", "alias": "salesforce_manager_performance", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [["opportunity_aggregation_by_owner"], ["stg_salesforce_user"], ["stg_salesforce_user_role"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.salesforce.opportunity_aggregation_by_owner", "model.salesforce.stg_salesforce_user", "model.salesforce.stg_salesforce_user_role"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/salesforce_manager_performance.sql", "compiled": true, "compiled_sql": "with opportunity_aggregation_by_owner as (\n    \n    select *\n    from __dbt__CTE__opportunity_aggregation_by_owner\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), user_role as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user_role\n  \n)\n\nselect \n\n  coalesce(manager.name, 'No Manager Assigned') as manager_name,\n  manager.city as manager_city,\n  manager.state as manager_state,\n  user_role.role_name as manager_position,\n  count(distinct owner_id) as number_of_direct_reports,\n  coalesce(sum(bookings_amount_closed_this_month), 0) as bookings_amount_closed_this_month,\n  coalesce(sum(bookings_amount_closed_this_quarter), 0) as bookings_amount_closed_this_quarter,\n  coalesce(sum(total_number_bookings), 0) as total_number_bookings,\n  coalesce(sum(total_bookings_amount), 0) as total_bookings_amount,\n  coalesce(sum(bookings_count_closed_this_month), 0) as bookings_count_closed_this_month,\n  coalesce(sum(bookings_count_closed_this_quarter), 0) as bookings_count_closed_this_quarter,\n  coalesce(max(largest_booking), 0) as largest_booking,\n  coalesce(sum(lost_amount_this_month), 0) as lost_amount_this_month,\n  coalesce(sum(lost_amount_this_quarter), 0) as lost_amount_this_quarter,\n  coalesce(sum(total_number_lost), 0) as total_number_lost,\n  coalesce(sum(total_lost_amount), 0) as total_lost_amount,\n  coalesce(sum(lost_count_this_month), 0) as lost_count_this_month,\n  coalesce(sum(lost_count_this_quarter), 0) as lost_count_this_quarter,\n  coalesce(sum(pipeline_created_amount_this_month), 0) as pipeline_created_amount_this_month,\n  coalesce(sum(pipeline_created_amount_this_quarter), 0) as pipeline_created_amount_this_quarter,\n  coalesce(sum(pipeline_created_forecast_amount_this_month), 0) as pipeline_created_forecast_amount_this_month,\n  coalesce(sum(pipeline_created_forecast_amount_this_quarter), 0) as pipeline_created_forecast_amount_this_quarter,\n  coalesce(sum(pipeline_count_created_this_month), 0) as pipeline_count_created_this_month,\n  coalesce(sum(pipeline_count_created_this_quarter), 0) as pipeline_count_created_this_quarter,\n  coalesce(sum(total_number_pipeline), 0) as total_number_pipeline,\n  coalesce(sum(total_pipeline_amount), 0) as total_pipeline_amount,\n  coalesce(sum(total_pipeline_forecast_amount), 0) as total_pipeline_forecast_amount,\n  coalesce(max(largest_deal_in_pipeline), 0) as largest_deal_in_pipeline,\n  round(case when sum(bookings_amount_closed_this_month + lost_amount_this_month) > 0 then \n            sum(bookings_amount_closed_this_month) / sum(bookings_amount_closed_this_month + lost_amount_this_month) * 100\n            else 0 end, 2) as win_percent_this_month,\n  round(case when sum(bookings_amount_closed_this_quarter + lost_amount_this_quarter) > 0 then\n            sum(bookings_amount_closed_this_quarter) / sum(bookings_amount_closed_this_quarter + lost_amount_this_quarter) * 100\n            else 0 end, 2) as win_percent_this_quarter,\n  round(case when sum(total_bookings_amount + total_lost_amount) > 0 then \n            sum(total_bookings_amount) / sum(total_bookings_amount + total_lost_amount) * 100\n            else 0 end, 2) as total_win_percent\n\nfrom opportunity_aggregation_by_owner\nleft join user as manager on manager.user_id = opportunity_aggregation_by_owner.manager_id\nleft join user_role on user_role.user_role_id = manager.user_role_id\ngroup by 1, 2, 3, 4\nhaving number_of_direct_reports > 0", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_user", "sql": " __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)"}, {"id": "model.salesforce.opportunity_aggregation_by_owner", "sql": " __dbt__CTE__opportunity_aggregation_by_owner as (\nwith salesforce_opportunity_enhanced as (\n    \n    select *\n    from `digital-arbor-400`.`dbt_kristin_test`.`salesforce_opportunity_enhanced`\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), booking_by_owner as (\n\n  select \n    opportunity_manager_id as b_manager_id,\n    opportunity_owner_id as b_owner_id,\n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n  group by 1, 2\n\n), lost_by_owner as (\n\n  select \n    opportunity_manager_id as l_manager_id,\n    opportunity_owner_id as l_owner_id,\n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n  group by 1, 2\n\n), pipeline_by_owner as (\n\n  select \n    opportunity_manager_id as p_manager_id,\n    opportunity_owner_id as p_owner_id,\n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n  group by 1, 2\n)\n\nselect \n  user.user_id as owner_id,\n  coalesce(p_manager_id, b_manager_id, l_manager_id) as manager_id,\n  booking_by_owner.*,\n  lost_by_owner.*,\n  pipeline_by_owner.*\nfrom user \nleft join booking_by_owner on booking_by_owner.b_owner_id = user.user_id\nleft join lost_by_owner on lost_by_owner.l_owner_id = user.user_id\nleft join pipeline_by_owner on pipeline_by_owner.p_owner_id = user.user_id\n)"}, {"id": "model.salesforce.stg_salesforce_user_role", "sql": " __dbt__CTE__stg_salesforce_user_role as (\nwith base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "with  __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n),  __dbt__CTE__opportunity_aggregation_by_owner as (\nwith salesforce_opportunity_enhanced as (\n    \n    select *\n    from `digital-arbor-400`.`dbt_kristin_test`.`salesforce_opportunity_enhanced`\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), booking_by_owner as (\n\n  select \n    opportunity_manager_id as b_manager_id,\n    opportunity_owner_id as b_owner_id,\n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n  group by 1, 2\n\n), lost_by_owner as (\n\n  select \n    opportunity_manager_id as l_manager_id,\n    opportunity_owner_id as l_owner_id,\n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n  group by 1, 2\n\n), pipeline_by_owner as (\n\n  select \n    opportunity_manager_id as p_manager_id,\n    opportunity_owner_id as p_owner_id,\n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n  group by 1, 2\n)\n\nselect \n  user.user_id as owner_id,\n  coalesce(p_manager_id, b_manager_id, l_manager_id) as manager_id,\n  booking_by_owner.*,\n  lost_by_owner.*,\n  pipeline_by_owner.*\nfrom user \nleft join booking_by_owner on booking_by_owner.b_owner_id = user.user_id\nleft join lost_by_owner on lost_by_owner.l_owner_id = user.user_id\nleft join pipeline_by_owner on pipeline_by_owner.p_owner_id = user.user_id\n),  __dbt__CTE__stg_salesforce_user_role as (\nwith base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields\n),opportunity_aggregation_by_owner as (\n    \n    select *\n    from __dbt__CTE__opportunity_aggregation_by_owner\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), user_role as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user_role\n  \n)\n\nselect \n\n  coalesce(manager.name, 'No Manager Assigned') as manager_name,\n  manager.city as manager_city,\n  manager.state as manager_state,\n  user_role.role_name as manager_position,\n  count(distinct owner_id) as number_of_direct_reports,\n  coalesce(sum(bookings_amount_closed_this_month), 0) as bookings_amount_closed_this_month,\n  coalesce(sum(bookings_amount_closed_this_quarter), 0) as bookings_amount_closed_this_quarter,\n  coalesce(sum(total_number_bookings), 0) as total_number_bookings,\n  coalesce(sum(total_bookings_amount), 0) as total_bookings_amount,\n  coalesce(sum(bookings_count_closed_this_month), 0) as bookings_count_closed_this_month,\n  coalesce(sum(bookings_count_closed_this_quarter), 0) as bookings_count_closed_this_quarter,\n  coalesce(max(largest_booking), 0) as largest_booking,\n  coalesce(sum(lost_amount_this_month), 0) as lost_amount_this_month,\n  coalesce(sum(lost_amount_this_quarter), 0) as lost_amount_this_quarter,\n  coalesce(sum(total_number_lost), 0) as total_number_lost,\n  coalesce(sum(total_lost_amount), 0) as total_lost_amount,\n  coalesce(sum(lost_count_this_month), 0) as lost_count_this_month,\n  coalesce(sum(lost_count_this_quarter), 0) as lost_count_this_quarter,\n  coalesce(sum(pipeline_created_amount_this_month), 0) as pipeline_created_amount_this_month,\n  coalesce(sum(pipeline_created_amount_this_quarter), 0) as pipeline_created_amount_this_quarter,\n  coalesce(sum(pipeline_created_forecast_amount_this_month), 0) as pipeline_created_forecast_amount_this_month,\n  coalesce(sum(pipeline_created_forecast_amount_this_quarter), 0) as pipeline_created_forecast_amount_this_quarter,\n  coalesce(sum(pipeline_count_created_this_month), 0) as pipeline_count_created_this_month,\n  coalesce(sum(pipeline_count_created_this_quarter), 0) as pipeline_count_created_this_quarter,\n  coalesce(sum(total_number_pipeline), 0) as total_number_pipeline,\n  coalesce(sum(total_pipeline_amount), 0) as total_pipeline_amount,\n  coalesce(sum(total_pipeline_forecast_amount), 0) as total_pipeline_forecast_amount,\n  coalesce(max(largest_deal_in_pipeline), 0) as largest_deal_in_pipeline,\n  round(case when sum(bookings_amount_closed_this_month + lost_amount_this_month) > 0 then \n            sum(bookings_amount_closed_this_month) / sum(bookings_amount_closed_this_month + lost_amount_this_month) * 100\n            else 0 end, 2) as win_percent_this_month,\n  round(case when sum(bookings_amount_closed_this_quarter + lost_amount_this_quarter) > 0 then\n            sum(bookings_amount_closed_this_quarter) / sum(bookings_amount_closed_this_quarter + lost_amount_this_quarter) * 100\n            else 0 end, 2) as win_percent_this_quarter,\n  round(case when sum(total_bookings_amount + total_lost_amount) > 0 then \n            sum(total_bookings_amount) / sum(total_bookings_amount + total_lost_amount) * 100\n            else 0 end, 2) as total_win_percent\n\nfrom opportunity_aggregation_by_owner\nleft join user as manager on manager.user_id = opportunity_aggregation_by_owner.manager_id\nleft join user_role on user_role.user_role_id = manager.user_role_id\ngroup by 1, 2, 3, 4\nhaving number_of_direct_reports > 0", "wrapped_sql": null}, "model.salesforce.salesforce_opportunity_enhanced": {"raw_sql": "with opportunity as (\n    \n    select *\n    from {{ ref('stg_salesforce_opportunity') }}\n\n), user as (\n\n    select *\n    from {{ ref('stg_salesforce_user') }}\n  \n), account as (\n\n    select *\n    from {{ ref('stg_salesforce_account') }}\n  \n), add_fields as (\n\n    select \n      opportunity.* ,\n      account.*,\n      opportunity_owner.user_id as opportunity_owner_id,\n      opportunity_owner.name as opportunity_owner_name,\n      opportunity_owner.city opportunity_owner_city,\n      opportunity_owner.state as opportunity_owner_state,\n      opportunity_manager.user_id as opportunity_manager_id,\n      opportunity_manager.name as opportunity_manager_name,\n      opportunity_manager.city opportunity_manager_city,\n      opportunity_manager.state as opportunity_manager_state,\n      case\n        when opportunity.is_won then 'Won'\n        when not opportunity.is_won and opportunity.is_closed then 'Lost'\n        when not opportunity.is_closed and lower(opportunity.forecast_category) in ('pipeline','forecast','bestcase') then 'Pipeline'\n        else 'Other'\n      end as status,\n      case when is_created_this_month then amount else 0 end as created_amount_this_month,\n      case when is_created_this_quarter then amount else 0 end as created_amount_this_quarter,\n      case when is_created_this_month then 1 else 0 end as created_count_this_month,\n      case when is_created_this_quarter then 1 else 0 end as created_count_this_quarter,\n      case when is_closed_this_month then amount else 0 end as closed_amount_this_month,\n      case when is_closed_this_quarter then amount else 0 end as closed_amount_this_quarter,\n      case when is_closed_this_month then 1 else 0 end as closed_count_this_month,\n      case when is_closed_this_quarter then 1 else 0 end as closed_count_this_quarter\n      \n    from opportunity\n    left join account on opportunity.opportunity_account_id = account.account_id\n    left join user as opportunity_owner on opportunity.owner_id = opportunity_owner.user_id\n    left join user as opportunity_manager on opportunity_owner.manager_id = opportunity_manager.user_id\n)\n\nselect *\nfrom add_fields", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "salesforce_opportunity_enhanced"], "unique_id": "model.salesforce.salesforce_opportunity_enhanced", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "salesforce_opportunity_enhanced.sql", "original_file_path": "models/salesforce_opportunity_enhanced.sql", "name": "salesforce_opportunity_enhanced", "resource_type": "model", "alias": "salesforce_opportunity_enhanced", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [["stg_salesforce_opportunity"], ["stg_salesforce_user"], ["stg_salesforce_account"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.salesforce.stg_salesforce_opportunity", "model.salesforce.stg_salesforce_user", "model.salesforce.stg_salesforce_account"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/salesforce_opportunity_enhanced.sql", "compiled": true, "compiled_sql": "with opportunity as (\n    \n    select *\n    from __dbt__CTE__stg_salesforce_opportunity\n\n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), account as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_account\n  \n), add_fields as (\n\n    select \n      opportunity.* ,\n      account.*,\n      opportunity_owner.user_id as opportunity_owner_id,\n      opportunity_owner.name as opportunity_owner_name,\n      opportunity_owner.city opportunity_owner_city,\n      opportunity_owner.state as opportunity_owner_state,\n      opportunity_manager.user_id as opportunity_manager_id,\n      opportunity_manager.name as opportunity_manager_name,\n      opportunity_manager.city opportunity_manager_city,\n      opportunity_manager.state as opportunity_manager_state,\n      case\n        when opportunity.is_won then 'Won'\n        when not opportunity.is_won and opportunity.is_closed then 'Lost'\n        when not opportunity.is_closed and lower(opportunity.forecast_category) in ('pipeline','forecast','bestcase') then 'Pipeline'\n        else 'Other'\n      end as status,\n      case when is_created_this_month then amount else 0 end as created_amount_this_month,\n      case when is_created_this_quarter then amount else 0 end as created_amount_this_quarter,\n      case when is_created_this_month then 1 else 0 end as created_count_this_month,\n      case when is_created_this_quarter then 1 else 0 end as created_count_this_quarter,\n      case when is_closed_this_month then amount else 0 end as closed_amount_this_month,\n      case when is_closed_this_quarter then amount else 0 end as closed_amount_this_quarter,\n      case when is_closed_this_month then 1 else 0 end as closed_count_this_month,\n      case when is_closed_this_quarter then 1 else 0 end as closed_count_this_quarter\n      \n    from opportunity\n    left join account on opportunity.opportunity_account_id = account.account_id\n    left join user as opportunity_owner on opportunity.owner_id = opportunity_owner.user_id\n    left join user as opportunity_manager on opportunity_owner.manager_id = opportunity_manager.user_id\n)\n\nselect *\nfrom add_fields", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_opportunity", "sql": " __dbt__CTE__stg_salesforce_opportunity as (\nwith base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields\n)"}, {"id": "model.salesforce.stg_salesforce_user", "sql": " __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)"}, {"id": "model.salesforce.stg_salesforce_account", "sql": " __dbt__CTE__stg_salesforce_account as (\nwith base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "with  __dbt__CTE__stg_salesforce_opportunity as (\nwith base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields\n),  __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n),  __dbt__CTE__stg_salesforce_account as (\nwith base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields\n),opportunity as (\n    \n    select *\n    from __dbt__CTE__stg_salesforce_opportunity\n\n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), account as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_account\n  \n), add_fields as (\n\n    select \n      opportunity.* ,\n      account.*,\n      opportunity_owner.user_id as opportunity_owner_id,\n      opportunity_owner.name as opportunity_owner_name,\n      opportunity_owner.city opportunity_owner_city,\n      opportunity_owner.state as opportunity_owner_state,\n      opportunity_manager.user_id as opportunity_manager_id,\n      opportunity_manager.name as opportunity_manager_name,\n      opportunity_manager.city opportunity_manager_city,\n      opportunity_manager.state as opportunity_manager_state,\n      case\n        when opportunity.is_won then 'Won'\n        when not opportunity.is_won and opportunity.is_closed then 'Lost'\n        when not opportunity.is_closed and lower(opportunity.forecast_category) in ('pipeline','forecast','bestcase') then 'Pipeline'\n        else 'Other'\n      end as status,\n      case when is_created_this_month then amount else 0 end as created_amount_this_month,\n      case when is_created_this_quarter then amount else 0 end as created_amount_this_quarter,\n      case when is_created_this_month then 1 else 0 end as created_count_this_month,\n      case when is_created_this_quarter then 1 else 0 end as created_count_this_quarter,\n      case when is_closed_this_month then amount else 0 end as closed_amount_this_month,\n      case when is_closed_this_quarter then amount else 0 end as closed_amount_this_quarter,\n      case when is_closed_this_month then 1 else 0 end as closed_count_this_month,\n      case when is_closed_this_quarter then 1 else 0 end as closed_count_this_quarter\n      \n    from opportunity\n    left join account on opportunity.opportunity_account_id = account.account_id\n    left join user as opportunity_owner on opportunity.owner_id = opportunity_owner.user_id\n    left join user as opportunity_manager on opportunity_owner.manager_id = opportunity_manager.user_id\n)\n\nselect *\nfrom add_fields", "wrapped_sql": null}, "model.salesforce.opportunity_aggregation_by_owner": {"raw_sql": "with salesforce_opportunity_enhanced as (\n    \n    select *\n    from {{ ref('salesforce_opportunity_enhanced') }}\n  \n), user as (\n\n    select *\n    from {{ ref('stg_salesforce_user') }}\n  \n), booking_by_owner as (\n\n  select \n    opportunity_manager_id as b_manager_id,\n    opportunity_owner_id as b_owner_id,\n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n  group by 1, 2\n\n), lost_by_owner as (\n\n  select \n    opportunity_manager_id as l_manager_id,\n    opportunity_owner_id as l_owner_id,\n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n  group by 1, 2\n\n), pipeline_by_owner as (\n\n  select \n    opportunity_manager_id as p_manager_id,\n    opportunity_owner_id as p_owner_id,\n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n  group by 1, 2\n)\n\nselect \n  user.user_id as owner_id,\n  coalesce(p_manager_id, b_manager_id, l_manager_id) as manager_id,\n  booking_by_owner.*,\n  lost_by_owner.*,\n  pipeline_by_owner.*\nfrom user \nleft join booking_by_owner on booking_by_owner.b_owner_id = user.user_id\nleft join lost_by_owner on lost_by_owner.l_owner_id = user.user_id\nleft join pipeline_by_owner on pipeline_by_owner.p_owner_id = user.user_id", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "intermediate", "opportunity_aggregation_by_owner"], "unique_id": "model.salesforce.opportunity_aggregation_by_owner", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "intermediate/opportunity_aggregation_by_owner.sql", "original_file_path": "models/intermediate/opportunity_aggregation_by_owner.sql", "name": "opportunity_aggregation_by_owner", "resource_type": "model", "alias": "opportunity_aggregation_by_owner", "config": {"enabled": true, "materialized": "ephemeral", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [["salesforce_opportunity_enhanced"], ["stg_salesforce_user"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.salesforce.salesforce_opportunity_enhanced", "model.salesforce.stg_salesforce_user"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/intermediate/opportunity_aggregation_by_owner.sql", "compiled": true, "compiled_sql": "with salesforce_opportunity_enhanced as (\n    \n    select *\n    from `digital-arbor-400`.`dbt_kristin_test`.`salesforce_opportunity_enhanced`\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), booking_by_owner as (\n\n  select \n    opportunity_manager_id as b_manager_id,\n    opportunity_owner_id as b_owner_id,\n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n  group by 1, 2\n\n), lost_by_owner as (\n\n  select \n    opportunity_manager_id as l_manager_id,\n    opportunity_owner_id as l_owner_id,\n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n  group by 1, 2\n\n), pipeline_by_owner as (\n\n  select \n    opportunity_manager_id as p_manager_id,\n    opportunity_owner_id as p_owner_id,\n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n  group by 1, 2\n)\n\nselect \n  user.user_id as owner_id,\n  coalesce(p_manager_id, b_manager_id, l_manager_id) as manager_id,\n  booking_by_owner.*,\n  lost_by_owner.*,\n  pipeline_by_owner.*\nfrom user \nleft join booking_by_owner on booking_by_owner.b_owner_id = user.user_id\nleft join lost_by_owner on lost_by_owner.l_owner_id = user.user_id\nleft join pipeline_by_owner on pipeline_by_owner.p_owner_id = user.user_id", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_user", "sql": " __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "with  __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n),salesforce_opportunity_enhanced as (\n    \n    select *\n    from `digital-arbor-400`.`dbt_kristin_test`.`salesforce_opportunity_enhanced`\n  \n), user as (\n\n    select *\n    from __dbt__CTE__stg_salesforce_user\n  \n), booking_by_owner as (\n\n  select \n    opportunity_manager_id as b_manager_id,\n    opportunity_owner_id as b_owner_id,\n    round(sum(closed_amount_this_month)) as bookings_amount_closed_this_month,\n    round(sum(closed_amount_this_quarter)) as bookings_amount_closed_this_quarter,\n    count(*) as total_number_bookings,\n    round(sum(amount)) as total_bookings_amount,\n    sum(closed_count_this_month) as bookings_count_closed_this_month,\n    sum(closed_count_this_quarter) as bookings_count_closed_this_quarter,\n    round(avg(amount)) as avg_bookings_amount,\n    max(amount) as largest_booking,\n    avg(days_to_close) as avg_days_to_close\n  from salesforce_opportunity_enhanced\n  where status = 'Won'\n  group by 1, 2\n\n), lost_by_owner as (\n\n  select \n    opportunity_manager_id as l_manager_id,\n    opportunity_owner_id as l_owner_id,\n    round(sum(closed_amount_this_month)) as lost_amount_this_month,\n    round(sum(closed_amount_this_quarter)) as lost_amount_this_quarter,\n    count(*) as total_number_lost,\n    round(sum(amount)) as total_lost_amount,\n    sum(closed_count_this_month) as lost_count_this_month,\n    sum(closed_count_this_quarter) as lost_count_this_quarter\n  from salesforce_opportunity_enhanced\n  where status = 'Lost'\n  group by 1, 2\n\n), pipeline_by_owner as (\n\n  select \n    opportunity_manager_id as p_manager_id,\n    opportunity_owner_id as p_owner_id,\n    round(sum(created_amount_this_month)) as pipeline_created_amount_this_month,\n    round(sum(created_amount_this_quarter)) as pipeline_created_amount_this_quarter,\n    round(sum(created_amount_this_month * probability)) as pipeline_created_forecast_amount_this_month,\n    round(sum(created_amount_this_quarter * probability)) as pipeline_created_forecast_amount_this_quarter,\n    sum(created_count_this_month) as pipeline_count_created_this_month,\n    sum(created_count_this_quarter) as pipeline_count_created_this_quarter,\n    count(*) as total_number_pipeline,\n    round(sum(amount)) as total_pipeline_amount,\n    round(sum(amount * probability)) as total_pipeline_forecast_amount,\n    round(avg(amount)) as avg_pipeline_opp_amount,\n    max(amount) as largest_deal_in_pipeline,\n    avg(days_since_created) as avg_days_open\n  from salesforce_opportunity_enhanced\n  where status = 'Pipeline'\n  group by 1, 2\n)\n\nselect \n  user.user_id as owner_id,\n  coalesce(p_manager_id, b_manager_id, l_manager_id) as manager_id,\n  booking_by_owner.*,\n  lost_by_owner.*,\n  pipeline_by_owner.*\nfrom user \nleft join booking_by_owner on booking_by_owner.b_owner_id = user.user_id\nleft join lost_by_owner on lost_by_owner.l_owner_id = user.user_id\nleft join pipeline_by_owner on pipeline_by_owner.p_owner_id = user.user_id", "wrapped_sql": null}, "model.salesforce.stg_salesforce_opportunity": {"raw_sql": "with base as (\n\n    select *\n    from {{ var('opportunity')}}\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= {{ dbt_utils.date_trunc('month', dbt_utils.current_timestamp()) }} as is_created_this_month,\n        created_date >= {{ dbt_utils.date_trunc('quarter', dbt_utils.current_timestamp()) }} as is_created_this_quarter,\n        {{ dbt_utils.datediff(dbt_utils.current_timestamp(), 'created_date', 'day') }} as days_since_created,\n        {{ dbt_utils.datediff('close_date', 'created_date', 'day') }} as days_to_close,\n        {{ dbt_utils.date_trunc('month', 'close_date') }} = {{ dbt_utils.date_trunc('month', dbt_utils.current_timestamp()) }} as is_closed_this_month,\n        {{ dbt_utils.date_trunc('quarter', 'close_date') }} = {{ dbt_utils.date_trunc('quarter', dbt_utils.current_timestamp()) }} as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "base", "stg_salesforce_opportunity"], "unique_id": "model.salesforce.stg_salesforce_opportunity", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "base/stg_salesforce_opportunity.sql", "original_file_path": "models/base/stg_salesforce_opportunity.sql", "name": "stg_salesforce_opportunity", "resource_type": "model", "alias": "stg_salesforce_opportunity", "config": {"enabled": true, "materialized": "ephemeral", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.current_timestamp", "macro.dbt_utils.date_trunc", "macro.dbt_utils.datediff"], "nodes": []}, "description": "", "columns": {"opportunity_id": {"name": "opportunity_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/base/schema.yml", "build_path": "target/compiled/salesforce/base/stg_salesforce_opportunity.sql", "compiled": true, "compiled_sql": "with base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "with base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields", "wrapped_sql": null}, "model.salesforce.stg_salesforce_user": {"raw_sql": "with base as (\n\n    select *\n    from {{ var('user')}}\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "base", "stg_salesforce_user"], "unique_id": "model.salesforce.stg_salesforce_user", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "base/stg_salesforce_user.sql", "original_file_path": "models/base/stg_salesforce_user.sql", "name": "stg_salesforce_user", "resource_type": "model", "alias": "stg_salesforce_user", "config": {"enabled": true, "materialized": "ephemeral", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {"user_id": {"name": "user_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/base/schema.yml", "build_path": "target/compiled/salesforce/base/stg_salesforce_user.sql", "compiled": true, "compiled_sql": "with base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "with base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields", "wrapped_sql": null}, "model.salesforce.stg_salesforce_user_role": {"raw_sql": "with base as (\n\n    select *\n    from {{ var('user_role')}}\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "base", "stg_salesforce_user_role"], "unique_id": "model.salesforce.stg_salesforce_user_role", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "base/stg_salesforce_user_role.sql", "original_file_path": "models/base/stg_salesforce_user_role.sql", "name": "stg_salesforce_user_role", "resource_type": "model", "alias": "stg_salesforce_user_role", "config": {"enabled": true, "materialized": "ephemeral", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {"user_role_id": {"name": "user_role_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/base/schema.yml", "build_path": "target/compiled/salesforce/base/stg_salesforce_user_role.sql", "compiled": true, "compiled_sql": "with base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "with base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields", "wrapped_sql": null}, "model.salesforce.stg_salesforce_account": {"raw_sql": "with base as (\n\n    select *\n    from {{ var('account')}}\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "base", "stg_salesforce_account"], "unique_id": "model.salesforce.stg_salesforce_account", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "base/stg_salesforce_account.sql", "original_file_path": "models/base/stg_salesforce_account.sql", "name": "stg_salesforce_account", "resource_type": "model", "alias": "stg_salesforce_account", "config": {"enabled": true, "materialized": "ephemeral", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {"account_id": {"name": "account_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/base/schema.yml", "build_path": "target/compiled/salesforce/base/stg_salesforce_account.sql", "compiled": true, "compiled_sql": "with base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "with base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields", "wrapped_sql": null}, "test.salesforce.not_null_stg_salesforce_account_account_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('stg_salesforce_account'), column_name='account_id') }}", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "schema_test", "not_null_stg_salesforce_account_account_id"], "unique_id": "test.salesforce.not_null_stg_salesforce_account_account_id", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "schema_test/not_null_stg_salesforce_account_account_id.sql", "original_file_path": "models/base/schema.yml", "name": "not_null_stg_salesforce_account_account_id", "resource_type": "test", "alias": "not_null_stg_salesforce_account_account_id", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["stg_salesforce_account"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.salesforce.stg_salesforce_account"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/schema_test/not_null_stg_salesforce_account_account_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom __dbt__CTE__stg_salesforce_account\nwhere account_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_account", "sql": " __dbt__CTE__stg_salesforce_account as (\nwith base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_account as (\nwith base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom __dbt__CTE__stg_salesforce_account\nwhere account_id is null\n\n", "wrapped_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_account as (\nwith base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom __dbt__CTE__stg_salesforce_account\nwhere account_id is null\n\n", "column_name": "account_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "account_id"}}}, "test.salesforce.unique_stg_salesforce_account_account_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('stg_salesforce_account'), column_name='account_id') }}", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "schema_test", "unique_stg_salesforce_account_account_id"], "unique_id": "test.salesforce.unique_stg_salesforce_account_account_id", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "schema_test/unique_stg_salesforce_account_account_id.sql", "original_file_path": "models/base/schema.yml", "name": "unique_stg_salesforce_account_account_id", "resource_type": "test", "alias": "unique_stg_salesforce_account_account_id", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["stg_salesforce_account"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.salesforce.stg_salesforce_account"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/schema_test/unique_stg_salesforce_account_account_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        account_id\n\n    from __dbt__CTE__stg_salesforce_account\n    where account_id is not null\n    group by account_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_account", "sql": " __dbt__CTE__stg_salesforce_account as (\nwith base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_account as (\nwith base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom (\n\n    select\n        account_id\n\n    from __dbt__CTE__stg_salesforce_account\n    where account_id is not null\n    group by account_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_account as (\nwith base as (\n\n    select *\n    from salesforce.account\n    where not is_deleted\n\n), fields as (\n\n    select \n\n      id as account_id,\n      name as account_name,\n      industry,\n      number_of_employees,\n      account_source,\n      rating as account_rating,\n      annual_revenue\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom (\n\n    select\n        account_id\n\n    from __dbt__CTE__stg_salesforce_account\n    where account_id is not null\n    group by account_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "account_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "account_id"}}}, "test.salesforce.not_null_stg_salesforce_opportunity_opportunity_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('stg_salesforce_opportunity'), column_name='opportunity_id') }}", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "schema_test", "not_null_stg_salesforce_opportunity_opportunity_id"], "unique_id": "test.salesforce.not_null_stg_salesforce_opportunity_opportunity_id", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "schema_test/not_null_stg_salesforce_opportunity_opportunity_id.sql", "original_file_path": "models/base/schema.yml", "name": "not_null_stg_salesforce_opportunity_opportunity_id", "resource_type": "test", "alias": "not_null_stg_salesforce_opportunity_opportunity_id", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["stg_salesforce_opportunity"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.salesforce.stg_salesforce_opportunity"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/schema_test/not_null_stg_salesforce_opportunity_opportunity_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom __dbt__CTE__stg_salesforce_opportunity\nwhere opportunity_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_opportunity", "sql": " __dbt__CTE__stg_salesforce_opportunity as (\nwith base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_opportunity as (\nwith base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom __dbt__CTE__stg_salesforce_opportunity\nwhere opportunity_id is null\n\n", "wrapped_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_opportunity as (\nwith base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom __dbt__CTE__stg_salesforce_opportunity\nwhere opportunity_id is null\n\n", "column_name": "opportunity_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "opportunity_id"}}}, "test.salesforce.unique_stg_salesforce_opportunity_opportunity_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('stg_salesforce_opportunity'), column_name='opportunity_id') }}", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "schema_test", "unique_stg_salesforce_opportunity_opportunity_id"], "unique_id": "test.salesforce.unique_stg_salesforce_opportunity_opportunity_id", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "schema_test/unique_stg_salesforce_opportunity_opportunity_id.sql", "original_file_path": "models/base/schema.yml", "name": "unique_stg_salesforce_opportunity_opportunity_id", "resource_type": "test", "alias": "unique_stg_salesforce_opportunity_opportunity_id", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["stg_salesforce_opportunity"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.salesforce.stg_salesforce_opportunity"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/schema_test/unique_stg_salesforce_opportunity_opportunity_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        opportunity_id\n\n    from __dbt__CTE__stg_salesforce_opportunity\n    where opportunity_id is not null\n    group by opportunity_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_opportunity", "sql": " __dbt__CTE__stg_salesforce_opportunity as (\nwith base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_opportunity as (\nwith base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom (\n\n    select\n        opportunity_id\n\n    from __dbt__CTE__stg_salesforce_opportunity\n    where opportunity_id is not null\n    group by opportunity_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_opportunity as (\nwith base as (\n\n    select *\n    from salesforce.opportunity\n    where not is_deleted\n\n), fields as (\n\n    select \n\n        id as opportunity_id,\n        account_id as opportunity_account_id,\n        amount,\n        probability,\n        created_date, \n        is_won,\n        is_closed,\n        forecast_category,\n        stage_name,\n        owner_id,\n        close_date,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_created_this_month,\n        created_date >= \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_created_this_quarter,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(\n    current_timestamp\n as datetime),\n        day\n    )\n\n\n as days_since_created,\n        \n  \n\n    datetime_diff(\n        cast(created_date as datetime),\n        cast(close_date as datetime),\n        day\n    )\n\n\n as days_to_close,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        month\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        month\n    )\n\n as is_closed_this_month,\n        \n    timestamp_trunc(\n        cast(close_date as timestamp),\n        quarter\n    )\n\n = \n    timestamp_trunc(\n        cast(\n    current_timestamp\n as timestamp),\n        quarter\n    )\n\n as is_closed_this_quarter\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom (\n\n    select\n        opportunity_id\n\n    from __dbt__CTE__stg_salesforce_opportunity\n    where opportunity_id is not null\n    group by opportunity_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "opportunity_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "opportunity_id"}}}, "test.salesforce.not_null_stg_salesforce_user_user_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('stg_salesforce_user'), column_name='user_id') }}", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "schema_test", "not_null_stg_salesforce_user_user_id"], "unique_id": "test.salesforce.not_null_stg_salesforce_user_user_id", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "schema_test/not_null_stg_salesforce_user_user_id.sql", "original_file_path": "models/base/schema.yml", "name": "not_null_stg_salesforce_user_user_id", "resource_type": "test", "alias": "not_null_stg_salesforce_user_user_id", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["stg_salesforce_user"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.salesforce.stg_salesforce_user"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/schema_test/not_null_stg_salesforce_user_user_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom __dbt__CTE__stg_salesforce_user\nwhere user_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_user", "sql": " __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom __dbt__CTE__stg_salesforce_user\nwhere user_id is null\n\n", "wrapped_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom __dbt__CTE__stg_salesforce_user\nwhere user_id is null\n\n", "column_name": "user_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "user_id"}}}, "test.salesforce.unique_stg_salesforce_user_user_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('stg_salesforce_user'), column_name='user_id') }}", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "schema_test", "unique_stg_salesforce_user_user_id"], "unique_id": "test.salesforce.unique_stg_salesforce_user_user_id", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "schema_test/unique_stg_salesforce_user_user_id.sql", "original_file_path": "models/base/schema.yml", "name": "unique_stg_salesforce_user_user_id", "resource_type": "test", "alias": "unique_stg_salesforce_user_user_id", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["stg_salesforce_user"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.salesforce.stg_salesforce_user"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/schema_test/unique_stg_salesforce_user_user_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        user_id\n\n    from __dbt__CTE__stg_salesforce_user\n    where user_id is not null\n    group by user_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_user", "sql": " __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom (\n\n    select\n        user_id\n\n    from __dbt__CTE__stg_salesforce_user\n    where user_id is not null\n    group by user_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_user as (\nwith base as (\n\n    select *\n    from salesforce.user\n\n), fields as (\n\n    select \n      id as user_id,\n      name,\n      city,\n      state,\n      manager_id,\n      user_role_id\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom (\n\n    select\n        user_id\n\n    from __dbt__CTE__stg_salesforce_user\n    where user_id is not null\n    group by user_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "user_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "user_id"}}}, "test.salesforce.not_null_stg_salesforce_user_role_user_role_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('stg_salesforce_user_role'), column_name='user_role_id') }}", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "schema_test", "not_null_stg_salesforce_user_role_user_role_id"], "unique_id": "test.salesforce.not_null_stg_salesforce_user_role_user_role_id", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "schema_test/not_null_stg_salesforce_user_role_user_role_id.sql", "original_file_path": "models/base/schema.yml", "name": "not_null_stg_salesforce_user_role_user_role_id", "resource_type": "test", "alias": "not_null_stg_salesforce_user_role_user_role_id", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["stg_salesforce_user_role"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.salesforce.stg_salesforce_user_role"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/schema_test/not_null_stg_salesforce_user_role_user_role_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom __dbt__CTE__stg_salesforce_user_role\nwhere user_role_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_user_role", "sql": " __dbt__CTE__stg_salesforce_user_role as (\nwith base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_user_role as (\nwith base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom __dbt__CTE__stg_salesforce_user_role\nwhere user_role_id is null\n\n", "wrapped_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_user_role as (\nwith base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom __dbt__CTE__stg_salesforce_user_role\nwhere user_role_id is null\n\n", "column_name": "user_role_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "user_role_id"}}}, "test.salesforce.unique_stg_salesforce_user_role_user_role_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('stg_salesforce_user_role'), column_name='user_role_id') }}", "database": "digital-arbor-400", "schema": "dbt_kristin_test", "fqn": ["salesforce", "schema_test", "unique_stg_salesforce_user_role_user_role_id"], "unique_id": "test.salesforce.unique_stg_salesforce_user_role_user_role_id", "package_name": "salesforce", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce", "path": "schema_test/unique_stg_salesforce_user_role_user_role_id.sql", "original_file_path": "models/base/schema.yml", "name": "unique_stg_salesforce_user_role_user_role_id", "resource_type": "test", "alias": "unique_stg_salesforce_user_role_user_role_id", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"account": "salesforce.account", "opportunity": "salesforce.opportunity", "user_role": "salesforce.user_role", "user": "salesforce.user"}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["stg_salesforce_user_role"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.salesforce.stg_salesforce_user_role"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/salesforce/schema_test/unique_stg_salesforce_user_role_user_role_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        user_role_id\n\n    from __dbt__CTE__stg_salesforce_user_role\n    where user_role_id is not null\n    group by user_role_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.salesforce.stg_salesforce_user_role", "sql": " __dbt__CTE__stg_salesforce_user_role as (\nwith base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields\n)"}], "injected_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_user_role as (\nwith base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom (\n\n    select\n        user_role_id\n\n    from __dbt__CTE__stg_salesforce_user_role\n    where user_role_id is not null\n    group by user_role_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nwith __dbt__CTE__stg_salesforce_user_role as (\nwith base as (\n\n    select *\n    from salesforce.user_role\n    where not _fivetran_deleted\n\n), fields as (\n\n    select \n\n      id as user_role_id,\n      name as role_name\n\n    from base\n\n)\n\nselect *\nfrom fields\n)select count(*)\nfrom (\n\n    select\n        user_role_id\n\n    from __dbt__CTE__stg_salesforce_user_role\n    where user_role_id is not null\n    group by user_role_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "user_role_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "user_role_id"}}}}, "macros": {"macro.dbt.statement": {"raw_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set status, res = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, status=status, agate_table=res) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro noop_statement(name=None, status=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_result(name, status=status, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.statement", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/core.sql", "original_file_path": "macros/core.sql", "resource_type": "macro", "name": "statement", "macro_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set status, res = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, status=status, agate_table=res) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.noop_statement": {"raw_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set status, res = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, status=status, agate_table=res) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro noop_statement(name=None, status=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_result(name, status=status, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.noop_statement", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/core.sql", "original_file_path": "macros/core.sql", "resource_type": "macro", "name": "noop_statement", "macro_sql": "{% macro noop_statement(name=None, status=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_result(name, status=status, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.run_hooks": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.run_hooks", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "run_hooks", "macro_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.column_list": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.column_list", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "column_list", "macro_sql": "{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.column_list_for_create_table": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.column_list_for_create_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "column_list_for_create_table", "macro_sql": "{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.make_hook_config": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.make_hook_config", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "make_hook_config", "macro_sql": "{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.before_begin": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.before_begin", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "before_begin", "macro_sql": "{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.in_transaction": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.in_transaction", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "in_transaction", "macro_sql": "{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.after_commit": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.after_commit", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "after_commit", "macro_sql": "{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.drop_relation_if_exists": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.drop_relation_if_exists", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "drop_relation_if_exists", "macro_sql": "{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.load_relation": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.load_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "load_relation", "macro_sql": "{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_merge_sql": {"raw_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter_macro('snapshot_merge_sql', target, source, insert_cols) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'update'\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n    ;\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshot/snapshot_merge.sql", "resource_type": "macro", "name": "snapshot_merge_sql", "macro_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter_macro('snapshot_merge_sql', target, source, insert_cols) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_merge_sql": {"raw_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter_macro('snapshot_merge_sql', target, source, insert_cols) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'update'\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n    ;\n{% endmacro %}", "unique_id": "macro.dbt.default__snapshot_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshot/snapshot_merge.sql", "resource_type": "macro", "name": "default__snapshot_merge_sql", "macro_sql": "{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'update'\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n    ;\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.strategy_dispatch": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.strategy_dispatch", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "strategy_dispatch", "macro_sql": "{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_hash_arguments": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_hash_arguments", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_hash_arguments", "macro_sql": "{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_hash_arguments": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.default__snapshot_hash_arguments", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "default__snapshot_hash_arguments", "macro_sql": "{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_get_time": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_get_time", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_get_time", "macro_sql": "{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_get_time": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.default__snapshot_get_time", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "default__snapshot_get_time", "macro_sql": "{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_timestamp_strategy": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_timestamp_strategy", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_timestamp_strategy", "macro_sql": "{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_string_as_time": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_string_as_time", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_string_as_time", "macro_sql": "{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_string_as_time": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.default__snapshot_string_as_time", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "default__snapshot_string_as_time", "macro_sql": "{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_check_all_get_existing_columns": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_check_all_get_existing_columns", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_check_all_get_existing_columns", "macro_sql": "{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_check_strategy": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_check_strategy", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_check_strategy", "macro_sql": "{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_columns": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.create_columns", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "create_columns", "macro_sql": "{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_columns": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__create_columns", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "default__create_columns", "macro_sql": "{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.post_snapshot": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.post_snapshot", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "post_snapshot", "macro_sql": "{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__post_snapshot": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__post_snapshot", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "default__post_snapshot", "macro_sql": "{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_staging_table_inserts": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.snapshot_staging_table_inserts", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "snapshot_staging_table_inserts", "macro_sql": "{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_staging_table_updates": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.snapshot_staging_table_updates", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "snapshot_staging_table_updates", "macro_sql": "{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.build_snapshot_table": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.build_snapshot_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "build_snapshot_table", "macro_sql": "{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_or_create_relation": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.get_or_create_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "get_or_create_relation", "macro_sql": "{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.build_snapshot_staging_table": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.build_snapshot_staging_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "build_snapshot_staging_table", "macro_sql": "{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_snapshot_default": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.materialization_snapshot_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "materialization_snapshot_default", "macro_sql": "{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_csv_table": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.create_csv_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "create_csv_table", "macro_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.reset_csv_table": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.reset_csv_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "reset_csv_table", "macro_sql": "{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.load_csv_rows": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.load_csv_rows", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "load_csv_rows", "macro_sql": "{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_csv_table": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__create_csv_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "default__create_csv_table", "macro_sql": "{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__reset_csv_table": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__reset_csv_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "default__reset_csv_table", "macro_sql": "{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_seed_column_quoted_csv": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.get_seed_column_quoted_csv", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "get_seed_column_quoted_csv", "macro_sql": "{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.basic_load_csv_rows": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.basic_load_csv_rows", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "basic_load_csv_rows", "macro_sql": "{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__load_csv_rows": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__load_csv_rows", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "default__load_csv_rows", "macro_sql": "{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_seed_default": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.materialization_seed_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "materialization_seed_default", "macro_sql": "{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.incremental_upsert": {"raw_sql": "{% macro incremental_upsert(tmp_relation, target_relation, unique_key=none, statement_name=\"main\") %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n\n    {%- if unique_key is not none -%}\n    delete\n    from {{ target_relation }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ tmp_relation }}\n    );\n    {%- endif %}\n\n    insert into {{ target_relation }} ({{ dest_cols_csv }})\n    (\n       select {{ dest_cols_csv }}\n       from {{ tmp_relation }}\n    );\n{%- endmacro %}", "unique_id": "macro.dbt.incremental_upsert", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/incremental/helpers.sql", "original_file_path": "macros/materializations/incremental/helpers.sql", "resource_type": "macro", "name": "incremental_upsert", "macro_sql": "{% macro incremental_upsert(tmp_relation, target_relation, unique_key=none, statement_name=\"main\") %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n\n    {%- if unique_key is not none -%}\n    delete\n    from {{ target_relation }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ tmp_relation }}\n    );\n    {%- endif %}\n\n    insert into {{ target_relation }} ({{ dest_cols_csv }})\n    (\n       select {{ dest_cols_csv }}\n       from {{ tmp_relation }}\n    );\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_incremental_default": {"raw_sql": "{% materialization incremental, default -%}\n\n  {% set unique_key = config.get('unique_key') %}\n  {% set full_refresh_mode = flags.FULL_REFRESH %}\n\n  {% set target_relation = this %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view or full_refresh_mode %}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {% set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" %}\n      {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n      {% do adapter.drop_relation(backup_relation) %}\n\n      {% do adapter.rename_relation(target_relation, backup_relation) %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n      {% do to_drop.append(backup_relation) %}\n  {% else %}\n      {% set tmp_relation = make_temp_relation(target_relation) %}\n      {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n      {% do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) %}\n      {% set build_sql = incremental_upsert(tmp_relation, target_relation, unique_key=unique_key) %}\n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt.materialization_incremental_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "resource_type": "macro", "name": "materialization_incremental_default", "macro_sql": "{% materialization incremental, default -%}\n\n  {% set unique_key = config.get('unique_key') %}\n  {% set full_refresh_mode = flags.FULL_REFRESH %}\n\n  {% set target_relation = this %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view or full_refresh_mode %}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {% set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" %}\n      {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n      {% do adapter.drop_relation(backup_relation) %}\n\n      {% do adapter.rename_relation(target_relation, backup_relation) %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n      {% do to_drop.append(backup_relation) %}\n  {% else %}\n      {% set tmp_relation = make_temp_relation(target_relation) %}\n      {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n      {% do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) %}\n      {% set build_sql = incremental_upsert(tmp_relation, target_relation, unique_key=unique_key) %}\n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.get_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "get_merge_sql", "macro_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_delete_insert_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "get_delete_insert_merge_sql", "macro_sql": "{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_insert_overwrite_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "get_insert_overwrite_merge_sql", "macro_sql": "{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.default__get_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "default__get_merge_sql", "macro_sql": "{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_quoted_csv": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.get_quoted_csv", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "get_quoted_csv", "macro_sql": "{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.common_get_delete_insert_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.common_get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "common_get_delete_insert_merge_sql", "macro_sql": "{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_delete_insert_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.default__get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "default__get_delete_insert_merge_sql", "macro_sql": "{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_insert_overwrite_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.default__get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "default__get_insert_overwrite_merge_sql", "macro_sql": "{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_table_default": {"raw_sql": "{% materialization table, default %}\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema,\n                                                      database=database,\n                                                      type='table') -%}\n\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_table_as(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  {% if old_relation is not none %}\n      {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "unique_id": "macro.dbt.materialization_table_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/table/table.sql", "original_file_path": "macros/materializations/table/table.sql", "resource_type": "macro", "name": "materialization_table_default", "macro_sql": "{% materialization table, default %}\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema,\n                                                      database=database,\n                                                      type='table') -%}\n\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_table_as(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  {% if old_relation is not none %}\n      {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_view_default": {"raw_sql": "{%- materialization view, default -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, database=database,\n                                                type='view') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema, database=database, type='view') -%}\n\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"old_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the old_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the old_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema, database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if old_relation is not none %}\n    {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "unique_id": "macro.dbt.materialization_view_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/view/view.sql", "original_file_path": "macros/materializations/view/view.sql", "resource_type": "macro", "name": "materialization_view_default", "macro_sql": "{%- materialization view, default -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, database=database,\n                                                type='view') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema, database=database, type='view') -%}\n\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"old_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the old_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the old_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema, database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if old_relation is not none %}\n    {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.handle_existing_table": {"raw_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter_macro(\"dbt.handle_existing_table\", full_refresh, old_relation) }}\n{% endmacro %}\n\n{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}\n\n{# /*\n       Core materialization implementation. BigQuery and Snowflake are similar\n       because both can use `create or replace view` where the resulting view schema\n       is not necessarily the same as the existing view. On Redshift, this would\n       result in: ERROR:  cannot change number of columns in view\n\n       This implementation is superior to the create_temp, swap_with_existing, drop_old\n       paradigm because transactions don't run DDL queries atomically on Snowflake. By using\n       `create or replace view`, the materialization becomes atomic in nature.\n    */\n#}\n\n{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(flags.FULL_REFRESH, old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "unique_id": "macro.dbt.handle_existing_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/view/create_or_replace_view.sql", "original_file_path": "macros/materializations/view/create_or_replace_view.sql", "resource_type": "macro", "name": "handle_existing_table", "macro_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter_macro(\"dbt.handle_existing_table\", full_refresh, old_relation) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__handle_existing_table": {"raw_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter_macro(\"dbt.handle_existing_table\", full_refresh, old_relation) }}\n{% endmacro %}\n\n{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}\n\n{# /*\n       Core materialization implementation. BigQuery and Snowflake are similar\n       because both can use `create or replace view` where the resulting view schema\n       is not necessarily the same as the existing view. On Redshift, this would\n       result in: ERROR:  cannot change number of columns in view\n\n       This implementation is superior to the create_temp, swap_with_existing, drop_old\n       paradigm because transactions don't run DDL queries atomically on Snowflake. By using\n       `create or replace view`, the materialization becomes atomic in nature.\n    */\n#}\n\n{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(flags.FULL_REFRESH, old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "unique_id": "macro.dbt.default__handle_existing_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/view/create_or_replace_view.sql", "original_file_path": "macros/materializations/view/create_or_replace_view.sql", "resource_type": "macro", "name": "default__handle_existing_table", "macro_sql": "{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_or_replace_view": {"raw_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter_macro(\"dbt.handle_existing_table\", full_refresh, old_relation) }}\n{% endmacro %}\n\n{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}\n\n{# /*\n       Core materialization implementation. BigQuery and Snowflake are similar\n       because both can use `create or replace view` where the resulting view schema\n       is not necessarily the same as the existing view. On Redshift, this would\n       result in: ERROR:  cannot change number of columns in view\n\n       This implementation is superior to the create_temp, swap_with_existing, drop_old\n       paradigm because transactions don't run DDL queries atomically on Snowflake. By using\n       `create or replace view`, the materialization becomes atomic in nature.\n    */\n#}\n\n{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(flags.FULL_REFRESH, old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "unique_id": "macro.dbt.create_or_replace_view", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/view/create_or_replace_view.sql", "original_file_path": "macros/materializations/view/create_or_replace_view.sql", "resource_type": "macro", "name": "create_or_replace_view", "macro_sql": "{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(flags.FULL_REFRESH, old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.generate_alias_name": {"raw_sql": "{#\n    Renders a alias name given a custom alias name. If the custom\n    alias name is none, then the resulting alias is just the filename of the\n    model. If an alias override is specified, then that is used.\n\n    This macro can be overriden in projects to define different semantics\n    for rendering a alias name.\n\n    Arguments:\n    custom_alias_name: The custom alias name specified for a model, or none\n    node: The available node that an alias is being generated for, or none\n\n#}\n{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name is none -%}\n\n        {{ node.name }}\n\n    {%- else -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.generate_alias_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_custom_alias.sql", "original_file_path": "macros/etc/get_custom_alias.sql", "resource_type": "macro", "name": "generate_alias_name", "macro_sql": "{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name is none -%}\n\n        {{ node.name }}\n\n    {%- else -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.run_query": {"raw_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "unique_id": "macro.dbt.run_query", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/query.sql", "original_file_path": "macros/etc/query.sql", "resource_type": "macro", "name": "run_query", "macro_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.is_incremental": {"raw_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "unique_id": "macro.dbt.is_incremental", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/is_incremental.sql", "original_file_path": "macros/etc/is_incremental.sql", "resource_type": "macro", "name": "is_incremental", "macro_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.table_options": {"raw_sql": "{% macro table_options() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n{%- endmacro -%}\n\n{% macro get_relation_comment(persist_docs, model) %}\n\n  {%- if persist_docs is not mapping -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n\n  {% if persist_docs.get('relation', false) %}\n    {{ return((model.description | tojson)[1:-1]) }}\n  {%- else -%}\n    {{ return(none) }}\n  {% endif %}\n\n{% endmacro %}", "unique_id": "macro.dbt.table_options", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_relation_comment.sql", "original_file_path": "macros/etc/get_relation_comment.sql", "resource_type": "macro", "name": "table_options", "macro_sql": "{% macro table_options() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_relation_comment": {"raw_sql": "{% macro table_options() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n{%- endmacro -%}\n\n{% macro get_relation_comment(persist_docs, model) %}\n\n  {%- if persist_docs is not mapping -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n\n  {% if persist_docs.get('relation', false) %}\n    {{ return((model.description | tojson)[1:-1]) }}\n  {%- else -%}\n    {{ return(none) }}\n  {% endif %}\n\n{% endmacro %}", "unique_id": "macro.dbt.get_relation_comment", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_relation_comment.sql", "original_file_path": "macros/etc/get_relation_comment.sql", "resource_type": "macro", "name": "get_relation_comment", "macro_sql": "{% macro get_relation_comment(persist_docs, model) %}\n\n  {%- if persist_docs is not mapping -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n\n  {% if persist_docs.get('relation', false) %}\n    {{ return((model.description | tojson)[1:-1]) }}\n  {%- else -%}\n    {{ return(none) }}\n  {% endif %}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.convert_datetime": {"raw_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}\n\n{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}\n\n{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}\n\n{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "unique_id": "macro.dbt.convert_datetime", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "resource_type": "macro", "name": "convert_datetime", "macro_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.dates_in_range": {"raw_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}\n\n{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}\n\n{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}\n\n{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "unique_id": "macro.dbt.dates_in_range", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "resource_type": "macro", "name": "dates_in_range", "macro_sql": "{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.partition_range": {"raw_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}\n\n{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}\n\n{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}\n\n{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "unique_id": "macro.dbt.partition_range", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "resource_type": "macro", "name": "partition_range", "macro_sql": "{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.py_current_timestring": {"raw_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}\n\n{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}\n\n{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}\n\n{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "unique_id": "macro.dbt.py_current_timestring", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "resource_type": "macro", "name": "py_current_timestring", "macro_sql": "{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.generate_schema_name": {"raw_sql": "{#\n    Renders a schema name given a custom schema name. If the custom\n    schema name is none, then the resulting schema is just the \"schema\"\n    value in the specified target. If a schema override is specified, then\n    the resulting schema is the default schema concatenated with the\n    custom schema.\n\n    This macro can be overriden in projects to define different semantics\n    for rendering a schema name.\n\n    Arguments:\n    custom_schema_name: The custom schema name specified for a model, or none\n    node: The node the schema is being generated for\n\n#}\n{% macro generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n{#\n    Renders a schema name given a custom schema name. In production, this macro\n    will render out the overriden schema name for a model. Otherwise, the default\n    schema specified in the active target is used.\n\n    Arguments:\n    custom_schema_name: The custom schema name specified for a model, or none\n    node: The node the schema is being generated for\n\n#}\n{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.generate_schema_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_custom_schema.sql", "original_file_path": "macros/etc/get_custom_schema.sql", "resource_type": "macro", "name": "generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.generate_schema_name_for_env": {"raw_sql": "{#\n    Renders a schema name given a custom schema name. If the custom\n    schema name is none, then the resulting schema is just the \"schema\"\n    value in the specified target. If a schema override is specified, then\n    the resulting schema is the default schema concatenated with the\n    custom schema.\n\n    This macro can be overriden in projects to define different semantics\n    for rendering a schema name.\n\n    Arguments:\n    custom_schema_name: The custom schema name specified for a model, or none\n    node: The node the schema is being generated for\n\n#}\n{% macro generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n{#\n    Renders a schema name given a custom schema name. In production, this macro\n    will render out the overriden schema name for a model. Otherwise, the default\n    schema specified in the active target is used.\n\n    Arguments:\n    custom_schema_name: The custom schema name specified for a model, or none\n    node: The node the schema is being generated for\n\n#}\n{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.generate_schema_name_for_env", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_custom_schema.sql", "original_file_path": "macros/etc/get_custom_schema.sql", "resource_type": "macro", "name": "generate_schema_name_for_env", "macro_sql": "{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.generate_database_name": {"raw_sql": "{#\n    Renders a database name given a custom database name. If the custom\n    database name is none, then the resulting database is just the \"database\"\n    value in the specified target. If a database override is specified, then\n    the resulting database is the default database concatenated with the\n    custom database.\n\n    This macro can be overriden in projects to define different semantics\n    for rendering a database name.\n\n    Arguments:\n    custom_database_name: The custom database name specified for a model, or none\n    node: The node the database is being generated for\n\n#}\n{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.generate_database_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_custom_database.sql", "original_file_path": "macros/etc/get_custom_database.sql", "resource_type": "macro", "name": "generate_database_name", "macro_sql": "{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.adapter_macro": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.adapter_macro", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "adapter_macro", "macro_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_columns_in_query": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.get_columns_in_query", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "get_columns_in_query", "macro_sql": "{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_columns_in_query": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__get_columns_in_query", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__get_columns_in_query", "macro_sql": "{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_schema": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.create_schema", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "create_schema", "macro_sql": "{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_schema": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__create_schema", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__create_schema", "macro_sql": "{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.drop_schema": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.drop_schema", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "drop_schema", "macro_sql": "{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__drop_schema": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__drop_schema", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__drop_schema", "macro_sql": "{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_table_as": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.create_table_as", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "create_table_as", "macro_sql": "{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_table_as": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__create_table_as", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__create_table_as", "macro_sql": "{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_view_as": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.create_view_as", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "create_view_as", "macro_sql": "{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_view_as": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__create_view_as", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__create_view_as", "macro_sql": "{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_catalog": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.get_catalog", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "get_catalog", "macro_sql": "{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": ["macro.dbt.adapter_macro"]}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_catalog": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__get_catalog", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__get_catalog", "macro_sql": "{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_columns_in_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.get_columns_in_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "get_columns_in_relation", "macro_sql": "{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.sql_convert_columns_in_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.sql_convert_columns_in_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "sql_convert_columns_in_relation", "macro_sql": "{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_columns_in_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__get_columns_in_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__get_columns_in_relation", "macro_sql": "{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.alter_column_type": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.alter_column_type", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "alter_column_type", "macro_sql": "{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__alter_column_type": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__alter_column_type", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__alter_column_type", "macro_sql": "{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.drop_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.drop_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "drop_relation", "macro_sql": "{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__drop_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__drop_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__drop_relation", "macro_sql": "{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.truncate_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.truncate_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "truncate_relation", "macro_sql": "{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__truncate_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__truncate_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__truncate_relation", "macro_sql": "{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.rename_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.rename_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "rename_relation", "macro_sql": "{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__rename_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__rename_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__rename_relation", "macro_sql": "{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.information_schema_name": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.information_schema_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "information_schema_name", "macro_sql": "{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__information_schema_name": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__information_schema_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__information_schema_name", "macro_sql": "{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.list_schemas": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.list_schemas", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "list_schemas", "macro_sql": "{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__list_schemas": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__list_schemas", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__list_schemas", "macro_sql": "{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.check_schema_exists": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.check_schema_exists", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "check_schema_exists", "macro_sql": "{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__check_schema_exists": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__check_schema_exists", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__check_schema_exists", "macro_sql": "{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.list_relations_without_caching": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.list_relations_without_caching", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "list_relations_without_caching", "macro_sql": "{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__list_relations_without_caching": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__list_relations_without_caching", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__list_relations_without_caching", "macro_sql": "{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.current_timestamp": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.current_timestamp", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__current_timestamp": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__current_timestamp", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.collect_freshness": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.collect_freshness", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__collect_freshness": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__collect_freshness", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.make_temp_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.make_temp_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "make_temp_relation", "macro_sql": "{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__make_temp_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__make_temp_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__make_temp_relation", "macro_sql": "{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.set_sql_header": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.set_sql_header", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "set_sql_header", "macro_sql": "{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.test_relationships": {"raw_sql": "{% macro test_relationships(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nselect count(*)\nfrom (\n    select {{ column_name }} as id from {{ model }}\n) as child\nleft join (\n    select {{ field }} as id from {{ to }}\n) as parent on parent.id = child.id\nwhere child.id is not null\n  and parent.id is null\n\n{% endmacro %}", "unique_id": "macro.dbt.test_relationships", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/schema_tests/relationships.sql", "original_file_path": "macros/schema_tests/relationships.sql", "resource_type": "macro", "name": "test_relationships", "macro_sql": "{% macro test_relationships(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nselect count(*)\nfrom (\n    select {{ column_name }} as id from {{ model }}\n) as child\nleft join (\n    select {{ field }} as id from {{ to }}\n) as parent on parent.id = child.id\nwhere child.id is not null\n  and parent.id is null\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.test_not_null": {"raw_sql": "{% macro test_not_null(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "unique_id": "macro.dbt.test_not_null", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/schema_tests/not_null.sql", "original_file_path": "macros/schema_tests/not_null.sql", "resource_type": "macro", "name": "test_not_null", "macro_sql": "{% macro test_not_null(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.test_unique": {"raw_sql": "{% macro test_unique(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom (\n\n    select\n        {{ column_name }}\n\n    from {{ model }}\n    where {{ column_name }} is not null\n    group by {{ column_name }}\n    having count(*) > 1\n\n) validation_errors\n\n{% endmacro %}", "unique_id": "macro.dbt.test_unique", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/schema_tests/unique.sql", "original_file_path": "macros/schema_tests/unique.sql", "resource_type": "macro", "name": "test_unique", "macro_sql": "{% macro test_unique(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom (\n\n    select\n        {{ column_name }}\n\n    from {{ model }}\n    where {{ column_name }} is not null\n    group by {{ column_name }}\n    having count(*) > 1\n\n) validation_errors\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.test_accepted_values": {"raw_sql": "{% macro test_accepted_values(model, values) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n{% set quote_values = kwargs.get('quote', True) %}\n\nwith all_values as (\n\n    select distinct\n        {{ column_name }} as value_field\n\n    from {{ model }}\n\n),\n\nvalidation_errors as (\n\n    select\n        value_field\n\n    from all_values\n    where value_field not in (\n        {% for value in values -%}\n            {% if quote_values -%}\n            '{{ value }}'\n            {%- else -%}\n            {{ value }}\n            {%- endif -%}\n            {%- if not loop.last -%},{%- endif %}\n        {%- endfor %}\n    )\n)\n\nselect count(*)\nfrom validation_errors\n\n{% endmacro %}", "unique_id": "macro.dbt.test_accepted_values", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/schema_tests/accepted_values.sql", "original_file_path": "macros/schema_tests/accepted_values.sql", "resource_type": "macro", "name": "test_accepted_values", "macro_sql": "{% macro test_accepted_values(model, values) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n{% set quote_values = kwargs.get('quote', True) %}\n\nwith all_values as (\n\n    select distinct\n        {{ column_name }} as value_field\n\n    from {{ model }}\n\n),\n\nvalidation_errors as (\n\n    select\n        value_field\n\n    from all_values\n    where value_field not in (\n        {% for value in values -%}\n            {% if quote_values -%}\n            '{{ value }}'\n            {%- else -%}\n            {{ value }}\n            {%- endif -%}\n            {%- if not loop.last -%},{%- endif %}\n        {%- endfor %}\n    )\n)\n\nselect count(*)\nfrom validation_errors\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.date_sharded_table": {"raw_sql": "{% macro date_sharded_table(base_name) %}\n    {{ return(base_name ~ \"[DBT__PARTITION_DATE]\") }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.date_sharded_table", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/etc.sql", "original_file_path": "macros/etc.sql", "resource_type": "macro", "name": "date_sharded_table", "macro_sql": "{% macro date_sharded_table(base_name) %}\n    {{ return(base_name ~ \"[DBT__PARTITION_DATE]\") }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__get_catalog": {"raw_sql": "{% macro bigquery__get_catalog(information_schema, schemas) -%}\n\n  {%- if (schemas | length) == 0 -%}\n    {# Hopefully nothing cares about the columns we return when there are no rows #}\n    {%- set query  = \"select 1 as id limit 0\" -%}\n  {%- else -%}\n\n  {%- set query -%}\n    with schemas as (\n\n        select\n          catalog_name as table_database,\n          schema_name as table_schema,\n          location\n\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where (\n          {%- for schema in schemas -%}\n            upper(schema_name) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n          {%- endfor -%}\n        )\n    ),\n\n    tables as (\n        select\n            project_id as table_database,\n            dataset_id as table_schema,\n            table_id as original_table_name,\n\n            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,\n\n            row_count,\n            size_bytes as size_bytes,\n            case\n                when type = 1 then 'table'\n                when type = 2 then 'view'\n                else 'external'\n            end as table_type,\n\n            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,\n            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,\n            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name\n\n        from {{ information_schema.replace(information_schema_view='__TABLES__') }}\n\n    ),\n\n    extracted as (\n\n        select *,\n            case\n                when is_date_shard then shard_base_name\n                else original_table_name\n            end as table_name\n\n        from tables\n\n    ),\n\n    unsharded_tables as (\n\n        select\n            table_database,\n            table_schema,\n            table_name,\n            coalesce(table_type, 'external') as table_type,\n            is_date_shard,\n\n            struct(\n                min(shard_name) as shard_min,\n                max(shard_name) as shard_max,\n                count(*) as shard_count\n            ) as table_shards,\n\n            sum(size_bytes) as size_bytes,\n            sum(row_count) as row_count,\n\n            max(relation_id) as relation_id\n\n        from extracted\n        group by 1,2,3,4,5\n\n    ),\n\n    info_schema_columns as (\n\n        select\n            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,\n            table_catalog as table_database,\n            table_schema,\n            table_name,\n\n            -- use the \"real\" column name from the paths query below\n            column_name as base_column_name,\n            ordinal_position as column_index,\n            cast(null as string) as column_comment,\n\n            is_partitioning_column,\n            clustering_ordinal_position\n\n        from {{ information_schema.replace(information_schema_view='COLUMNS') }}\n        where ordinal_position is not null\n\n    ),\n\n    info_schema_column_paths as (\n\n        select\n            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,\n            field_path as column_name,\n            data_type as column_type,\n            column_name as base_column_name\n\n        from {{ information_schema.replace(information_schema_view='COLUMN_FIELD_PATHS') }}\n        where data_type not like 'STRUCT%'\n\n    ),\n\n    columns as (\n\n        select * except (base_column_name)\n        from info_schema_columns\n        join info_schema_column_paths using (relation_id, base_column_name)\n\n    ),\n\n    column_stats as (\n\n        select\n            table_database,\n            table_schema,\n            table_name,\n            max(relation_id) as relation_id,\n            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,\n            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,\n            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,\n            array_to_string(\n                array_agg(\n                    case\n                        when clustering_ordinal_position is not null then column_name\n                        else null\n                    end ignore nulls\n                    order by clustering_ordinal_position\n                ), ', '\n            ) as clustering_columns\n\n        from columns\n        group by 1,2,3\n\n    )\n\n    select\n        unsharded_tables.table_database,\n        unsharded_tables.table_schema,\n        case\n            when is_date_shard then concat(unsharded_tables.table_name, '*')\n            else unsharded_tables.table_name\n        end as table_name,\n        unsharded_tables.table_type,\n\n        -- coalesce name and type for External tables - these columns are not\n        -- present in the COLUMN_FIELD_PATHS resultset\n        coalesce(columns.column_name, '<unknown>') as column_name,\n        -- invent a row number to account for nested fields -- BQ does\n        -- not treat these nested properties as independent fields\n        row_number() over (\n            partition by relation_id\n            order by columns.column_index, columns.column_name\n        ) as column_index,\n        coalesce(columns.column_type, '<unknown>') as column_type,\n        columns.column_comment,\n\n        'Location' as `stats__location__label`,\n        location as `stats__location__value`,\n        'The geographic location of this table' as `stats__location__description`,\n        location is not null as `stats__location__include`,\n\n        'Shard count' as `stats__date_shards__label`,\n        table_shards.shard_count as `stats__date_shards__value`,\n        'The number of date shards in this table' as `stats__date_shards__description`,\n        is_date_shard as `stats__date_shards__include`,\n\n        'Shard (min)' as `stats__date_shard_min__label`,\n        table_shards.shard_min as `stats__date_shard_min__value`,\n        'The first date shard in this table' as `stats__date_shard_min__description`,\n        is_date_shard as `stats__date_shard_min__include`,\n\n        'Shard (max)' as `stats__date_shard_max__label`,\n        table_shards.shard_max as `stats__date_shard_max__value`,\n        'The last date shard in this table' as `stats__date_shard_max__description`,\n        is_date_shard as `stats__date_shard_max__include`,\n\n        '# Rows' as `stats__num_rows__label`,\n        row_count as `stats__num_rows__value`,\n        'Approximate count of rows in this table' as `stats__num_rows__description`,\n        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,\n\n        'Approximate Size' as `stats__num_bytes__label`,\n        size_bytes as `stats__num_bytes__value`,\n        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,\n        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,\n\n        'Partitioned By' as `stats__partitioning_type__label`,\n        partition_column as `stats__partitioning_type__value`,\n        'The partitioning column for this table' as `stats__partitioning_type__description`,\n        is_partitioned as `stats__partitioning_type__include`,\n\n        'Clustered By' as `stats__clustering_fields__label`,\n        clustering_columns as `stats__clustering_fields__value`,\n        'The clustering columns for this table' as `stats__clustering_fields__description`,\n        is_clustered as `stats__clustering_fields__include`\n\n    -- join using relation_id (an actual relation, not a shard prefix) to make\n    -- sure that column metadata is picked up through the join. This will only\n    -- return the column information for the \"max\" table in a date-sharded table set\n    from unsharded_tables\n    left join schemas using(table_database, table_schema)\n    left join columns using (relation_id)\n    left join column_stats using (relation_id)\n  {%- endset -%}\n\n  {%- endif -%}\n\n  {{ return(run_query(query)) }}\n\n{%- endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__get_catalog", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "resource_type": "macro", "name": "bigquery__get_catalog", "macro_sql": "{% macro bigquery__get_catalog(information_schema, schemas) -%}\n\n  {%- if (schemas | length) == 0 -%}\n    {# Hopefully nothing cares about the columns we return when there are no rows #}\n    {%- set query  = \"select 1 as id limit 0\" -%}\n  {%- else -%}\n\n  {%- set query -%}\n    with schemas as (\n\n        select\n          catalog_name as table_database,\n          schema_name as table_schema,\n          location\n\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where (\n          {%- for schema in schemas -%}\n            upper(schema_name) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n          {%- endfor -%}\n        )\n    ),\n\n    tables as (\n        select\n            project_id as table_database,\n            dataset_id as table_schema,\n            table_id as original_table_name,\n\n            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,\n\n            row_count,\n            size_bytes as size_bytes,\n            case\n                when type = 1 then 'table'\n                when type = 2 then 'view'\n                else 'external'\n            end as table_type,\n\n            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,\n            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,\n            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name\n\n        from {{ information_schema.replace(information_schema_view='__TABLES__') }}\n\n    ),\n\n    extracted as (\n\n        select *,\n            case\n                when is_date_shard then shard_base_name\n                else original_table_name\n            end as table_name\n\n        from tables\n\n    ),\n\n    unsharded_tables as (\n\n        select\n            table_database,\n            table_schema,\n            table_name,\n            coalesce(table_type, 'external') as table_type,\n            is_date_shard,\n\n            struct(\n                min(shard_name) as shard_min,\n                max(shard_name) as shard_max,\n                count(*) as shard_count\n            ) as table_shards,\n\n            sum(size_bytes) as size_bytes,\n            sum(row_count) as row_count,\n\n            max(relation_id) as relation_id\n\n        from extracted\n        group by 1,2,3,4,5\n\n    ),\n\n    info_schema_columns as (\n\n        select\n            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,\n            table_catalog as table_database,\n            table_schema,\n            table_name,\n\n            -- use the \"real\" column name from the paths query below\n            column_name as base_column_name,\n            ordinal_position as column_index,\n            cast(null as string) as column_comment,\n\n            is_partitioning_column,\n            clustering_ordinal_position\n\n        from {{ information_schema.replace(information_schema_view='COLUMNS') }}\n        where ordinal_position is not null\n\n    ),\n\n    info_schema_column_paths as (\n\n        select\n            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,\n            field_path as column_name,\n            data_type as column_type,\n            column_name as base_column_name\n\n        from {{ information_schema.replace(information_schema_view='COLUMN_FIELD_PATHS') }}\n        where data_type not like 'STRUCT%'\n\n    ),\n\n    columns as (\n\n        select * except (base_column_name)\n        from info_schema_columns\n        join info_schema_column_paths using (relation_id, base_column_name)\n\n    ),\n\n    column_stats as (\n\n        select\n            table_database,\n            table_schema,\n            table_name,\n            max(relation_id) as relation_id,\n            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,\n            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,\n            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,\n            array_to_string(\n                array_agg(\n                    case\n                        when clustering_ordinal_position is not null then column_name\n                        else null\n                    end ignore nulls\n                    order by clustering_ordinal_position\n                ), ', '\n            ) as clustering_columns\n\n        from columns\n        group by 1,2,3\n\n    )\n\n    select\n        unsharded_tables.table_database,\n        unsharded_tables.table_schema,\n        case\n            when is_date_shard then concat(unsharded_tables.table_name, '*')\n            else unsharded_tables.table_name\n        end as table_name,\n        unsharded_tables.table_type,\n\n        -- coalesce name and type for External tables - these columns are not\n        -- present in the COLUMN_FIELD_PATHS resultset\n        coalesce(columns.column_name, '<unknown>') as column_name,\n        -- invent a row number to account for nested fields -- BQ does\n        -- not treat these nested properties as independent fields\n        row_number() over (\n            partition by relation_id\n            order by columns.column_index, columns.column_name\n        ) as column_index,\n        coalesce(columns.column_type, '<unknown>') as column_type,\n        columns.column_comment,\n\n        'Location' as `stats__location__label`,\n        location as `stats__location__value`,\n        'The geographic location of this table' as `stats__location__description`,\n        location is not null as `stats__location__include`,\n\n        'Shard count' as `stats__date_shards__label`,\n        table_shards.shard_count as `stats__date_shards__value`,\n        'The number of date shards in this table' as `stats__date_shards__description`,\n        is_date_shard as `stats__date_shards__include`,\n\n        'Shard (min)' as `stats__date_shard_min__label`,\n        table_shards.shard_min as `stats__date_shard_min__value`,\n        'The first date shard in this table' as `stats__date_shard_min__description`,\n        is_date_shard as `stats__date_shard_min__include`,\n\n        'Shard (max)' as `stats__date_shard_max__label`,\n        table_shards.shard_max as `stats__date_shard_max__value`,\n        'The last date shard in this table' as `stats__date_shard_max__description`,\n        is_date_shard as `stats__date_shard_max__include`,\n\n        '# Rows' as `stats__num_rows__label`,\n        row_count as `stats__num_rows__value`,\n        'Approximate count of rows in this table' as `stats__num_rows__description`,\n        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,\n\n        'Approximate Size' as `stats__num_bytes__label`,\n        size_bytes as `stats__num_bytes__value`,\n        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,\n        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,\n\n        'Partitioned By' as `stats__partitioning_type__label`,\n        partition_column as `stats__partitioning_type__value`,\n        'The partitioning column for this table' as `stats__partitioning_type__description`,\n        is_partitioned as `stats__partitioning_type__include`,\n\n        'Clustered By' as `stats__clustering_fields__label`,\n        clustering_columns as `stats__clustering_fields__value`,\n        'The clustering columns for this table' as `stats__clustering_fields__description`,\n        is_clustered as `stats__clustering_fields__include`\n\n    -- join using relation_id (an actual relation, not a shard prefix) to make\n    -- sure that column metadata is picked up through the join. This will only\n    -- return the column information for the \"max\" table in a date-sharded table set\n    from unsharded_tables\n    left join schemas using(table_database, table_schema)\n    left join columns using (relation_id)\n    left join column_stats using (relation_id)\n  {%- endset -%}\n\n  {%- endif -%}\n\n  {{ return(run_query(query)) }}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.partition_by": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.partition_by", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "partition_by", "macro_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.cluster_by": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.cluster_by", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "cluster_by", "macro_sql": "{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery_table_options": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery_table_options", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery_table_options", "macro_sql": "{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__create_table_as": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__create_table_as", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__create_table_as", "macro_sql": "{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__create_view_as": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__create_view_as", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__create_view_as", "macro_sql": "{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__create_schema": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__create_schema", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__create_schema", "macro_sql": "{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__drop_schema": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__drop_schema", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__drop_schema", "macro_sql": "{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__drop_relation": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__drop_relation", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__drop_relation", "macro_sql": "{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__get_columns_in_relation": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__get_columns_in_relation", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__get_columns_in_relation", "macro_sql": "{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__list_relations_without_caching": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__list_relations_without_caching", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__list_relations_without_caching", "macro_sql": "{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__current_timestamp": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__current_timestamp", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__current_timestamp", "macro_sql": "{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__snapshot_string_as_time": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__snapshot_string_as_time", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__snapshot_string_as_time", "macro_sql": "{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__list_schemas": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__list_schemas", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__list_schemas", "macro_sql": "{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__check_schema_exists": {"raw_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n{% macro bigquery_table_options(persist_docs, temporary, kms_key_name, labels) %}\n  {% set opts = {} -%}\n\n  {%- set description = get_relation_comment(persist_docs, model) -%}\n  {%- if description is not none -%}\n    {%- do opts.update({'description': \"'\" ~ description ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if temporary -%}\n    {% do opts.update({'expiration_timestamp': 'TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)'}) %}\n  {%- endif -%}\n  {%- if kms_key_name -%}\n    {%- do opts.update({'kms_key_name': \"'\" ~ kms_key_name ~ \"'\"}) -%}\n  {%- endif -%}\n  {%- if labels -%}\n    {%- set label_list = [] -%}\n    {%- for label, value in labels.items() -%}\n      {%- do label_list.append((label, value)) -%}\n    {%- endfor -%}\n    {%- do opts.update({'labels': label_list}) -%}\n  {%- endif -%}\n\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_kms_key_name = config.get('kms_key_name', none) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(\n      persist_docs=raw_persist_docs,\n      temporary=temporary,\n      kms_key_name=raw_kms_key_name,\n      labels=raw_labels\n  ) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- set raw_labels = config.get('labels', []) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_table_options(persist_docs=raw_persist_docs, temporary=false, labels=raw_labels) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro bigquery__create_schema(database_name, schema_name) -%}\n  {{ adapter.create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_schema(database_name, schema_name) -%}\n  {{ adapter.drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}\n\n\n{% macro bigquery__list_relations_without_caching(information_schema, schema) -%}\n  {{ return(adapter.list_relations_without_caching(information_schema, schema)) }}\n{%- endmacro %}\n\n\n{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}\n\n\n{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas()) }}\n{% endmacro %}\n\n\n{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__check_schema_exists", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "bigquery__check_schema_exists", "macro_sql": "{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__create_csv_table": {"raw_sql": "{% macro bigquery__create_csv_table(model, agate_table) %}\n    -- no-op\n{% endmacro %}\n\n{% macro bigquery__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}\n\n{% macro bigquery__load_csv_rows(model, agate_table) %}\n\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {{ adapter.load_dataframe(model['database'], model['schema'], model['alias'],\n  \t\t\t\t\t\t\tagate_table, column_override) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__create_csv_table", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "resource_type": "macro", "name": "bigquery__create_csv_table", "macro_sql": "{% macro bigquery__create_csv_table(model, agate_table) %}\n    -- no-op\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__reset_csv_table": {"raw_sql": "{% macro bigquery__create_csv_table(model, agate_table) %}\n    -- no-op\n{% endmacro %}\n\n{% macro bigquery__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}\n\n{% macro bigquery__load_csv_rows(model, agate_table) %}\n\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {{ adapter.load_dataframe(model['database'], model['schema'], model['alias'],\n  \t\t\t\t\t\t\tagate_table, column_override) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__reset_csv_table", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "resource_type": "macro", "name": "bigquery__reset_csv_table", "macro_sql": "{% macro bigquery__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__load_csv_rows": {"raw_sql": "{% macro bigquery__create_csv_table(model, agate_table) %}\n    -- no-op\n{% endmacro %}\n\n{% macro bigquery__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}\n\n{% macro bigquery__load_csv_rows(model, agate_table) %}\n\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {{ adapter.load_dataframe(model['database'], model['schema'], model['alias'],\n  \t\t\t\t\t\t\tagate_table, column_override) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__load_csv_rows", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "resource_type": "macro", "name": "bigquery__load_csv_rows", "macro_sql": "{% macro bigquery__load_csv_rows(model, agate_table) %}\n\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {{ adapter.load_dataframe(model['database'], model['schema'], model['alias'],\n  \t\t\t\t\t\t\tagate_table, column_override) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__handle_existing_table": {"raw_sql": "{% macro bigquery__handle_existing_table(full_refresh, old_relation) %}\n    {%- if full_refresh -%}\n      {{ adapter.drop_relation(old_relation) }}\n    {%- else -%}\n      {{ exceptions.relation_wrong_type(old_relation, 'view') }}\n    {%- endif -%}\n{% endmacro %}\n\n\n{% materialization view, adapter='bigquery' -%}\n    {{ return(create_or_replace_view(run_outside_transaction_hooks=False)) }}\n{%- endmaterialization %}", "unique_id": "macro.dbt_bigquery.bigquery__handle_existing_table", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "resource_type": "macro", "name": "bigquery__handle_existing_table", "macro_sql": "{% macro bigquery__handle_existing_table(full_refresh, old_relation) %}\n    {%- if full_refresh -%}\n      {{ adapter.drop_relation(old_relation) }}\n    {%- else -%}\n      {{ exceptions.relation_wrong_type(old_relation, 'view') }}\n    {%- endif -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.materialization_view_bigquery": {"raw_sql": "{% macro bigquery__handle_existing_table(full_refresh, old_relation) %}\n    {%- if full_refresh -%}\n      {{ adapter.drop_relation(old_relation) }}\n    {%- else -%}\n      {{ exceptions.relation_wrong_type(old_relation, 'view') }}\n    {%- endif -%}\n{% endmacro %}\n\n\n{% materialization view, adapter='bigquery' -%}\n    {{ return(create_or_replace_view(run_outside_transaction_hooks=False)) }}\n{%- endmaterialization %}", "unique_id": "macro.dbt_bigquery.materialization_view_bigquery", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "resource_type": "macro", "name": "materialization_view_bigquery", "macro_sql": "{% materialization view, adapter='bigquery' -%}\n    {{ return(create_or_replace_view(run_outside_transaction_hooks=False)) }}\n{%- endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.make_date_partitioned_table": {"raw_sql": "{% macro make_date_partitioned_table(model, relation, dates, should_create, verbose=False) %}\n\n  {% if should_create %}\n      {{ adapter.make_date_partitioned_table(relation) }}\n  {% endif %}\n\n  {% for date in dates %}\n    {% set date = (date | string) %}\n    {% if verbose %}\n        {% set table_start_time = modules.datetime.datetime.now().strftime(\"%H:%M:%S\") %}\n        {{ log(table_start_time ~ ' | -> Running for day ' ~ date, info=True) }}\n    {% endif %}\n\n    {% set fixed_sql = model['injected_sql'] | replace('[DBT__PARTITION_DATE]', date) %}\n    {% set _ = adapter.execute_model(model, 'table', fixed_sql, decorator=date) %}\n  {% endfor %}\n\n  {% set num_days = dates | length %}\n  {% if num_days == 1 %}\n      {% set result_str = 'CREATED 1 PARTITION' %}\n  {% else %}\n      {% set result_str = 'CREATED ' ~ num_days ~ ' PARTITIONS' %}\n  {% endif %}\n\n  {{ store_result('main', status=result_str) }}\n\n{% endmacro %}\n\n{% materialization table, adapter='bigquery' -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n  {%- set target_relation = api.Relation.create(database=database, schema=schema, identifier=identifier, type='table') -%}\n  {%- set verbose = config.get('verbose', False) -%}\n\n  {# partitions: iterate over each partition, running a separate query in a for-loop #}\n  {%- set partitions = config.get('partitions') -%}\n\n  {% if partitions %}\n      {% if partitions is number or partitions is string %}\n        {% set partitions = [(partitions | string)] %}\n      {% endif %}\n\n      {% if partitions is not iterable %}\n        {{ exceptions.raise_compiler_error(\"Provided `partitions` configuration is not a list. Got: \" ~ partitions, model) }}\n      {% endif %}\n  {% endif %}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {#\n      Since dbt uses WRITE_TRUNCATE mode for tables, we only need to drop this thing\n      if it is not a table. If it _is_ already a table, then we can overwrite it without downtime\n  #}\n  {%- if exists_not_as_table -%}\n      {{ adapter.drop_relation(old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% if partitions %}\n    {# Create the dp-table if 1. it does not exist or 2. it existed, but we just dropped it #}\n    {%- set should_create = (old_relation is none or exists_not_as_table) -%}\n    {{ make_date_partitioned_table(model, target_relation, partitions, should_create, verbose) }}\n  {% else %}\n    {%- set raw_partition_by = config.get('partition_by', none) -%}\n    {%- set partition_by = adapter.parse_partition_by(raw_partition_by) -%}\n    {%- set cluster_by = config.get('cluster_by', none) -%}\n    {% if not adapter.is_replaceable(old_relation, partition_by, cluster_by) %}\n      {% do log(\"Hard refreshing \" ~ old_relation ~ \" because it is not replaceable\") %}\n      {% do adapter.drop_relation(old_relation) %}\n    {% endif %}\n    {% call statement('main') -%}\n      {{ create_table_as(False, target_relation, sql) }}\n    {% endcall -%}\n  {% endif %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt_bigquery.make_date_partitioned_table", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "resource_type": "macro", "name": "make_date_partitioned_table", "macro_sql": "{% macro make_date_partitioned_table(model, relation, dates, should_create, verbose=False) %}\n\n  {% if should_create %}\n      {{ adapter.make_date_partitioned_table(relation) }}\n  {% endif %}\n\n  {% for date in dates %}\n    {% set date = (date | string) %}\n    {% if verbose %}\n        {% set table_start_time = modules.datetime.datetime.now().strftime(\"%H:%M:%S\") %}\n        {{ log(table_start_time ~ ' | -> Running for day ' ~ date, info=True) }}\n    {% endif %}\n\n    {% set fixed_sql = model['injected_sql'] | replace('[DBT__PARTITION_DATE]', date) %}\n    {% set _ = adapter.execute_model(model, 'table', fixed_sql, decorator=date) %}\n  {% endfor %}\n\n  {% set num_days = dates | length %}\n  {% if num_days == 1 %}\n      {% set result_str = 'CREATED 1 PARTITION' %}\n  {% else %}\n      {% set result_str = 'CREATED ' ~ num_days ~ ' PARTITIONS' %}\n  {% endif %}\n\n  {{ store_result('main', status=result_str) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.materialization_table_bigquery": {"raw_sql": "{% macro make_date_partitioned_table(model, relation, dates, should_create, verbose=False) %}\n\n  {% if should_create %}\n      {{ adapter.make_date_partitioned_table(relation) }}\n  {% endif %}\n\n  {% for date in dates %}\n    {% set date = (date | string) %}\n    {% if verbose %}\n        {% set table_start_time = modules.datetime.datetime.now().strftime(\"%H:%M:%S\") %}\n        {{ log(table_start_time ~ ' | -> Running for day ' ~ date, info=True) }}\n    {% endif %}\n\n    {% set fixed_sql = model['injected_sql'] | replace('[DBT__PARTITION_DATE]', date) %}\n    {% set _ = adapter.execute_model(model, 'table', fixed_sql, decorator=date) %}\n  {% endfor %}\n\n  {% set num_days = dates | length %}\n  {% if num_days == 1 %}\n      {% set result_str = 'CREATED 1 PARTITION' %}\n  {% else %}\n      {% set result_str = 'CREATED ' ~ num_days ~ ' PARTITIONS' %}\n  {% endif %}\n\n  {{ store_result('main', status=result_str) }}\n\n{% endmacro %}\n\n{% materialization table, adapter='bigquery' -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n  {%- set target_relation = api.Relation.create(database=database, schema=schema, identifier=identifier, type='table') -%}\n  {%- set verbose = config.get('verbose', False) -%}\n\n  {# partitions: iterate over each partition, running a separate query in a for-loop #}\n  {%- set partitions = config.get('partitions') -%}\n\n  {% if partitions %}\n      {% if partitions is number or partitions is string %}\n        {% set partitions = [(partitions | string)] %}\n      {% endif %}\n\n      {% if partitions is not iterable %}\n        {{ exceptions.raise_compiler_error(\"Provided `partitions` configuration is not a list. Got: \" ~ partitions, model) }}\n      {% endif %}\n  {% endif %}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {#\n      Since dbt uses WRITE_TRUNCATE mode for tables, we only need to drop this thing\n      if it is not a table. If it _is_ already a table, then we can overwrite it without downtime\n  #}\n  {%- if exists_not_as_table -%}\n      {{ adapter.drop_relation(old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% if partitions %}\n    {# Create the dp-table if 1. it does not exist or 2. it existed, but we just dropped it #}\n    {%- set should_create = (old_relation is none or exists_not_as_table) -%}\n    {{ make_date_partitioned_table(model, target_relation, partitions, should_create, verbose) }}\n  {% else %}\n    {%- set raw_partition_by = config.get('partition_by', none) -%}\n    {%- set partition_by = adapter.parse_partition_by(raw_partition_by) -%}\n    {%- set cluster_by = config.get('cluster_by', none) -%}\n    {% if not adapter.is_replaceable(old_relation, partition_by, cluster_by) %}\n      {% do log(\"Hard refreshing \" ~ old_relation ~ \" because it is not replaceable\") %}\n      {% do adapter.drop_relation(old_relation) %}\n    {% endif %}\n    {% call statement('main') -%}\n      {{ create_table_as(False, target_relation, sql) }}\n    {% endcall -%}\n  {% endif %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt_bigquery.materialization_table_bigquery", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "resource_type": "macro", "name": "materialization_table_bigquery", "macro_sql": "{% materialization table, adapter='bigquery' -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n  {%- set target_relation = api.Relation.create(database=database, schema=schema, identifier=identifier, type='table') -%}\n  {%- set verbose = config.get('verbose', False) -%}\n\n  {# partitions: iterate over each partition, running a separate query in a for-loop #}\n  {%- set partitions = config.get('partitions') -%}\n\n  {% if partitions %}\n      {% if partitions is number or partitions is string %}\n        {% set partitions = [(partitions | string)] %}\n      {% endif %}\n\n      {% if partitions is not iterable %}\n        {{ exceptions.raise_compiler_error(\"Provided `partitions` configuration is not a list. Got: \" ~ partitions, model) }}\n      {% endif %}\n  {% endif %}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {#\n      Since dbt uses WRITE_TRUNCATE mode for tables, we only need to drop this thing\n      if it is not a table. If it _is_ already a table, then we can overwrite it without downtime\n  #}\n  {%- if exists_not_as_table -%}\n      {{ adapter.drop_relation(old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% if partitions %}\n    {# Create the dp-table if 1. it does not exist or 2. it existed, but we just dropped it #}\n    {%- set should_create = (old_relation is none or exists_not_as_table) -%}\n    {{ make_date_partitioned_table(model, target_relation, partitions, should_create, verbose) }}\n  {% else %}\n    {%- set raw_partition_by = config.get('partition_by', none) -%}\n    {%- set partition_by = adapter.parse_partition_by(raw_partition_by) -%}\n    {%- set cluster_by = config.get('cluster_by', none) -%}\n    {% if not adapter.is_replaceable(old_relation, partition_by, cluster_by) %}\n      {% do log(\"Hard refreshing \" ~ old_relation ~ \" because it is not replaceable\") %}\n      {% do adapter.drop_relation(old_relation) %}\n    {% endif %}\n    {% call statement('main') -%}\n      {{ create_table_as(False, target_relation, sql) }}\n    {% endcall -%}\n  {% endif %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.dbt_bigquery_validate_get_incremental_strategy": {"raw_sql": "{% macro dbt_bigquery_validate_get_incremental_strategy(config) %}\n  {#-- Find and validate the incremental strategy #}\n  {%- set strategy = config.get(\"incremental_strategy\", default=\"merge\") -%}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ strategy }}\n    Expected one of: 'merge', 'insert_overwrite'\n  {%- endset %}\n  {% if strategy not in ['merge', 'insert_overwrite'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {% endif %}\n\n  {% do return(strategy) %}\n{% endmacro %}\n\n\n{% macro bq_insert_overwrite(tmp_relation, target_relation, sql, unique_key, partition_by, partitions, dest_columns) %}\n  {%- set partition_type =\n      'date' if partition_by.data_type in ('timestamp, datetime') \n      else partition_by.data_type -%}\n\n  {% if partitions is not none and partitions != [] %} {# static #}\n  \n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in (\n              {{ partitions | join (', ') }}\n          )\n      {%- endset %}\n\n      {%- set source_sql -%}\n        (\n          {{sql}}\n        )\n      {%- endset -%}\n      \n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate]) }}\n  \n  {% else %} {# dynamic #}\n  \n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in unnest(dbt_partitions_for_replacement)\n      {%- endset %}\n\n      {%- set source_sql -%}\n      (\n        select * from {{ tmp_relation }}\n      )\n      {%- endset -%}\n\n      -- generated script to merge partitions into {{ target_relation }}\n      declare dbt_partitions_for_replacement array<{{ partition_type }}>;\n      declare _dbt_max_partition {{ partition_by.data_type }};\n\n      set _dbt_max_partition = (\n          select max({{ partition_by.field }}) from {{ this }}\n      );\n\n      -- 1. create a temp table\n      {{ create_table_as(True, tmp_relation, sql) }}\n\n      -- 2. define partitions to update\n      set (dbt_partitions_for_replacement) = (\n          select as struct\n              array_agg(distinct {{ partition_by.render() }})\n          from {{ tmp_relation }}\n      );\n      \n      -- 3. run the merge statement\n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate]) }};\n\n      -- 4. clean up the temp table\n      drop table if exists {{ tmp_relation }}\n  \n  {% endif %}\n\n{% endmacro %}\n\n\n{% materialization incremental, adapter='bigquery' -%}\n\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set target_relation = this %}\n  {%- set existing_relation = load_relation(this) %}\n  {%- set tmp_relation = make_temp_relation(this) %}\n  \n  {#-- Validate early so we don't run SQL if the strategy is invalid --#}\n  {% set strategy = dbt_bigquery_validate_get_incremental_strategy(config) -%}\n\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set partition_by = adapter.parse_partition_by(raw_partition_by) -%}\n  {%- set partitions = config.get('partitions', none) -%}\n  {%- set cluster_by = config.get('cluster_by', none) -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view %}\n      {#-- There's no way to atomically replace a view with a table on BQ --#}\n      {{ adapter.drop_relation(existing_relation) }}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif full_refresh_mode %}\n      {#-- If the partition/cluster config has changed, then we must drop and recreate --#}\n      {% if not adapter.is_replaceable(existing_relation, partition_by, cluster_by) %}\n          {% do log(\"Hard refreshing \" ~ existing_relation ~ \" because it is not replaceable\") %}\n          {{ adapter.drop_relation(existing_relation) }}\n      {% endif %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% else %}\n     {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n\n     {#-- if partitioned, use BQ scripting to get the range of partition values to be updated --#}\n     {% if strategy == 'insert_overwrite' %}\n     \n        {% set missing_partition_msg -%}\n          The 'insert_overwrite' strategy requires the `partition_by` config.\n        {%- endset %}\n        {% if partition_by is none %}\n          {% do exceptions.raise_compiler_error(missing_partition_msg) %}\n        {% endif %}\n        \n        {% set build_sql = bq_insert_overwrite(\n            tmp_relation,\n            target_relation,\n            sql,\n            unique_key,\n            partition_by,\n            partitions,\n            dest_columns) %}\n\n     {% else %}\n       {#-- wrap sql in parens to make it a subquery --#}\n       {%- set source_sql -%}\n         (\n           {{sql}}\n         )\n       {%- endset -%}\n\n       {% set build_sql = get_merge_sql(target_relation, source_sql, unique_key, dest_columns) %}\n\n     {% endif %}\n\n  {% endif %}\n\n  {%- call statement('main') -%}\n    {{ build_sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt_bigquery.dbt_bigquery_validate_get_incremental_strategy", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/incremental.sql", "original_file_path": "macros/materializations/incremental.sql", "resource_type": "macro", "name": "dbt_bigquery_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_bigquery_validate_get_incremental_strategy(config) %}\n  {#-- Find and validate the incremental strategy #}\n  {%- set strategy = config.get(\"incremental_strategy\", default=\"merge\") -%}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ strategy }}\n    Expected one of: 'merge', 'insert_overwrite'\n  {%- endset %}\n  {% if strategy not in ['merge', 'insert_overwrite'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {% endif %}\n\n  {% do return(strategy) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bq_insert_overwrite": {"raw_sql": "{% macro dbt_bigquery_validate_get_incremental_strategy(config) %}\n  {#-- Find and validate the incremental strategy #}\n  {%- set strategy = config.get(\"incremental_strategy\", default=\"merge\") -%}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ strategy }}\n    Expected one of: 'merge', 'insert_overwrite'\n  {%- endset %}\n  {% if strategy not in ['merge', 'insert_overwrite'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {% endif %}\n\n  {% do return(strategy) %}\n{% endmacro %}\n\n\n{% macro bq_insert_overwrite(tmp_relation, target_relation, sql, unique_key, partition_by, partitions, dest_columns) %}\n  {%- set partition_type =\n      'date' if partition_by.data_type in ('timestamp, datetime') \n      else partition_by.data_type -%}\n\n  {% if partitions is not none and partitions != [] %} {# static #}\n  \n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in (\n              {{ partitions | join (', ') }}\n          )\n      {%- endset %}\n\n      {%- set source_sql -%}\n        (\n          {{sql}}\n        )\n      {%- endset -%}\n      \n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate]) }}\n  \n  {% else %} {# dynamic #}\n  \n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in unnest(dbt_partitions_for_replacement)\n      {%- endset %}\n\n      {%- set source_sql -%}\n      (\n        select * from {{ tmp_relation }}\n      )\n      {%- endset -%}\n\n      -- generated script to merge partitions into {{ target_relation }}\n      declare dbt_partitions_for_replacement array<{{ partition_type }}>;\n      declare _dbt_max_partition {{ partition_by.data_type }};\n\n      set _dbt_max_partition = (\n          select max({{ partition_by.field }}) from {{ this }}\n      );\n\n      -- 1. create a temp table\n      {{ create_table_as(True, tmp_relation, sql) }}\n\n      -- 2. define partitions to update\n      set (dbt_partitions_for_replacement) = (\n          select as struct\n              array_agg(distinct {{ partition_by.render() }})\n          from {{ tmp_relation }}\n      );\n      \n      -- 3. run the merge statement\n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate]) }};\n\n      -- 4. clean up the temp table\n      drop table if exists {{ tmp_relation }}\n  \n  {% endif %}\n\n{% endmacro %}\n\n\n{% materialization incremental, adapter='bigquery' -%}\n\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set target_relation = this %}\n  {%- set existing_relation = load_relation(this) %}\n  {%- set tmp_relation = make_temp_relation(this) %}\n  \n  {#-- Validate early so we don't run SQL if the strategy is invalid --#}\n  {% set strategy = dbt_bigquery_validate_get_incremental_strategy(config) -%}\n\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set partition_by = adapter.parse_partition_by(raw_partition_by) -%}\n  {%- set partitions = config.get('partitions', none) -%}\n  {%- set cluster_by = config.get('cluster_by', none) -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view %}\n      {#-- There's no way to atomically replace a view with a table on BQ --#}\n      {{ adapter.drop_relation(existing_relation) }}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif full_refresh_mode %}\n      {#-- If the partition/cluster config has changed, then we must drop and recreate --#}\n      {% if not adapter.is_replaceable(existing_relation, partition_by, cluster_by) %}\n          {% do log(\"Hard refreshing \" ~ existing_relation ~ \" because it is not replaceable\") %}\n          {{ adapter.drop_relation(existing_relation) }}\n      {% endif %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% else %}\n     {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n\n     {#-- if partitioned, use BQ scripting to get the range of partition values to be updated --#}\n     {% if strategy == 'insert_overwrite' %}\n     \n        {% set missing_partition_msg -%}\n          The 'insert_overwrite' strategy requires the `partition_by` config.\n        {%- endset %}\n        {% if partition_by is none %}\n          {% do exceptions.raise_compiler_error(missing_partition_msg) %}\n        {% endif %}\n        \n        {% set build_sql = bq_insert_overwrite(\n            tmp_relation,\n            target_relation,\n            sql,\n            unique_key,\n            partition_by,\n            partitions,\n            dest_columns) %}\n\n     {% else %}\n       {#-- wrap sql in parens to make it a subquery --#}\n       {%- set source_sql -%}\n         (\n           {{sql}}\n         )\n       {%- endset -%}\n\n       {% set build_sql = get_merge_sql(target_relation, source_sql, unique_key, dest_columns) %}\n\n     {% endif %}\n\n  {% endif %}\n\n  {%- call statement('main') -%}\n    {{ build_sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt_bigquery.bq_insert_overwrite", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/incremental.sql", "original_file_path": "macros/materializations/incremental.sql", "resource_type": "macro", "name": "bq_insert_overwrite", "macro_sql": "{% macro bq_insert_overwrite(tmp_relation, target_relation, sql, unique_key, partition_by, partitions, dest_columns) %}\n  {%- set partition_type =\n      'date' if partition_by.data_type in ('timestamp, datetime') \n      else partition_by.data_type -%}\n\n  {% if partitions is not none and partitions != [] %} {# static #}\n  \n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in (\n              {{ partitions | join (', ') }}\n          )\n      {%- endset %}\n\n      {%- set source_sql -%}\n        (\n          {{sql}}\n        )\n      {%- endset -%}\n      \n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate]) }}\n  \n  {% else %} {# dynamic #}\n  \n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in unnest(dbt_partitions_for_replacement)\n      {%- endset %}\n\n      {%- set source_sql -%}\n      (\n        select * from {{ tmp_relation }}\n      )\n      {%- endset -%}\n\n      -- generated script to merge partitions into {{ target_relation }}\n      declare dbt_partitions_for_replacement array<{{ partition_type }}>;\n      declare _dbt_max_partition {{ partition_by.data_type }};\n\n      set _dbt_max_partition = (\n          select max({{ partition_by.field }}) from {{ this }}\n      );\n\n      -- 1. create a temp table\n      {{ create_table_as(True, tmp_relation, sql) }}\n\n      -- 2. define partitions to update\n      set (dbt_partitions_for_replacement) = (\n          select as struct\n              array_agg(distinct {{ partition_by.render() }})\n          from {{ tmp_relation }}\n      );\n      \n      -- 3. run the merge statement\n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate]) }};\n\n      -- 4. clean up the temp table\n      drop table if exists {{ tmp_relation }}\n  \n  {% endif %}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.materialization_incremental_bigquery": {"raw_sql": "{% macro dbt_bigquery_validate_get_incremental_strategy(config) %}\n  {#-- Find and validate the incremental strategy #}\n  {%- set strategy = config.get(\"incremental_strategy\", default=\"merge\") -%}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ strategy }}\n    Expected one of: 'merge', 'insert_overwrite'\n  {%- endset %}\n  {% if strategy not in ['merge', 'insert_overwrite'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {% endif %}\n\n  {% do return(strategy) %}\n{% endmacro %}\n\n\n{% macro bq_insert_overwrite(tmp_relation, target_relation, sql, unique_key, partition_by, partitions, dest_columns) %}\n  {%- set partition_type =\n      'date' if partition_by.data_type in ('timestamp, datetime') \n      else partition_by.data_type -%}\n\n  {% if partitions is not none and partitions != [] %} {# static #}\n  \n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in (\n              {{ partitions | join (', ') }}\n          )\n      {%- endset %}\n\n      {%- set source_sql -%}\n        (\n          {{sql}}\n        )\n      {%- endset -%}\n      \n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate]) }}\n  \n  {% else %} {# dynamic #}\n  \n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in unnest(dbt_partitions_for_replacement)\n      {%- endset %}\n\n      {%- set source_sql -%}\n      (\n        select * from {{ tmp_relation }}\n      )\n      {%- endset -%}\n\n      -- generated script to merge partitions into {{ target_relation }}\n      declare dbt_partitions_for_replacement array<{{ partition_type }}>;\n      declare _dbt_max_partition {{ partition_by.data_type }};\n\n      set _dbt_max_partition = (\n          select max({{ partition_by.field }}) from {{ this }}\n      );\n\n      -- 1. create a temp table\n      {{ create_table_as(True, tmp_relation, sql) }}\n\n      -- 2. define partitions to update\n      set (dbt_partitions_for_replacement) = (\n          select as struct\n              array_agg(distinct {{ partition_by.render() }})\n          from {{ tmp_relation }}\n      );\n      \n      -- 3. run the merge statement\n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate]) }};\n\n      -- 4. clean up the temp table\n      drop table if exists {{ tmp_relation }}\n  \n  {% endif %}\n\n{% endmacro %}\n\n\n{% materialization incremental, adapter='bigquery' -%}\n\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set target_relation = this %}\n  {%- set existing_relation = load_relation(this) %}\n  {%- set tmp_relation = make_temp_relation(this) %}\n  \n  {#-- Validate early so we don't run SQL if the strategy is invalid --#}\n  {% set strategy = dbt_bigquery_validate_get_incremental_strategy(config) -%}\n\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set partition_by = adapter.parse_partition_by(raw_partition_by) -%}\n  {%- set partitions = config.get('partitions', none) -%}\n  {%- set cluster_by = config.get('cluster_by', none) -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view %}\n      {#-- There's no way to atomically replace a view with a table on BQ --#}\n      {{ adapter.drop_relation(existing_relation) }}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif full_refresh_mode %}\n      {#-- If the partition/cluster config has changed, then we must drop and recreate --#}\n      {% if not adapter.is_replaceable(existing_relation, partition_by, cluster_by) %}\n          {% do log(\"Hard refreshing \" ~ existing_relation ~ \" because it is not replaceable\") %}\n          {{ adapter.drop_relation(existing_relation) }}\n      {% endif %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% else %}\n     {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n\n     {#-- if partitioned, use BQ scripting to get the range of partition values to be updated --#}\n     {% if strategy == 'insert_overwrite' %}\n     \n        {% set missing_partition_msg -%}\n          The 'insert_overwrite' strategy requires the `partition_by` config.\n        {%- endset %}\n        {% if partition_by is none %}\n          {% do exceptions.raise_compiler_error(missing_partition_msg) %}\n        {% endif %}\n        \n        {% set build_sql = bq_insert_overwrite(\n            tmp_relation,\n            target_relation,\n            sql,\n            unique_key,\n            partition_by,\n            partitions,\n            dest_columns) %}\n\n     {% else %}\n       {#-- wrap sql in parens to make it a subquery --#}\n       {%- set source_sql -%}\n         (\n           {{sql}}\n         )\n       {%- endset -%}\n\n       {% set build_sql = get_merge_sql(target_relation, source_sql, unique_key, dest_columns) %}\n\n     {% endif %}\n\n  {% endif %}\n\n  {%- call statement('main') -%}\n    {{ build_sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt_bigquery.materialization_incremental_bigquery", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/incremental.sql", "original_file_path": "macros/materializations/incremental.sql", "resource_type": "macro", "name": "materialization_incremental_bigquery", "macro_sql": "{% materialization incremental, adapter='bigquery' -%}\n\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set target_relation = this %}\n  {%- set existing_relation = load_relation(this) %}\n  {%- set tmp_relation = make_temp_relation(this) %}\n  \n  {#-- Validate early so we don't run SQL if the strategy is invalid --#}\n  {% set strategy = dbt_bigquery_validate_get_incremental_strategy(config) -%}\n\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set partition_by = adapter.parse_partition_by(raw_partition_by) -%}\n  {%- set partitions = config.get('partitions', none) -%}\n  {%- set cluster_by = config.get('cluster_by', none) -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view %}\n      {#-- There's no way to atomically replace a view with a table on BQ --#}\n      {{ adapter.drop_relation(existing_relation) }}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif full_refresh_mode %}\n      {#-- If the partition/cluster config has changed, then we must drop and recreate --#}\n      {% if not adapter.is_replaceable(existing_relation, partition_by, cluster_by) %}\n          {% do log(\"Hard refreshing \" ~ existing_relation ~ \" because it is not replaceable\") %}\n          {{ adapter.drop_relation(existing_relation) }}\n      {% endif %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% else %}\n     {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n\n     {#-- if partitioned, use BQ scripting to get the range of partition values to be updated --#}\n     {% if strategy == 'insert_overwrite' %}\n     \n        {% set missing_partition_msg -%}\n          The 'insert_overwrite' strategy requires the `partition_by` config.\n        {%- endset %}\n        {% if partition_by is none %}\n          {% do exceptions.raise_compiler_error(missing_partition_msg) %}\n        {% endif %}\n        \n        {% set build_sql = bq_insert_overwrite(\n            tmp_relation,\n            target_relation,\n            sql,\n            unique_key,\n            partition_by,\n            partitions,\n            dest_columns) %}\n\n     {% else %}\n       {#-- wrap sql in parens to make it a subquery --#}\n       {%- set source_sql -%}\n         (\n           {{sql}}\n         )\n       {%- endset -%}\n\n       {% set build_sql = get_merge_sql(target_relation, source_sql, unique_key, dest_columns) %}\n\n     {% endif %}\n\n  {% endif %}\n\n  {%- call statement('main') -%}\n    {{ build_sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__snapshot_hash_arguments": {"raw_sql": "{% macro bigquery__snapshot_hash_arguments(args) -%}\n  to_hex(md5(concat({%- for arg in args -%}\n    coalesce(cast({{ arg }} as string), ''){% if not loop.last %}, '|',{% endif -%}\n  {%- endfor -%}\n  )))\n{%- endmacro %}\n\n{% macro bigquery__create_columns(relation, columns) %}\n  {{ adapter.alter_table_add_columns(relation, columns) }}\n{% endmacro %}\n\n{% macro bigquery__post_snapshot(staging_relation) %}\n  -- Clean up the snapshot temp table\n  {% do drop_relation(staging_relation) %}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__snapshot_hash_arguments", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "resource_type": "macro", "name": "bigquery__snapshot_hash_arguments", "macro_sql": "{% macro bigquery__snapshot_hash_arguments(args) -%}\n  to_hex(md5(concat({%- for arg in args -%}\n    coalesce(cast({{ arg }} as string), ''){% if not loop.last %}, '|',{% endif -%}\n  {%- endfor -%}\n  )))\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__create_columns": {"raw_sql": "{% macro bigquery__snapshot_hash_arguments(args) -%}\n  to_hex(md5(concat({%- for arg in args -%}\n    coalesce(cast({{ arg }} as string), ''){% if not loop.last %}, '|',{% endif -%}\n  {%- endfor -%}\n  )))\n{%- endmacro %}\n\n{% macro bigquery__create_columns(relation, columns) %}\n  {{ adapter.alter_table_add_columns(relation, columns) }}\n{% endmacro %}\n\n{% macro bigquery__post_snapshot(staging_relation) %}\n  -- Clean up the snapshot temp table\n  {% do drop_relation(staging_relation) %}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__create_columns", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "resource_type": "macro", "name": "bigquery__create_columns", "macro_sql": "{% macro bigquery__create_columns(relation, columns) %}\n  {{ adapter.alter_table_add_columns(relation, columns) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_bigquery.bigquery__post_snapshot": {"raw_sql": "{% macro bigquery__snapshot_hash_arguments(args) -%}\n  to_hex(md5(concat({%- for arg in args -%}\n    coalesce(cast({{ arg }} as string), ''){% if not loop.last %}, '|',{% endif -%}\n  {%- endfor -%}\n  )))\n{%- endmacro %}\n\n{% macro bigquery__create_columns(relation, columns) %}\n  {{ adapter.alter_table_add_columns(relation, columns) }}\n{% endmacro %}\n\n{% macro bigquery__post_snapshot(staging_relation) %}\n  -- Clean up the snapshot temp table\n  {% do drop_relation(staging_relation) %}\n{% endmacro %}", "unique_id": "macro.dbt_bigquery.bigquery__post_snapshot", "package_name": "dbt_bigquery", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "resource_type": "macro", "name": "bigquery__post_snapshot", "macro_sql": "{% macro bigquery__post_snapshot(staging_relation) %}\n  -- Clean up the snapshot temp table\n  {% do drop_relation(staging_relation) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.except": {"raw_sql": "{% macro except() %}\n  {{ adapter_macro('dbt_utils.except') }}\n{% endmacro %}\n\n\n{% macro default__except() %}\n\n    except\n\n{% endmacro %}\n    \n{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.except", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "resource_type": "macro", "name": "except", "macro_sql": "{% macro except() %}\n  {{ adapter_macro('dbt_utils.except') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__except": {"raw_sql": "{% macro except() %}\n  {{ adapter_macro('dbt_utils.except') }}\n{% endmacro %}\n\n\n{% macro default__except() %}\n\n    except\n\n{% endmacro %}\n    \n{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__except", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "resource_type": "macro", "name": "default__except", "macro_sql": "{% macro default__except() %}\n\n    except\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__except": {"raw_sql": "{% macro except() %}\n  {{ adapter_macro('dbt_utils.except') }}\n{% endmacro %}\n\n\n{% macro default__except() %}\n\n    except\n\n{% endmacro %}\n    \n{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__except", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "resource_type": "macro", "name": "bigquery__except", "macro_sql": "{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.replace": {"raw_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ adapter_macro('dbt_utils.replace', field, old_chars, new_chars) }}\n{% endmacro %}\n\n\n{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n    \n\n{% endmacro %}", "unique_id": "macro.dbt_utils.replace", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/replace.sql", "original_file_path": "macros/cross_db_utils/replace.sql", "resource_type": "macro", "name": "replace", "macro_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ adapter_macro('dbt_utils.replace', field, old_chars, new_chars) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__replace": {"raw_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ adapter_macro('dbt_utils.replace', field, old_chars, new_chars) }}\n{% endmacro %}\n\n\n{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n    \n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__replace", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/replace.sql", "original_file_path": "macros/cross_db_utils/replace.sql", "resource_type": "macro", "name": "default__replace", "macro_sql": "{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n    \n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.concat": {"raw_sql": "{% macro concat(fields) -%}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{%- endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.concat", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "concat", "macro_sql": "{% macro concat(fields) -%}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__concat": {"raw_sql": "{% macro concat(fields) -%}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{%- endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__concat", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "default__concat", "macro_sql": "{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.alternative_concat": {"raw_sql": "{% macro concat(fields) -%}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{%- endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.alternative_concat", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "alternative_concat", "macro_sql": "{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__concat": {"raw_sql": "{% macro concat(fields) -%}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{%- endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.redshift__concat", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "redshift__concat", "macro_sql": "{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__concat": {"raw_sql": "{% macro concat(fields) -%}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{%- endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__concat", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "snowflake__concat", "macro_sql": "{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.identifier": {"raw_sql": "{% macro identifier(value) %}\n  {{ adapter_macro('dbt_utils.identifier', value) }}\n{% endmacro %}\n\n{% macro default__identifier(value) -%}\n    \"{{ value }}\"\n{%- endmacro %}\n\n{% macro bigquery__identifier(value) -%}\n    `{{ value }}`\n{%- endmacro %}", "unique_id": "macro.dbt_utils.identifier", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/identifer.sql", "original_file_path": "macros/cross_db_utils/identifer.sql", "resource_type": "macro", "name": "identifier", "macro_sql": "{% macro identifier(value) %}\n  {{ adapter_macro('dbt_utils.identifier', value) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__identifier": {"raw_sql": "{% macro identifier(value) %}\n  {{ adapter_macro('dbt_utils.identifier', value) }}\n{% endmacro %}\n\n{% macro default__identifier(value) -%}\n    \"{{ value }}\"\n{%- endmacro %}\n\n{% macro bigquery__identifier(value) -%}\n    `{{ value }}`\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default__identifier", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/identifer.sql", "original_file_path": "macros/cross_db_utils/identifer.sql", "resource_type": "macro", "name": "default__identifier", "macro_sql": "{% macro default__identifier(value) -%}\n    \"{{ value }}\"\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__identifier": {"raw_sql": "{% macro identifier(value) %}\n  {{ adapter_macro('dbt_utils.identifier', value) }}\n{% endmacro %}\n\n{% macro default__identifier(value) -%}\n    \"{{ value }}\"\n{%- endmacro %}\n\n{% macro bigquery__identifier(value) -%}\n    `{{ value }}`\n{%- endmacro %}", "unique_id": "macro.dbt_utils.bigquery__identifier", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/identifer.sql", "original_file_path": "macros/cross_db_utils/identifer.sql", "resource_type": "macro", "name": "bigquery__identifier", "macro_sql": "{% macro bigquery__identifier(value) -%}\n    `{{ value }}`\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_string", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_string", "macro_sql": "\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_string", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_string", "macro_sql": "{% macro default__type_string() %}\n    string\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.redshift__type_string", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "redshift__type_string", "macro_sql": "\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.postgres__type_string", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "postgres__type_string", "macro_sql": "{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__type_string", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "snowflake__type_string", "macro_sql": "{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_timestamp": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_timestamp", "macro_sql": "\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_timestamp": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_timestamp", "macro_sql": "{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__type_timestamp": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "snowflake__type_timestamp", "macro_sql": "{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_float": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_float", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_float", "macro_sql": "\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_float": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_float", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_float", "macro_sql": "{% macro default__type_float() %}\n    float\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_float": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__type_float", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "bigquery__type_float", "macro_sql": "{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_numeric": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_numeric", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_numeric", "macro_sql": "\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_numeric": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_numeric", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_numeric": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__type_numeric", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "bigquery__type_numeric", "macro_sql": "{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_bigint": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_bigint", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_bigint", "macro_sql": "\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_bigint": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_bigint", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_bigint", "macro_sql": "{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_bigint": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__type_bigint", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "bigquery__type_bigint", "macro_sql": "{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_int": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_int", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_int", "macro_sql": "\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_int": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_int", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_int", "macro_sql": "{% macro default__type_int() %}\n    int\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_int": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{%- macro type_string() -%}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{%- endmacro -%}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{%- macro type_timestamp() -%}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{%- endmacro -%}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{%- macro type_float() -%}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{%- endmacro -%}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{%- macro type_numeric() -%}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{%- endmacro -%}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{%- macro type_bigint() -%}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{%- endmacro -%}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{%- macro type_int() -%}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{%- endmacro -%}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__type_int", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "bigquery__type_int", "macro_sql": "{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils._is_relation": {"raw_sql": "{% macro _is_relation(obj, macro) %}\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\n    {%- endif -%}\n{% endmacro %}", "unique_id": "macro.dbt_utils._is_relation", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/_is_relation.sql", "original_file_path": "macros/cross_db_utils/_is_relation.sql", "resource_type": "macro", "name": "_is_relation", "macro_sql": "{% macro _is_relation(obj, macro) %}\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\n    {%- endif -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.length": {"raw_sql": "{% macro length(expression) -%}\n    {{ adapter_macro('dbt_utils.length', expression) }}\n{% endmacro %}\n\n\n{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.length", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "resource_type": "macro", "name": "length", "macro_sql": "{% macro length(expression) -%}\n    {{ adapter_macro('dbt_utils.length', expression) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__length": {"raw_sql": "{% macro length(expression) -%}\n    {{ adapter_macro('dbt_utils.length', expression) }}\n{% endmacro %}\n\n\n{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.default__length", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "resource_type": "macro", "name": "default__length", "macro_sql": "{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__length": {"raw_sql": "{% macro length(expression) -%}\n    {{ adapter_macro('dbt_utils.length', expression) }}\n{% endmacro %}\n\n\n{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.redshift__length", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "resource_type": "macro", "name": "redshift__length", "macro_sql": "{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.dateadd": {"raw_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}\n\n\n{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}\n\n\n{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.dateadd", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "resource_type": "macro", "name": "dateadd", "macro_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__dateadd": {"raw_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}\n\n\n{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}\n\n\n{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__dateadd", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "resource_type": "macro", "name": "default__dateadd", "macro_sql": "{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__dateadd": {"raw_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}\n\n\n{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}\n\n\n{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__dateadd", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "resource_type": "macro", "name": "bigquery__dateadd", "macro_sql": "{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__dateadd": {"raw_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}\n\n\n{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}\n\n\n{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.postgres__dateadd", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "resource_type": "macro", "name": "postgres__dateadd", "macro_sql": "{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.intersect": {"raw_sql": "{% macro intersect() %}\n  {{ adapter_macro('dbt_utils.intersect') }}\n{% endmacro %}\n\n\n{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}\n\n{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.intersect", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "resource_type": "macro", "name": "intersect", "macro_sql": "{% macro intersect() %}\n  {{ adapter_macro('dbt_utils.intersect') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__intersect": {"raw_sql": "{% macro intersect() %}\n  {{ adapter_macro('dbt_utils.intersect') }}\n{% endmacro %}\n\n\n{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}\n\n{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__intersect", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "resource_type": "macro", "name": "default__intersect", "macro_sql": "{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__intersect": {"raw_sql": "{% macro intersect() %}\n  {{ adapter_macro('dbt_utils.intersect') }}\n{% endmacro %}\n\n\n{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}\n\n{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__intersect", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "resource_type": "macro", "name": "bigquery__intersect", "macro_sql": "{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.right": {"raw_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}\n\n{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.right", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "resource_type": "macro", "name": "right", "macro_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__right": {"raw_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}\n\n{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.default__right", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "resource_type": "macro", "name": "default__right", "macro_sql": "{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__right": {"raw_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}\n\n{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.bigquery__right", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "resource_type": "macro", "name": "bigquery__right", "macro_sql": "{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__right": {"raw_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}\n\n{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.snowflake__right", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "resource_type": "macro", "name": "snowflake__right", "macro_sql": "{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.datediff": {"raw_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}\n\n\n{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    )\n\n{% endmacro %}\n\n\n{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {% if datepart == 'year' %}\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\n    {% elif datepart == 'quarter' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\n    {% elif datepart == 'month' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\n    {% elif datepart == 'day' %}\n        (({{second_date}})::date - ({{first_date}})::date)\n    {% elif datepart == 'week' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\n            else\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\n        end)\n    {% elif datepart == 'hour' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\n    {% elif datepart == 'minute' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\n    {% elif datepart == 'second' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\n    {% elif datepart == 'millisecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\n    {% elif datepart == 'microsecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\n    {% else %}\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\n    {% endif %}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.datediff", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "resource_type": "macro", "name": "datediff", "macro_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__datediff": {"raw_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}\n\n\n{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    )\n\n{% endmacro %}\n\n\n{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {% if datepart == 'year' %}\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\n    {% elif datepart == 'quarter' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\n    {% elif datepart == 'month' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\n    {% elif datepart == 'day' %}\n        (({{second_date}})::date - ({{first_date}})::date)\n    {% elif datepart == 'week' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\n            else\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\n        end)\n    {% elif datepart == 'hour' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\n    {% elif datepart == 'minute' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\n    {% elif datepart == 'second' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\n    {% elif datepart == 'millisecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\n    {% elif datepart == 'microsecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\n    {% else %}\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\n    {% endif %}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__datediff", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "resource_type": "macro", "name": "default__datediff", "macro_sql": "{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__datediff": {"raw_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}\n\n\n{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    )\n\n{% endmacro %}\n\n\n{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {% if datepart == 'year' %}\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\n    {% elif datepart == 'quarter' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\n    {% elif datepart == 'month' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\n    {% elif datepart == 'day' %}\n        (({{second_date}})::date - ({{first_date}})::date)\n    {% elif datepart == 'week' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\n            else\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\n        end)\n    {% elif datepart == 'hour' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\n    {% elif datepart == 'minute' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\n    {% elif datepart == 'second' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\n    {% elif datepart == 'millisecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\n    {% elif datepart == 'microsecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\n    {% else %}\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\n    {% endif %}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__datediff", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "resource_type": "macro", "name": "bigquery__datediff", "macro_sql": "{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__datediff": {"raw_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}\n\n\n{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    )\n\n{% endmacro %}\n\n\n{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {% if datepart == 'year' %}\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\n    {% elif datepart == 'quarter' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\n    {% elif datepart == 'month' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\n    {% elif datepart == 'day' %}\n        (({{second_date}})::date - ({{first_date}})::date)\n    {% elif datepart == 'week' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\n            else\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\n        end)\n    {% elif datepart == 'hour' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\n    {% elif datepart == 'minute' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\n    {% elif datepart == 'second' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\n    {% elif datepart == 'millisecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\n    {% elif datepart == 'microsecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\n    {% else %}\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\n    {% endif %}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.postgres__datediff", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "resource_type": "macro", "name": "postgres__datediff", "macro_sql": "{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {% if datepart == 'year' %}\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\n    {% elif datepart == 'quarter' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\n    {% elif datepart == 'month' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\n    {% elif datepart == 'day' %}\n        (({{second_date}})::date - ({{first_date}})::date)\n    {% elif datepart == 'week' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\n            else\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\n        end)\n    {% elif datepart == 'hour' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\n    {% elif datepart == 'minute' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\n    {% elif datepart == 'second' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\n    {% elif datepart == 'millisecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\n    {% elif datepart == 'microsecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\n    {% else %}\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\n    {% endif %}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.safe_cast": {"raw_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}\n\n\n{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "unique_id": "macro.dbt_utils.safe_cast", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "resource_type": "macro", "name": "safe_cast", "macro_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__safe_cast": {"raw_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}\n\n\n{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "resource_type": "macro", "name": "default__safe_cast", "macro_sql": "{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__safe_cast": {"raw_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}\n\n\n{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "resource_type": "macro", "name": "snowflake__safe_cast", "macro_sql": "{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__safe_cast": {"raw_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}\n\n\n{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "resource_type": "macro", "name": "bigquery__safe_cast", "macro_sql": "{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.hash": {"raw_sql": "{% macro hash(field) -%}\n  {{ adapter_macro('dbt_utils.hash', field) }}\n{%- endmacro %}\n\n\n{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}\n\n\n{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "unique_id": "macro.dbt_utils.hash", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "resource_type": "macro", "name": "hash", "macro_sql": "{% macro hash(field) -%}\n  {{ adapter_macro('dbt_utils.hash', field) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__hash": {"raw_sql": "{% macro hash(field) -%}\n  {{ adapter_macro('dbt_utils.hash', field) }}\n{%- endmacro %}\n\n\n{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}\n\n\n{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default__hash", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "resource_type": "macro", "name": "default__hash", "macro_sql": "{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__hash": {"raw_sql": "{% macro hash(field) -%}\n  {{ adapter_macro('dbt_utils.hash', field) }}\n{%- endmacro %}\n\n\n{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}\n\n\n{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "unique_id": "macro.dbt_utils.bigquery__hash", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "resource_type": "macro", "name": "bigquery__hash", "macro_sql": "{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.position": {"raw_sql": "{% macro position(substring_text, string_text) -%}\n    {{ adapter_macro('dbt_utils.position', substring_text, string_text) }}\n{% endmacro %}\n\n\n{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.position", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "resource_type": "macro", "name": "position", "macro_sql": "{% macro position(substring_text, string_text) -%}\n    {{ adapter_macro('dbt_utils.position', substring_text, string_text) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__position": {"raw_sql": "{% macro position(substring_text, string_text) -%}\n    {{ adapter_macro('dbt_utils.position', substring_text, string_text) }}\n{% endmacro %}\n\n\n{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.default__position", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "resource_type": "macro", "name": "default__position", "macro_sql": "{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__position": {"raw_sql": "{% macro position(substring_text, string_text) -%}\n    {{ adapter_macro('dbt_utils.position', substring_text, string_text) }}\n{% endmacro %}\n\n\n{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.bigquery__position", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "resource_type": "macro", "name": "bigquery__position", "macro_sql": "{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.string_literal": {"raw_sql": "{%- macro string_literal(value) -%}\n  {{ adapter_macro('dbt_utils.string_literal', value) }}\n{%- endmacro -%}\n\n{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "unique_id": "macro.dbt_utils.string_literal", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/literal.sql", "original_file_path": "macros/cross_db_utils/literal.sql", "resource_type": "macro", "name": "string_literal", "macro_sql": "{%- macro string_literal(value) -%}\n  {{ adapter_macro('dbt_utils.string_literal', value) }}\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__string_literal": {"raw_sql": "{%- macro string_literal(value) -%}\n  {{ adapter_macro('dbt_utils.string_literal', value) }}\n{%- endmacro -%}\n\n{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default__string_literal", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/literal.sql", "original_file_path": "macros/cross_db_utils/literal.sql", "resource_type": "macro", "name": "default__string_literal", "macro_sql": "{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.current_timestamp": {"raw_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__current_timestamp": {"raw_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__current_timestamp": {"raw_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.redshift__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "redshift__current_timestamp", "macro_sql": "{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__current_timestamp": {"raw_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "bigquery__current_timestamp", "macro_sql": "{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.current_timestamp_in_utc": {"raw_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "current_timestamp_in_utc", "macro_sql": "{% macro current_timestamp_in_utc() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__current_timestamp_in_utc": {"raw_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "default__current_timestamp_in_utc", "macro_sql": "{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__current_timestamp_in_utc": {"raw_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "snowflake__current_timestamp_in_utc", "macro_sql": "{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__current_timestamp_in_utc": {"raw_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() -%}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{%- endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.postgres__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "postgres__current_timestamp_in_utc", "macro_sql": "{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.width_bucket": {"raw_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}\n\n\n{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "unique_id": "macro.dbt_utils.width_bucket", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "resource_type": "macro", "name": "width_bucket", "macro_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__width_bucket": {"raw_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}\n\n\n{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "resource_type": "macro", "name": "default__width_bucket", "macro_sql": "{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__width_bucket": {"raw_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}\n\n\n{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "unique_id": "macro.dbt_utils.redshift__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "resource_type": "macro", "name": "redshift__width_bucket", "macro_sql": "{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__width_bucket": {"raw_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}\n\n\n{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "resource_type": "macro", "name": "snowflake__width_bucket", "macro_sql": "{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.last_day": {"raw_sql": "/*\nThis function has been tested with dateparts of month and quarters. Further\ntesting is required to validate that it will work on other dateparts.\n*/\n\n{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}\n\n\n{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.last_day", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "resource_type": "macro", "name": "last_day", "macro_sql": "{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default_last_day": {"raw_sql": "/*\nThis function has been tested with dateparts of month and quarters. Further\ntesting is required to validate that it will work on other dateparts.\n*/\n\n{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}\n\n\n{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default_last_day", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "resource_type": "macro", "name": "default_last_day", "macro_sql": "\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__last_day": {"raw_sql": "/*\nThis function has been tested with dateparts of month and quarters. Further\ntesting is required to validate that it will work on other dateparts.\n*/\n\n{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}\n\n\n{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default__last_day", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "resource_type": "macro", "name": "default__last_day", "macro_sql": "{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__last_day": {"raw_sql": "/*\nThis function has been tested with dateparts of month and quarters. Further\ntesting is required to validate that it will work on other dateparts.\n*/\n\n{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}\n\n\n{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.postgres__last_day", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "resource_type": "macro", "name": "postgres__last_day", "macro_sql": "{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.split_part": {"raw_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ adapter_macro('dbt_utils.split_part', string_text, delimiter_text, part_number) }}\n{% endmacro %}\n\n\n{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.split_part", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "resource_type": "macro", "name": "split_part", "macro_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ adapter_macro('dbt_utils.split_part', string_text, delimiter_text, part_number) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__split_part": {"raw_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ adapter_macro('dbt_utils.split_part', string_text, delimiter_text, part_number) }}\n{% endmacro %}\n\n\n{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__split_part", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "resource_type": "macro", "name": "default__split_part", "macro_sql": "{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__split_part": {"raw_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ adapter_macro('dbt_utils.split_part', string_text, delimiter_text, part_number) }}\n{% endmacro %}\n\n\n{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__split_part", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "resource_type": "macro", "name": "bigquery__split_part", "macro_sql": "{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.date_trunc": {"raw_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ adapter_macro('dbt_utils.date_trunc', datepart, date) }}\n{%- endmacro %}\n\n{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}\n\n{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp),\n        {{datepart}}\n    )\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.date_trunc", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "resource_type": "macro", "name": "date_trunc", "macro_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ adapter_macro('dbt_utils.date_trunc', datepart, date) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__date_trunc": {"raw_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ adapter_macro('dbt_utils.date_trunc', datepart, date) }}\n{%- endmacro %}\n\n{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}\n\n{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp),\n        {{datepart}}\n    )\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__date_trunc", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "resource_type": "macro", "name": "default__date_trunc", "macro_sql": "{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__date_trunc": {"raw_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ adapter_macro('dbt_utils.date_trunc', datepart, date) }}\n{%- endmacro %}\n\n{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}\n\n{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp),\n        {{datepart}}\n    )\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__date_trunc", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "resource_type": "macro", "name": "bigquery__date_trunc", "macro_sql": "{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp),\n        {{datepart}}\n    )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_period_boundaries": {"raw_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}\n\n{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}\n\n{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}};\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {%- set rows_inserted = (load_result('main-' ~ i)['status'].split(\" \"))[2] | int -%}\n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement(name='main', status=status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt_utils.get_period_boundaries", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "resource_type": "macro", "name": "get_period_boundaries", "macro_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_period_sql": {"raw_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}\n\n{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}\n\n{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}};\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {%- set rows_inserted = (load_result('main-' ~ i)['status'].split(\" \"))[2] | int -%}\n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement(name='main', status=status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt_utils.get_period_sql", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "resource_type": "macro", "name": "get_period_sql", "macro_sql": "{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.materialization_insert_by_period_default": {"raw_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}\n\n{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}\n\n{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}};\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {%- set rows_inserted = (load_result('main-' ~ i)['status'].split(\" \"))[2] | int -%}\n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement(name='main', status=status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt_utils.materialization_insert_by_period_default", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "resource_type": "macro", "name": "materialization_insert_by_period_default", "macro_sql": "{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}};\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {%- set rows_inserted = (load_result('main-' ~ i)['status'].split(\" \"))[2] | int -%}\n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement(name='main', status=status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n{%- endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pretty_log_format": {"raw_sql": "{% macro pretty_log_format(message) %}\n\n    {{ return( dbt_utils.pretty_time() ~ ' + ' ~ message) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.pretty_log_format", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/logger/pretty_log_format.sql", "original_file_path": "macros/logger/pretty_log_format.sql", "resource_type": "macro", "name": "pretty_log_format", "macro_sql": "{% macro pretty_log_format(message) %}\n\n    {{ return( dbt_utils.pretty_time() ~ ' + ' ~ message) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pretty_time": {"raw_sql": "{% macro pretty_time(format='%H:%M:%S') %}\n\n    {{ return(modules.datetime.datetime.now().strftime(format)) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.pretty_time", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/logger/pretty_time.sql", "original_file_path": "macros/logger/pretty_time.sql", "resource_type": "macro", "name": "pretty_time", "macro_sql": "{% macro pretty_time(format='%H:%M:%S') %}\n\n    {{ return(modules.datetime.datetime.now().strftime(format)) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.log_info": {"raw_sql": "{% macro log_info(message) %}\n\n    {{ log(dbt_utils.pretty_log_format(message), info=True) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.log_info", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/logger/log_info.sql", "original_file_path": "macros/logger/log_info.sql", "resource_type": "macro", "name": "log_info", "macro_sql": "{% macro log_info(message) %}\n\n    {{ log(dbt_utils.pretty_log_format(message), info=True) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_intervals_between": {"raw_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n\n\n{% macro date_spine(datepart, start_date, end_date) %}\n\n/*\ncall as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n)\n\n*/\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt_utils.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_intervals_between", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/datetime/date_spine.sql", "original_file_path": "macros/datetime/date_spine.sql", "resource_type": "macro", "name": "get_intervals_between", "macro_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.date_spine": {"raw_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n\n\n{% macro date_spine(datepart, start_date, end_date) %}\n\n/*\ncall as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n)\n\n*/\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt_utils.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.date_spine", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/datetime/date_spine.sql", "original_file_path": "macros/datetime/date_spine.sql", "resource_type": "macro", "name": "date_spine", "macro_sql": "{% macro date_spine(datepart, start_date, end_date) %}\n\n/*\ncall as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n)\n\n*/\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt_utils.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_host": {"raw_sql": "{% macro get_url_host(field) -%}\n\n{%- set parsed = \n    dbt_utils.split_part(\n        dbt_utils.split_part(\n            dbt_utils.replace(\n                dbt_utils.replace(field, \"'http://'\", \"''\"\n                ), \"'https://'\", \"''\"\n            ), \"'/'\", 1\n        ), \"'?'\", 1\n    )\n    \n-%}\n\n     \n    {{ dbt_utils.safe_cast(\n        parsed,\n        dbt_utils.type_string()\n        )}}\n        \n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.get_url_host", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/web/get_url_host.sql", "original_file_path": "macros/web/get_url_host.sql", "resource_type": "macro", "name": "get_url_host", "macro_sql": "{% macro get_url_host(field) -%}\n\n{%- set parsed = \n    dbt_utils.split_part(\n        dbt_utils.split_part(\n            dbt_utils.replace(\n                dbt_utils.replace(field, \"'http://'\", \"''\"\n                ), \"'https://'\", \"''\"\n            ), \"'/'\", 1\n        ), \"'?'\", 1\n    )\n    \n-%}\n\n     \n    {{ dbt_utils.safe_cast(\n        parsed,\n        dbt_utils.type_string()\n        )}}\n        \n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_path": {"raw_sql": "{% macro get_url_path(field) -%}\n\n    {%- set stripped_url = \n        dbt_utils.replace(\n            dbt_utils.replace(field, \"'http://'\", \"''\"), \"'https://'\", \"''\")\n    -%}\n\n    {%- set first_slash_pos -%}\n        coalesce(\n            nullif({{dbt_utils.position(\"'/'\", stripped_url)}}, 0),\n            {{dbt_utils.position(\"'?'\", stripped_url)}} - 1\n            )\n    {%- endset -%}\n\n    {%- set parsed_path =\n        dbt_utils.split_part(\n            dbt_utils.right(\n                stripped_url, \n                dbt_utils.length(stripped_url) ~ \"-\" ~ first_slash_pos\n                ), \n            \"'?'\", 1\n            )\n    -%}\n\n    {{ dbt_utils.safe_cast(\n        parsed_path,\n        dbt_utils.type_string()\n    )}}\n    \n{%- endmacro %}", "unique_id": "macro.dbt_utils.get_url_path", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/web/get_url_path.sql", "original_file_path": "macros/web/get_url_path.sql", "resource_type": "macro", "name": "get_url_path", "macro_sql": "{% macro get_url_path(field) -%}\n\n    {%- set stripped_url = \n        dbt_utils.replace(\n            dbt_utils.replace(field, \"'http://'\", \"''\"), \"'https://'\", \"''\")\n    -%}\n\n    {%- set first_slash_pos -%}\n        coalesce(\n            nullif({{dbt_utils.position(\"'/'\", stripped_url)}}, 0),\n            {{dbt_utils.position(\"'?'\", stripped_url)}} - 1\n            )\n    {%- endset -%}\n\n    {%- set parsed_path =\n        dbt_utils.split_part(\n            dbt_utils.right(\n                stripped_url, \n                dbt_utils.length(stripped_url) ~ \"-\" ~ first_slash_pos\n                ), \n            \"'?'\", 1\n            )\n    -%}\n\n    {{ dbt_utils.safe_cast(\n        parsed_path,\n        dbt_utils.type_string()\n    )}}\n    \n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_parameter": {"raw_sql": "{% macro get_url_parameter(field, url_parameter) -%}\n\n{%- set formatted_url_parameter = \"'\" + url_parameter + \"='\" -%}\n\n{%- set split = dbt_utils.split_part(dbt_utils.split_part(field, formatted_url_parameter, 2), \"'&'\", 1) -%}\n\nnullif({{ split }},'')\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.get_url_parameter", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/web/get_url_parameter.sql", "original_file_path": "macros/web/get_url_parameter.sql", "resource_type": "macro", "name": "get_url_parameter", "macro_sql": "{% macro get_url_parameter(field, url_parameter) -%}\n\n{%- set formatted_url_parameter = \"'\" + url_parameter + \"='\" -%}\n\n{%- set split = dbt_utils.split_part(dbt_utils.split_part(field, formatted_url_parameter, 2), \"'&'\", 1) -%}\n\nnullif({{ split }},'')\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.haversine_distance": {"raw_sql": "{#\nThis calculates the distance between two sets of latitude and longitude.\nThe formula is from the following blog post:\nhttp://daynebatten.com/2015/09/latitude-longitude-distance-sql/\n\nThe arguments should be float type. \n#}\n\n{% macro haversine_distance(lat1,lon1,lat2,lon2) -%}\n\n    2 * 3961 * asin(sqrt((sin(radians(({{lat2}} - {{lat1}}) / 2))) ^ 2 +\n    cos(radians({{lat1}})) * cos(radians({{lat2}})) *\n    (sin(radians(({{lon2}} - {{lon1}}) / 2))) ^ 2))\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.haversine_distance", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/geo/haversine_distance.sql", "original_file_path": "macros/geo/haversine_distance.sql", "resource_type": "macro", "name": "haversine_distance", "macro_sql": "{% macro haversine_distance(lat1,lon1,lat2,lon2) -%}\n\n    2 * 3961 * asin(sqrt((sin(radians(({{lat2}} - {{lat1}}) / 2))) ^ 2 +\n    cos(radians({{lat1}})) * cos(radians({{lat2}})) *\n    (sin(radians(({{lon2}} - {{lon1}}) / 2))) ^ 2))\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_equal_rowcount": {"raw_sql": "{% macro test_equal_rowcount(model) %}\n\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\nwith a as (\n\n    select count(*) as count_a from {{ model }}\n\n),\nb as (\n\n    select count(*) as count_b from {{ compare_model }}\n\n),\nfinal as (\n\n    select abs(\n            (select count_a from a) -\n            (select count_b from b)\n            )\n        as diff_count\n\n)\n\nselect diff_count from final\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_equal_rowcount", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/equal_rowcount.sql", "original_file_path": "macros/schema_tests/equal_rowcount.sql", "resource_type": "macro", "name": "test_equal_rowcount", "macro_sql": "{% macro test_equal_rowcount(model) %}\n\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\nwith a as (\n\n    select count(*) as count_a from {{ model }}\n\n),\nb as (\n\n    select count(*) as count_b from {{ compare_model }}\n\n),\nfinal as (\n\n    select abs(\n            (select count_a from a) -\n            (select count_b from b)\n            )\n        as diff_count\n\n)\n\nselect diff_count from final\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_relationships_where": {"raw_sql": "{% macro test_relationships_where(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n{% set from_condition = kwargs.get('from_condition', \"true\") %}\n{% set to_condition = kwargs.get('to_condition', \"true\") %}\n\nwith left_table as (\n\n  select\n    {{column_name}} as id\n\n  from {{model}}\n\n  where {{column_name}} is not null\n    and {{from_condition}}\n\n),\n\nright_table as (\n\n  select\n    {{field}} as id\n\n  from {{to}}\n\n  where {{field}} is not null\n    and {{to_condition}}\n\n),\n\nexceptions as (\n\n  select\n    left_table.id,\n    right_table.id as right_id\n\n  from left_table\n\n  left join right_table\n         on left_table.id = right_table.id\n\n  where right_table.id is null\n\n)\n\nselect count(*) from exceptions\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_relationships_where", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/relationships_where.sql", "original_file_path": "macros/schema_tests/relationships_where.sql", "resource_type": "macro", "name": "test_relationships_where", "macro_sql": "{% macro test_relationships_where(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n{% set from_condition = kwargs.get('from_condition', \"true\") %}\n{% set to_condition = kwargs.get('to_condition', \"true\") %}\n\nwith left_table as (\n\n  select\n    {{column_name}} as id\n\n  from {{model}}\n\n  where {{column_name}} is not null\n    and {{from_condition}}\n\n),\n\nright_table as (\n\n  select\n    {{field}} as id\n\n  from {{to}}\n\n  where {{field}} is not null\n    and {{to_condition}}\n\n),\n\nexceptions as (\n\n  select\n    left_table.id,\n    right_table.id as right_id\n\n  from left_table\n\n  left join right_table\n         on left_table.id = right_table.id\n\n  where right_table.id is null\n\n)\n\nselect count(*) from exceptions\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_recency": {"raw_sql": "{% macro test_recency(model, datepart, interval) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n\nselect\n    case when count(*) > 0 then 0\n    else 1\n    end as error_result\nfrom {{model}}\nwhere {{column_name}} >=\n    {{dbt_utils.dateadd(datepart, interval * -1, dbt_utils.current_timestamp())}}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_recency", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/recency.sql", "original_file_path": "macros/schema_tests/recency.sql", "resource_type": "macro", "name": "test_recency", "macro_sql": "{% macro test_recency(model, datepart, interval) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n\nselect\n    case when count(*) > 0 then 0\n    else 1\n    end as error_result\nfrom {{model}}\nwhere {{column_name}} >=\n    {{dbt_utils.dateadd(datepart, interval * -1, dbt_utils.current_timestamp())}}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_not_constant": {"raw_sql": "{% macro test_not_constant(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\n\nfrom (\n\n    select\n          count(distinct {{ column_name }})\n\n    from {{ model }}\n\n    having count(distinct {{ column_name }}) = 1\n\n    ) validation_errors\n\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_not_constant", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/not_constant.sql", "original_file_path": "macros/schema_tests/not_constant.sql", "resource_type": "macro", "name": "test_not_constant", "macro_sql": "{% macro test_not_constant(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\n\nfrom (\n\n    select\n          count(distinct {{ column_name }})\n\n    from {{ model }}\n\n    having count(distinct {{ column_name }}) = 1\n\n    ) validation_errors\n\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_at_least_one": {"raw_sql": "{% macro test_at_least_one(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom (\n    select\n\n      count({{ column_name }})\n\n    from {{ model }}\n\n    having count({{ column_name }}) = 0\n\n) validation_errors\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_at_least_one", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/at_least_one.sql", "original_file_path": "macros/schema_tests/at_least_one.sql", "resource_type": "macro", "name": "test_at_least_one", "macro_sql": "{% macro test_at_least_one(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom (\n    select\n\n      count({{ column_name }})\n\n    from {{ model }}\n\n    having count({{ column_name }}) = 0\n\n) validation_errors\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_unique_combination_of_columns": {"raw_sql": "{% macro test_unique_combination_of_columns(model) %}\n\n{%- set columns = kwargs.get('combination_of_columns', kwargs.get('arg')) %}\n\n{%- set columns_csv=columns | join(', ') %}\n\nwith validation_errors as (\n\n    select\n        {{ columns_csv }}\n    from {{ model }}\n\n    group by {{ columns_csv }}\n    having count(*) > 1\n\n)\n\nselect count(*)\nfrom validation_errors\n\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_unique_combination_of_columns", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/unique_combination_of_columns.sql", "original_file_path": "macros/schema_tests/unique_combination_of_columns.sql", "resource_type": "macro", "name": "test_unique_combination_of_columns", "macro_sql": "{% macro test_unique_combination_of_columns(model) %}\n\n{%- set columns = kwargs.get('combination_of_columns', kwargs.get('arg')) %}\n\n{%- set columns_csv=columns | join(', ') %}\n\nwith validation_errors as (\n\n    select\n        {{ columns_csv }}\n    from {{ model }}\n\n    group by {{ columns_csv }}\n    having count(*) > 1\n\n)\n\nselect count(*)\nfrom validation_errors\n\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_cardinality_equality": {"raw_sql": "{% macro test_cardinality_equality(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nwith table_a as (\nselect\n  {{ column_name }},\n  count(*) as num_rows\nfrom {{ model }}\ngroup by 1\n),\n\ntable_b as (\nselect\n  {{ field }},\n  count(*) as num_rows\nfrom {{ to }}\ngroup by 1\n),\n\nexcept_a as (\n  select *\n  from table_a\n  {{ dbt_utils.except() }}\n  select *\n  from table_b\n),\n\nexcept_b as (\n  select *\n  from table_b\n  {{ dbt_utils.except() }}\n  select *\n  from table_a\n),\n\nunioned as (\n  select *\n  from except_a\n  union all\n  select *\n  from except_b\n)\n\nselect count(*)\nfrom unioned\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_cardinality_equality", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/cardinality_equality.sql", "original_file_path": "macros/schema_tests/cardinality_equality.sql", "resource_type": "macro", "name": "test_cardinality_equality", "macro_sql": "{% macro test_cardinality_equality(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nwith table_a as (\nselect\n  {{ column_name }},\n  count(*) as num_rows\nfrom {{ model }}\ngroup by 1\n),\n\ntable_b as (\nselect\n  {{ field }},\n  count(*) as num_rows\nfrom {{ to }}\ngroup by 1\n),\n\nexcept_a as (\n  select *\n  from table_a\n  {{ dbt_utils.except() }}\n  select *\n  from table_b\n),\n\nexcept_b as (\n  select *\n  from table_b\n  {{ dbt_utils.except() }}\n  select *\n  from table_a\n),\n\nunioned as (\n  select *\n  from except_a\n  union all\n  select *\n  from except_b\n)\n\nselect count(*)\nfrom unioned\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_expression_is_true": {"raw_sql": "{% macro test_expression_is_true(model, condition='true') %}\n\n{% set expression = kwargs.get('expression', kwargs.get('arg')) %}\n\nwith meet_condition as (\n\n    select * from {{ model }} where {{ condition }}\n\n),\nvalidation_errors as (\n\n    select\n        *\n    from meet_condition\n    where not({{expression}})\n\n)\n\nselect count(*)\nfrom validation_errors\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_expression_is_true", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/expression_is_true.sql", "original_file_path": "macros/schema_tests/expression_is_true.sql", "resource_type": "macro", "name": "test_expression_is_true", "macro_sql": "{% macro test_expression_is_true(model, condition='true') %}\n\n{% set expression = kwargs.get('expression', kwargs.get('arg')) %}\n\nwith meet_condition as (\n\n    select * from {{ model }} where {{ condition }}\n\n),\nvalidation_errors as (\n\n    select\n        *\n    from meet_condition\n    where not({{expression}})\n\n)\n\nselect count(*)\nfrom validation_errors\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_equality": {"raw_sql": "{% macro test_equality(model) %}\n\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n-- setup\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n{% set compare_columns = kwargs.get('compare_columns', adapter.get_columns_in_relation(model) | map(attribute='quoted') ) %}\n{% set compare_cols_csv = compare_columns | join(', ') %}\n\nwith a as (\n\n    select * from {{ model }}\n\n),\n\nb as (\n\n    select * from {{ compare_model }}\n\n),\n\na_minus_b as (\n\n    select {{compare_cols_csv}} from a\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from b\n\n),\n\nb_minus_a as (\n\n    select {{compare_cols_csv}} from b\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_equality", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/equality.sql", "original_file_path": "macros/schema_tests/equality.sql", "resource_type": "macro", "name": "test_equality", "macro_sql": "{% macro test_equality(model) %}\n\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n-- setup\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n{% set compare_columns = kwargs.get('compare_columns', adapter.get_columns_in_relation(model) | map(attribute='quoted') ) %}\n{% set compare_cols_csv = compare_columns | join(', ') %}\n\nwith a as (\n\n    select * from {{ model }}\n\n),\n\nb as (\n\n    select * from {{ compare_model }}\n\n),\n\na_minus_b as (\n\n    select {{compare_cols_csv}} from a\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from b\n\n),\n\nb_minus_a as (\n\n    select {{compare_cols_csv}} from b\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_mutually_exclusive_ranges": {"raw_sql": "{% macro test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed') %}\n\n{% if gaps == 'not_allowed' %}\n    {% set allow_gaps_operator='=' %}\n    {% set allow_gaps_operator_in_words='equal_to' %}\n{% elif gaps == 'allowed' %}\n    {% set allow_gaps_operator='<=' %}\n    {% set allow_gaps_operator_in_words='less_than_or_equal_to' %}\n{% elif gaps == 'required' %}\n    {% set allow_gaps_operator='<' %}\n    {% set allow_gaps_operator_in_words='less_than' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`gaps` argument for mutually_exclusive_ranges test must be one of ['not_allowed', 'allowed', 'required'] Got: '\" ~ gaps ~\"'.'\"\n    ) }}\n\n{% endif %}\n\n{% set partition_clause=\"partition by \" ~ partition_by if partition_by else '' %}\n\nwith window_functions as (\n\n    select\n        {% if partition_by %}\n        {{ partition_by }},\n        {% endif %}\n        {{ lower_bound_column }} as lower_bound,\n        {{ upper_bound_column }} as upper_bound,\n\n        lead({{ lower_bound_column }}) over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }}\n        ) as next_lower_bound,\n\n        row_number() over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }} desc\n        ) = 1 as is_last_record\n\n    from {{ model }}\n\n),\n\ncalc as (\n    -- We want to return records where one of our assumptions fails, so we'll use\n    -- the `not` function with `and` statements so we can write our assumptions nore cleanly\n    select\n        *,\n\n        -- For each record: lower_bound should be < upper_bound.\n        -- Coalesce it to return an error on the null case (implicit assumption\n        -- these columns are not_null)\n        coalesce(\n            lower_bound < upper_bound,\n            false\n        ) as lower_bound_less_than_upper_bound,\n\n        -- For each record: upper_bound {{ allow_gaps_operator }} the next lower_bound.\n        -- Coalesce it to handle null cases for the last record.\n        coalesce(\n            upper_bound {{ allow_gaps_operator }} next_lower_bound,\n            is_last_record,\n            false\n        ) as upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n\n    from window_functions\n\n),\n\nvalidation_errors as (\n\n    select\n        *\n    from calc\n\n    where not(\n        -- THE FOLLOWING SHOULD BE TRUE --\n        lower_bound_less_than_upper_bound\n        and upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n    )\n)\n\nselect count(*) from validation_errors\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_mutually_exclusive_ranges", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/schema_tests/mutually_exclusive_ranges.sql", "original_file_path": "macros/schema_tests/mutually_exclusive_ranges.sql", "resource_type": "macro", "name": "test_mutually_exclusive_ranges", "macro_sql": "{% macro test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed') %}\n\n{% if gaps == 'not_allowed' %}\n    {% set allow_gaps_operator='=' %}\n    {% set allow_gaps_operator_in_words='equal_to' %}\n{% elif gaps == 'allowed' %}\n    {% set allow_gaps_operator='<=' %}\n    {% set allow_gaps_operator_in_words='less_than_or_equal_to' %}\n{% elif gaps == 'required' %}\n    {% set allow_gaps_operator='<' %}\n    {% set allow_gaps_operator_in_words='less_than' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`gaps` argument for mutually_exclusive_ranges test must be one of ['not_allowed', 'allowed', 'required'] Got: '\" ~ gaps ~\"'.'\"\n    ) }}\n\n{% endif %}\n\n{% set partition_clause=\"partition by \" ~ partition_by if partition_by else '' %}\n\nwith window_functions as (\n\n    select\n        {% if partition_by %}\n        {{ partition_by }},\n        {% endif %}\n        {{ lower_bound_column }} as lower_bound,\n        {{ upper_bound_column }} as upper_bound,\n\n        lead({{ lower_bound_column }}) over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }}\n        ) as next_lower_bound,\n\n        row_number() over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }} desc\n        ) = 1 as is_last_record\n\n    from {{ model }}\n\n),\n\ncalc as (\n    -- We want to return records where one of our assumptions fails, so we'll use\n    -- the `not` function with `and` statements so we can write our assumptions nore cleanly\n    select\n        *,\n\n        -- For each record: lower_bound should be < upper_bound.\n        -- Coalesce it to return an error on the null case (implicit assumption\n        -- these columns are not_null)\n        coalesce(\n            lower_bound < upper_bound,\n            false\n        ) as lower_bound_less_than_upper_bound,\n\n        -- For each record: upper_bound {{ allow_gaps_operator }} the next lower_bound.\n        -- Coalesce it to handle null cases for the last record.\n        coalesce(\n            upper_bound {{ allow_gaps_operator }} next_lower_bound,\n            is_last_record,\n            false\n        ) as upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n\n    from window_functions\n\n),\n\nvalidation_errors as (\n\n    select\n        *\n    from calc\n\n    where not(\n        -- THE FOLLOWING SHOULD BE TRUE --\n        lower_bound_less_than_upper_bound\n        and upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n    )\n)\n\nselect count(*) from validation_errors\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.nullcheck_table": {"raw_sql": "{% macro nullcheck_table(relation) %}\n\n  {%- do dbt_utils._is_relation(relation, 'nullcheck_table') -%}\n  {% set cols = adapter.get_columns_in_relation(relation) %}\n\n  select {{ dbt_utils.nullcheck(cols) }}\n  from {{relation}}\n  \n{% endmacro %}", "unique_id": "macro.dbt_utils.nullcheck_table", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/nullcheck_table.sql", "original_file_path": "macros/sql/nullcheck_table.sql", "resource_type": "macro", "name": "nullcheck_table", "macro_sql": "{% macro nullcheck_table(relation) %}\n\n  {%- do dbt_utils._is_relation(relation, 'nullcheck_table') -%}\n  {% set cols = adapter.get_columns_in_relation(relation) %}\n\n  select {{ dbt_utils.nullcheck(cols) }}\n  from {{relation}}\n  \n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_powers_of_two": {"raw_sql": "{% macro get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}\n\n\n{% macro generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * pow(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_powers_of_two", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "resource_type": "macro", "name": "get_powers_of_two", "macro_sql": "{% macro get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.generate_series": {"raw_sql": "{% macro get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}\n\n\n{% macro generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * pow(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.generate_series", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "resource_type": "macro", "name": "generate_series", "macro_sql": "{% macro generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * pow(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_relations_by_prefix": {"raw_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(database, row.table_schema, row.table_name) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}\n\n{% macro get_tables_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {% do exceptions.warn(\"Warning: the `get_tables_by_prefix` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `get_relations_by_prefix` macro instead\") %}\n\n    {{ return(dbt_utils.get_relations_by_prefix(schema, prefix, exclude, database)) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_relations_by_prefix", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/get_relations_by_prefix.sql", "original_file_path": "macros/sql/get_relations_by_prefix.sql", "resource_type": "macro", "name": "get_relations_by_prefix", "macro_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(database, row.table_schema, row.table_name) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_tables_by_prefix": {"raw_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(database, row.table_schema, row.table_name) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}\n\n{% macro get_tables_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {% do exceptions.warn(\"Warning: the `get_tables_by_prefix` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `get_relations_by_prefix` macro instead\") %}\n\n    {{ return(dbt_utils.get_relations_by_prefix(schema, prefix, exclude, database)) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_tables_by_prefix", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/get_relations_by_prefix.sql", "original_file_path": "macros/sql/get_relations_by_prefix.sql", "resource_type": "macro", "name": "get_tables_by_prefix", "macro_sql": "{% macro get_tables_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {% do exceptions.warn(\"Warning: the `get_tables_by_prefix` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `get_relations_by_prefix` macro instead\") %}\n\n    {{ return(dbt_utils.get_relations_by_prefix(schema, prefix, exclude, database)) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_tables_by_prefix_sql": {"raw_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ adapter_macro('dbt_utils.get_tables_by_prefix_sql', schema, prefix, exclude, database) }}\n{% endmacro %}\n\n{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n        select distinct \n            table_schema as \"table_schema\", table_name as \"table_name\"\n        from {{database}}.information_schema.tables\n        where table_schema ilike '{{ schema }}'\n        and table_name ilike '{{ prefix }}%'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}\n\n\n{% macro bigquery__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    \n        select distinct\n            dataset_id as table_schema, table_id as table_name\n\n        from {{adapter.quote(database)}}.{{schema}}.__TABLES_SUMMARY__\n        where dataset_id = '{{schema}}'\n            and lower(table_id) like lower ('{{prefix}}%')\n            and lower(table_id) not like lower ('{{exclude}}')\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "resource_type": "macro", "name": "get_tables_by_prefix_sql", "macro_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ adapter_macro('dbt_utils.get_tables_by_prefix_sql', schema, prefix, exclude, database) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_tables_by_prefix_sql": {"raw_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ adapter_macro('dbt_utils.get_tables_by_prefix_sql', schema, prefix, exclude, database) }}\n{% endmacro %}\n\n{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n        select distinct \n            table_schema as \"table_schema\", table_name as \"table_name\"\n        from {{database}}.information_schema.tables\n        where table_schema ilike '{{ schema }}'\n        and table_name ilike '{{ prefix }}%'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}\n\n\n{% macro bigquery__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    \n        select distinct\n            dataset_id as table_schema, table_id as table_name\n\n        from {{adapter.quote(database)}}.{{schema}}.__TABLES_SUMMARY__\n        where dataset_id = '{{schema}}'\n            and lower(table_id) like lower ('{{prefix}}%')\n            and lower(table_id) not like lower ('{{exclude}}')\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "resource_type": "macro", "name": "default__get_tables_by_prefix_sql", "macro_sql": "{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n        select distinct \n            table_schema as \"table_schema\", table_name as \"table_name\"\n        from {{database}}.information_schema.tables\n        where table_schema ilike '{{ schema }}'\n        and table_name ilike '{{ prefix }}%'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__get_tables_by_prefix_sql": {"raw_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ adapter_macro('dbt_utils.get_tables_by_prefix_sql', schema, prefix, exclude, database) }}\n{% endmacro %}\n\n{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n        select distinct \n            table_schema as \"table_schema\", table_name as \"table_name\"\n        from {{database}}.information_schema.tables\n        where table_schema ilike '{{ schema }}'\n        and table_name ilike '{{ prefix }}%'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}\n\n\n{% macro bigquery__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    \n        select distinct\n            dataset_id as table_schema, table_id as table_name\n\n        from {{adapter.quote(database)}}.{{schema}}.__TABLES_SUMMARY__\n        where dataset_id = '{{schema}}'\n            and lower(table_id) like lower ('{{prefix}}%')\n            and lower(table_id) not like lower ('{{exclude}}')\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "resource_type": "macro", "name": "bigquery__get_tables_by_prefix_sql", "macro_sql": "{% macro bigquery__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    \n        select distinct\n            dataset_id as table_schema, table_id as table_name\n\n        from {{adapter.quote(database)}}.{{schema}}.__TABLES_SUMMARY__\n        where dataset_id = '{{schema}}'\n            and lower(table_id) like lower ('{{prefix}}%')\n            and lower(table_id) not like lower ('{{exclude}}')\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.star": {"raw_sql": "{% macro star(from, relation_alias=False, except=[]) -%}\n\n    {%- do dbt_utils._is_relation(from, 'star') -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set include_cols = [] %}\n    {%- set cols = adapter.get_columns_in_relation(from) -%}\n    {%- for col in cols -%}\n\n        {%- if col.column not in except -%}\n            {% do include_cols.append(col.column) %}\n\n        {%- endif %}\n    {%- endfor %}\n\n    {%- for col in include_cols %}\n\n        {%- if relation_alias %}{{ relation_alias }}.{% else %}{%- endif -%}{{ dbt_utils.identifier(col)|trim }}\n        {%- if not loop.last %},{{ '\\n  ' }}{% endif %}\n\n    {%- endfor -%}\n{%- endmacro %}", "unique_id": "macro.dbt_utils.star", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/star.sql", "original_file_path": "macros/sql/star.sql", "resource_type": "macro", "name": "star", "macro_sql": "{% macro star(from, relation_alias=False, except=[]) -%}\n\n    {%- do dbt_utils._is_relation(from, 'star') -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set include_cols = [] %}\n    {%- set cols = adapter.get_columns_in_relation(from) -%}\n    {%- for col in cols -%}\n\n        {%- if col.column not in except -%}\n            {% do include_cols.append(col.column) %}\n\n        {%- endif %}\n    {%- endfor %}\n\n    {%- for col in include_cols %}\n\n        {%- if relation_alias %}{{ relation_alias }}.{% else %}{%- endif -%}{{ dbt_utils.identifier(col)|trim }}\n        {%- if not loop.last %},{{ '\\n  ' }}{% endif %}\n\n    {%- endfor -%}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.unpivot": {"raw_sql": "{#\nPivot values from columns to rows. Similar to pandas DataFrame melt() function.\n\nExample Usage: {{ unpivot(relation=ref('users'), cast_to='integer', exclude=['id','created_at']) }}\n\nArguments:\n    relation: Relation object, required.\n    cast_to: The datatype to cast all unpivoted columns to. Default is varchar.\n    exclude: A list of columns to keep but exclude from the unpivot operation. Default is none.\n    remove: A list of columns to remove from the resulting table. Default is none.\n    field_name: Destination table column name for the source table column names.\n    value_name: Destination table column name for the pivoted values\n#}\n\n{% macro unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n\n    {% if table %}\n        {% do exceptions.warn(\"Warning: the `unpivot` macro no longer accepts a `table` parameter. This parameter will be deprecated in a future release of dbt-utils. Use the `relation` parameter instead\") %}\n    {% endif %}\n\n    {% if relation and table %}\n        {{ exceptions.raise_compiler_error(\"Error: both the `relation` and `table` parameters were provided to `unpivot` macro. Choose one only (we recommend `relation`).\") }}\n    {% elif not relation and table %}\n        {% set relation=table %}\n    {% elif not relation and not table %}\n        {{ exceptions.raise_compiler_error(\"Error: argument `relation` is required for `unpivot` macro.\") }}\n    {% endif %}\n\n  {%- set exclude = exclude if exclude is not none else [] %}\n  {%- set remove = remove if remove is not none else [] %}\n\n  {%- set include_cols = [] %}\n\n  {%- set table_columns = {} %}\n\n  {%- do table_columns.update({relation: []}) %}\n\n  {%- do dbt_utils._is_relation(relation, 'unpivot') -%}\n  {%- set cols = adapter.get_columns_in_relation(relation) %}\n\n  {%- for col in cols -%}\n    {%- if col.column.lower() not in remove|map('lower') and col.column.lower() not in exclude|map('lower') -%}\n      {% do include_cols.append(col) %}\n    {%- endif %}\n  {%- endfor %}\n\n\n  {%- for col in include_cols -%}\n    select\n      {%- for exclude_col in exclude %}\n        {{ exclude_col }},\n      {%- endfor %}\n\n      cast('{{ col.column }}' as {{ dbt_utils.type_string() }}) as {{ field_name }},\n      cast({{ col.column }} as {{ cast_to }}) as {{ value_name }}\n\n    from {{ relation }}\n\n    {% if not loop.last -%}\n      union all\n    {% endif -%}\n  {%- endfor -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.unpivot", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/unpivot.sql", "original_file_path": "macros/sql/unpivot.sql", "resource_type": "macro", "name": "unpivot", "macro_sql": "{% macro unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n\n    {% if table %}\n        {% do exceptions.warn(\"Warning: the `unpivot` macro no longer accepts a `table` parameter. This parameter will be deprecated in a future release of dbt-utils. Use the `relation` parameter instead\") %}\n    {% endif %}\n\n    {% if relation and table %}\n        {{ exceptions.raise_compiler_error(\"Error: both the `relation` and `table` parameters were provided to `unpivot` macro. Choose one only (we recommend `relation`).\") }}\n    {% elif not relation and table %}\n        {% set relation=table %}\n    {% elif not relation and not table %}\n        {{ exceptions.raise_compiler_error(\"Error: argument `relation` is required for `unpivot` macro.\") }}\n    {% endif %}\n\n  {%- set exclude = exclude if exclude is not none else [] %}\n  {%- set remove = remove if remove is not none else [] %}\n\n  {%- set include_cols = [] %}\n\n  {%- set table_columns = {} %}\n\n  {%- do table_columns.update({relation: []}) %}\n\n  {%- do dbt_utils._is_relation(relation, 'unpivot') -%}\n  {%- set cols = adapter.get_columns_in_relation(relation) %}\n\n  {%- for col in cols -%}\n    {%- if col.column.lower() not in remove|map('lower') and col.column.lower() not in exclude|map('lower') -%}\n      {% do include_cols.append(col) %}\n    {%- endif %}\n  {%- endfor %}\n\n\n  {%- for col in include_cols -%}\n    select\n      {%- for exclude_col in exclude %}\n        {{ exclude_col }},\n      {%- endfor %}\n\n      cast('{{ col.column }}' as {{ dbt_utils.type_string() }}) as {{ field_name }},\n      cast({{ col.column }} as {{ cast_to }}) as {{ value_name }}\n\n    from {{ relation }}\n\n    {% if not loop.last -%}\n      union all\n    {% endif -%}\n  {%- endfor -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.union_relations": {"raw_sql": "{%- macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name=none) -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. -#}\n    {%- if not execute %}\n        {{ return('') }}\n    {% endif -%}\n\n    {%- set column_override = column_override if column_override is not none else {} -%}\n    {%- set source_column_name = source_column_name if source_column_name is not none else '_dbt_source_relation' -%}\n\n    {%- set relation_columns = {} -%}\n    {%- set column_superset = {} -%}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) -%}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) -%}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing -#}\n        {%- if exclude and col.column in exclude -%}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include -%}\n\n        {#- Otherwise add the column to the column superset -#}\n        {%- else -%}\n\n            {#- update the list of columns in this relation -#}\n            {%- do relation_columns[relation].append(col.column) -%}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] -%}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) -%}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) -%}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- set ordered_column_names = column_superset.keys() -%}\n\n    {%- for relation in relations %}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif -%}\n\n                {%- endfor %}\n\n            from {{ relation }}\n        )\n\n        {% if not loop.last -%}\n            union all\n        {% endif -%}\n\n    {%- endfor -%}\n\n{%- endmacro -%}\n\n{%- macro union_tables(tables, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_table') -%}\n\n    {%- do exceptions.warn(\"Warning: the `union_tables` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `union_relations` macro instead\") -%}\n\n    {{ return(dbt_utils.union_relations(tables, column_override, include, exclude, source_column_name)) }}\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.union_relations", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/union.sql", "original_file_path": "macros/sql/union.sql", "resource_type": "macro", "name": "union_relations", "macro_sql": "{%- macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name=none) -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. -#}\n    {%- if not execute %}\n        {{ return('') }}\n    {% endif -%}\n\n    {%- set column_override = column_override if column_override is not none else {} -%}\n    {%- set source_column_name = source_column_name if source_column_name is not none else '_dbt_source_relation' -%}\n\n    {%- set relation_columns = {} -%}\n    {%- set column_superset = {} -%}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) -%}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) -%}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing -#}\n        {%- if exclude and col.column in exclude -%}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include -%}\n\n        {#- Otherwise add the column to the column superset -#}\n        {%- else -%}\n\n            {#- update the list of columns in this relation -#}\n            {%- do relation_columns[relation].append(col.column) -%}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] -%}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) -%}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) -%}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- set ordered_column_names = column_superset.keys() -%}\n\n    {%- for relation in relations %}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif -%}\n\n                {%- endfor %}\n\n            from {{ relation }}\n        )\n\n        {% if not loop.last -%}\n            union all\n        {% endif -%}\n\n    {%- endfor -%}\n\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.union_tables": {"raw_sql": "{%- macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name=none) -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. -#}\n    {%- if not execute %}\n        {{ return('') }}\n    {% endif -%}\n\n    {%- set column_override = column_override if column_override is not none else {} -%}\n    {%- set source_column_name = source_column_name if source_column_name is not none else '_dbt_source_relation' -%}\n\n    {%- set relation_columns = {} -%}\n    {%- set column_superset = {} -%}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) -%}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) -%}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing -#}\n        {%- if exclude and col.column in exclude -%}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include -%}\n\n        {#- Otherwise add the column to the column superset -#}\n        {%- else -%}\n\n            {#- update the list of columns in this relation -#}\n            {%- do relation_columns[relation].append(col.column) -%}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] -%}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) -%}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) -%}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- set ordered_column_names = column_superset.keys() -%}\n\n    {%- for relation in relations %}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif -%}\n\n                {%- endfor %}\n\n            from {{ relation }}\n        )\n\n        {% if not loop.last -%}\n            union all\n        {% endif -%}\n\n    {%- endfor -%}\n\n{%- endmacro -%}\n\n{%- macro union_tables(tables, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_table') -%}\n\n    {%- do exceptions.warn(\"Warning: the `union_tables` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `union_relations` macro instead\") -%}\n\n    {{ return(dbt_utils.union_relations(tables, column_override, include, exclude, source_column_name)) }}\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.union_tables", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/union.sql", "original_file_path": "macros/sql/union.sql", "resource_type": "macro", "name": "union_tables", "macro_sql": "{%- macro union_tables(tables, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_table') -%}\n\n    {%- do exceptions.warn(\"Warning: the `union_tables` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `union_relations` macro instead\") -%}\n\n    {{ return(dbt_utils.union_relations(tables, column_override, include, exclude, source_column_name)) }}\n\n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.group_by": {"raw_sql": "{%- macro group_by(n) -%}\n\n  group by {% for i in range(1, n + 1) -%}\n      {{ i }}{{ ',' if not loop.last }}   \n   {%- endfor -%}\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.group_by", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/groupby.sql", "original_file_path": "macros/sql/groupby.sql", "resource_type": "macro", "name": "group_by", "macro_sql": "{%- macro group_by(n) -%}\n\n  group by {% for i in range(1, n + 1) -%}\n      {{ i }}{{ ',' if not loop.last }}   \n   {%- endfor -%}\n\n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.surrogate_key": {"raw_sql": "{%- macro surrogate_key(field_list) -%}\n\n\n{%- if varargs|length >= 1 %}\n\n{%- do exceptions.warn(\"Warning: the `surrogate_key` macro now takes a single list argument instead of multiple string arguments. Support for multiple string arguments will be deprecated in a future release of dbt-utils.\") -%}\n\n{# first argument is not included in varargs, so add first element to field_list_xf #}\n{%- set field_list_xf = [field_list] -%}\n\n{%- for field in varargs %}\n{%- set _ = field_list_xf.append(field) -%}\n{%- endfor -%}\n\n{%- else -%}\n\n{# if using list, just set field_list_xf as field_list #}\n{%- set field_list_xf = field_list -%}\n\n{%- endif -%}\n\n\n{%- set fields = [] -%}\n\n{%- for field in field_list_xf -%}\n\n    {%- set _ = fields.append(\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt_utils.type_string() ~ \"), '')\"\n    ) -%}\n\n    {%- if not loop.last %}\n        {%- set _ = fields.append(\"'-'\") -%}\n    {%- endif -%}\n\n{%- endfor -%}\n\n{{dbt_utils.hash(dbt_utils.concat(fields))}}\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.surrogate_key", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/surrogate_key.sql", "original_file_path": "macros/sql/surrogate_key.sql", "resource_type": "macro", "name": "surrogate_key", "macro_sql": "{%- macro surrogate_key(field_list) -%}\n\n\n{%- if varargs|length >= 1 %}\n\n{%- do exceptions.warn(\"Warning: the `surrogate_key` macro now takes a single list argument instead of multiple string arguments. Support for multiple string arguments will be deprecated in a future release of dbt-utils.\") -%}\n\n{# first argument is not included in varargs, so add first element to field_list_xf #}\n{%- set field_list_xf = [field_list] -%}\n\n{%- for field in varargs %}\n{%- set _ = field_list_xf.append(field) -%}\n{%- endfor -%}\n\n{%- else -%}\n\n{# if using list, just set field_list_xf as field_list #}\n{%- set field_list_xf = field_list -%}\n\n{%- endif -%}\n\n\n{%- set fields = [] -%}\n\n{%- for field in field_list_xf -%}\n\n    {%- set _ = fields.append(\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt_utils.type_string() ~ \"), '')\"\n    ) -%}\n\n    {%- if not loop.last %}\n        {%- set _ = fields.append(\"'-'\") -%}\n    {%- endif -%}\n\n{%- endfor -%}\n\n{{dbt_utils.hash(dbt_utils.concat(fields))}}\n\n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.safe_add": {"raw_sql": "{%- macro safe_add() -%}\n\n{% set fields = [] %}\n\n{%- for field in varargs -%}\n\n    {% do fields.append(\"coalesce(\" ~ field ~ \", 0)\") %}\n\n{%- endfor -%}\n\n{{ fields|join(' +\\n  ') }}\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.safe_add", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/safe_add.sql", "original_file_path": "macros/sql/safe_add.sql", "resource_type": "macro", "name": "safe_add", "macro_sql": "{%- macro safe_add() -%}\n\n{% set fields = [] %}\n\n{%- for field in varargs -%}\n\n    {% do fields.append(\"coalesce(\" ~ field ~ \", 0)\") %}\n\n{%- endfor -%}\n\n{{ fields|join(' +\\n  ') }}\n\n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.nullcheck": {"raw_sql": "{% macro nullcheck(cols) %}\n{%- for col in cols %}\n\n    {% if col.is_string() -%}\n\n    nullif({{col.name}},'') as {{col.name}}\n\n    {%- else -%}\n\n    {{col.name}}\n\n    {%- endif -%}\n\n{%- if not loop.last -%} , {%- endif -%}\n\n{%- endfor -%}\n{% endmacro %}", "unique_id": "macro.dbt_utils.nullcheck", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/nullcheck.sql", "original_file_path": "macros/sql/nullcheck.sql", "resource_type": "macro", "name": "nullcheck", "macro_sql": "{% macro nullcheck(cols) %}\n{%- for col in cols %}\n\n    {% if col.is_string() -%}\n\n    nullif({{col.name}},'') as {{col.name}}\n\n    {%- else -%}\n\n    {{col.name}}\n\n    {%- endif -%}\n\n{%- if not loop.last -%} , {%- endif -%}\n\n{%- endfor -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_column_values": {"raw_sql": "{#\nThis macro fetches the unique values for `column` in the table `table`\n\nArguments:\n    table: A model `ref`, or a schema.table string for the table to query (Required)\n    column: The column to query for unique values\n    max_records: If provided, the maximum number of unique records to return (default: none)\n\nReturns:\n    A list of distinct values for the specified columns\n#}\n\n{% macro get_column_values(table, column, max_records=none, default=none) -%}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n{#--  #}\n\n    {%- set target_relation = adapter.get_relation(database=table.database,\n                                          schema=table.schema,\n                                         identifier=table.identifier) -%}\n\n    {%- call statement('get_column_values', fetch_result=true) %}\n\n        {%- if not target_relation and default is none -%}\n\n          {{ exceptions.raise_compiler_error(\"In get_column_values(): relation \" ~ table ~ \" does not exist and no default value was provided.\") }}\n\n        {%- elif not target_relation and default is not none -%}\n\n          {{ log(\"Relation \" ~ table ~ \" does not exist. Returning the default value: \" ~ default) }}\n\n          {{ return(default) }}\n\n        {%- else -%}\n\n            select\n                {{ column }} as value\n\n            from {{ target_relation }}\n            group by 1\n            order by count(*) desc\n\n            {% if max_records is not none %}\n            limit {{ max_records }}\n            {% endif %}\n\n        {% endif %}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_column_values') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values) }}\n    {%- else -%}\n        {{ return(default) }}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.get_column_values", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/get_column_values.sql", "original_file_path": "macros/sql/get_column_values.sql", "resource_type": "macro", "name": "get_column_values", "macro_sql": "{% macro get_column_values(table, column, max_records=none, default=none) -%}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n{#--  #}\n\n    {%- set target_relation = adapter.get_relation(database=table.database,\n                                          schema=table.schema,\n                                         identifier=table.identifier) -%}\n\n    {%- call statement('get_column_values', fetch_result=true) %}\n\n        {%- if not target_relation and default is none -%}\n\n          {{ exceptions.raise_compiler_error(\"In get_column_values(): relation \" ~ table ~ \" does not exist and no default value was provided.\") }}\n\n        {%- elif not target_relation and default is not none -%}\n\n          {{ log(\"Relation \" ~ table ~ \" does not exist. Returning the default value: \" ~ default) }}\n\n          {{ return(default) }}\n\n        {%- else -%}\n\n            select\n                {{ column }} as value\n\n            from {{ target_relation }}\n            group by 1\n            order by count(*) desc\n\n            {% if max_records is not none %}\n            limit {{ max_records }}\n            {% endif %}\n\n        {% endif %}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_column_values') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values) }}\n    {%- else -%}\n        {{ return(default) }}\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pivot": {"raw_sql": "{#\nPivot values from rows to columns.\n\nExample:\n\n    Input: `public.test`\n\n    | size | color |\n    |------+-------|\n    | S    | red   |\n    | S    | blue  |\n    | S    | red   |\n    | M    | red   |\n\n    select\n      size,\n      {{ dbt_utils.pivot('color', dbt_utils.get_column_values('public.test',\n                                                              'color')) }}\n    from public.test\n    group by size\n\n    Output:\n\n    | size | red | blue |\n    |------+-----+------|\n    | S    | 2   | 1    |\n    | M    | 1   | 0    |\n\nArguments:\n    column: Column name, required\n    values: List of row values to turn into columns, required\n    alias: Whether to create column aliases, default is True\n    agg: SQL aggregation function, default is sum\n    cmp: SQL value comparison, default is =\n    prefix: Column alias prefix, default is blank\n    suffix: Column alias postfix, default is blank\n    then_value: Value to use if comparison succeeds, default is 1\n    else_value: Value to use if comparison fails, default is 0\n    quote_identifiers: Whether to surround column aliases with double quotes, default is true\n#}\n\n{% macro pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True) %}\n  {% for v in values %}\n    {{ agg }}(\n      case\n      when {{ column }} {{ cmp }} '{{ v }}'\n        then {{ then_value }}\n      else {{ else_value }}\n      end\n    )\n    {% if alias %}\n      {% if quote_identifiers %}\n            as {{ adapter.quote(prefix ~ v ~ suffix) }}\n      {% else %}\n        as {{prefix ~ v ~ suffix }}\n      {% endif %}\n    {% endif %}\n    {% if not loop.last %},{% endif %}\n  {% endfor %}\n{% endmacro %}", "unique_id": "macro.dbt_utils.pivot", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/pivot.sql", "original_file_path": "macros/sql/pivot.sql", "resource_type": "macro", "name": "pivot", "macro_sql": "{% macro pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True) %}\n  {% for v in values %}\n    {{ agg }}(\n      case\n      when {{ column }} {{ cmp }} '{{ v }}'\n        then {{ then_value }}\n      else {{ else_value }}\n      end\n    )\n    {% if alias %}\n      {% if quote_identifiers %}\n            as {{ adapter.quote(prefix ~ v ~ suffix) }}\n      {% else %}\n        as {{prefix ~ v ~ suffix }}\n      {% endif %}\n    {% endif %}\n    {% if not loop.last %},{% endif %}\n  {% endfor %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_query_results_as_dict": {"raw_sql": "{% macro get_query_results_as_dict(query) %}\n{# This macro returns a dictionary of the form {column_name: (tuple_of_results)} #}\n\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {% set sql_results={} %}\n\n    {%- if execute -%}\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\n        {% for column_name, column in sql_results_table.items() %}\n            {% do sql_results.update({column_name: column.values()}) %}\n        {% endfor %}\n    {%- endif -%}\n\n    {{ return(sql_results) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_query_results_as_dict", "package_name": "dbt_utils", "root_path": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils", "path": "macros/sql/get_query_results_as_dict.sql", "original_file_path": "macros/sql/get_query_results_as_dict.sql", "resource_type": "macro", "name": "get_query_results_as_dict", "macro_sql": "{% macro get_query_results_as_dict(query) %}\n{# This macro returns a dictionary of the form {column_name: (tuple_of_results)} #}\n\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {% set sql_results={} %}\n\n    {%- if execute -%}\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\n        {% for column_name, column in sql_results_table.items() %}\n            {% do sql_results.update({column_name: column.values()}) %}\n        {% endfor %}\n    {%- endif -%}\n\n    {{ return(sql_results) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}}, "docs": {"dbt.__overview__": {"unique_id": "dbt.__overview__", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "overview.md", "original_file_path": "docs/overview.md", "file_contents": "{% docs __overview__ %}\n\n### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--models` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/overview)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [chat](https://slack.getdbt.com/) on Slack for live questions and support.\n\n{% enddocs %}", "name": "__overview__", "block_contents": "### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--models` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/overview)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [chat](https://slack.getdbt.com/) on Slack for live questions and support."}}, "disabled": [], "generated_at": "2020-05-05T23:24:18.963099Z", "parent_map": {"model.salesforce.salesforce_sales_snapshot": ["model.salesforce.salesforce_opportunity_enhanced"], "model.salesforce.salesforce_owner_performance": ["model.salesforce.opportunity_aggregation_by_owner", "model.salesforce.stg_salesforce_user"], "model.salesforce.salesforce_manager_performance": ["model.salesforce.opportunity_aggregation_by_owner", "model.salesforce.stg_salesforce_user", "model.salesforce.stg_salesforce_user_role"], "model.salesforce.salesforce_opportunity_enhanced": ["model.salesforce.stg_salesforce_account", "model.salesforce.stg_salesforce_opportunity", "model.salesforce.stg_salesforce_user"], "model.salesforce.opportunity_aggregation_by_owner": ["model.salesforce.salesforce_opportunity_enhanced", "model.salesforce.stg_salesforce_user"], "model.salesforce.stg_salesforce_opportunity": [], "model.salesforce.stg_salesforce_user": [], "model.salesforce.stg_salesforce_user_role": [], "model.salesforce.stg_salesforce_account": [], "test.salesforce.not_null_stg_salesforce_account_account_id": ["model.salesforce.stg_salesforce_account"], "test.salesforce.unique_stg_salesforce_account_account_id": ["model.salesforce.stg_salesforce_account"], "test.salesforce.not_null_stg_salesforce_opportunity_opportunity_id": ["model.salesforce.stg_salesforce_opportunity"], "test.salesforce.unique_stg_salesforce_opportunity_opportunity_id": ["model.salesforce.stg_salesforce_opportunity"], "test.salesforce.not_null_stg_salesforce_user_user_id": ["model.salesforce.stg_salesforce_user"], "test.salesforce.unique_stg_salesforce_user_user_id": ["model.salesforce.stg_salesforce_user"], "test.salesforce.not_null_stg_salesforce_user_role_user_role_id": ["model.salesforce.stg_salesforce_user_role"], "test.salesforce.unique_stg_salesforce_user_role_user_role_id": ["model.salesforce.stg_salesforce_user_role"]}, "child_map": {"model.salesforce.salesforce_sales_snapshot": [], "model.salesforce.salesforce_owner_performance": [], "model.salesforce.salesforce_manager_performance": [], "model.salesforce.salesforce_opportunity_enhanced": ["model.salesforce.opportunity_aggregation_by_owner", "model.salesforce.salesforce_sales_snapshot"], "model.salesforce.opportunity_aggregation_by_owner": ["model.salesforce.salesforce_manager_performance", "model.salesforce.salesforce_owner_performance"], "model.salesforce.stg_salesforce_opportunity": ["model.salesforce.salesforce_opportunity_enhanced", "test.salesforce.not_null_stg_salesforce_opportunity_opportunity_id", "test.salesforce.unique_stg_salesforce_opportunity_opportunity_id"], "model.salesforce.stg_salesforce_user": ["model.salesforce.opportunity_aggregation_by_owner", "model.salesforce.salesforce_manager_performance", "model.salesforce.salesforce_opportunity_enhanced", "model.salesforce.salesforce_owner_performance", "test.salesforce.not_null_stg_salesforce_user_user_id", "test.salesforce.unique_stg_salesforce_user_user_id"], "model.salesforce.stg_salesforce_user_role": ["model.salesforce.salesforce_manager_performance", "test.salesforce.not_null_stg_salesforce_user_role_user_role_id", "test.salesforce.unique_stg_salesforce_user_role_user_role_id"], "model.salesforce.stg_salesforce_account": ["model.salesforce.salesforce_opportunity_enhanced", "test.salesforce.not_null_stg_salesforce_account_account_id", "test.salesforce.unique_stg_salesforce_account_account_id"], "test.salesforce.not_null_stg_salesforce_account_account_id": [], "test.salesforce.unique_stg_salesforce_account_account_id": [], "test.salesforce.not_null_stg_salesforce_opportunity_opportunity_id": [], "test.salesforce.unique_stg_salesforce_opportunity_opportunity_id": [], "test.salesforce.not_null_stg_salesforce_user_user_id": [], "test.salesforce.unique_stg_salesforce_user_user_id": [], "test.salesforce.not_null_stg_salesforce_user_role_user_role_id": [], "test.salesforce.unique_stg_salesforce_user_role_user_role_id": []}, "metadata": {"project_id": "a8ff6c9514c35c853b350382534fb624", "user_id": "17115028-2cdc-4f57-abce-f8b742a5937d", "send_anonymous_usage_stats": true, "adapter_type": "bigquery"}, "files": {"/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/core.sql": {"path": {"searched_path": "macros", "relative_path": "core.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "9dde6e3cf4b01799f44b1c6d4f23e77f471567a1cbbeab763da5032f0d102821"}, "nodes": [], "docs": [], "macros": ["macro.dbt.statement", "macro.dbt.noop_statement"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/helpers.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/helpers.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "f29316a03082e0c4e9e0b9cc5d73af75206c9db845d01b1e2068d7bb2ab58090"}, "nodes": [], "docs": [], "macros": ["macro.dbt.run_hooks", "macro.dbt.column_list", "macro.dbt.column_list_for_create_table", "macro.dbt.make_hook_config", "macro.dbt.before_begin", "macro.dbt.in_transaction", "macro.dbt.after_commit", "macro.dbt.drop_relation_if_exists", "macro.dbt.load_relation"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/snapshot/snapshot_merge.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/snapshot/snapshot_merge.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "5c6f5982ea4f6a4efe7106b9706c78197d355ef5a50d9ca1c254ba9fe8b5d114"}, "nodes": [], "docs": [], "macros": ["macro.dbt.snapshot_merge_sql", "macro.dbt.default__snapshot_merge_sql"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/snapshot/strategies.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/snapshot/strategies.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "3f88751a98bef086ae59d67a8090e28140aebad8c3c4dbbf7fd462e422d808da"}, "nodes": [], "docs": [], "macros": ["macro.dbt.strategy_dispatch", "macro.dbt.snapshot_hash_arguments", "macro.dbt.default__snapshot_hash_arguments", "macro.dbt.snapshot_get_time", "macro.dbt.default__snapshot_get_time", "macro.dbt.snapshot_timestamp_strategy", "macro.dbt.snapshot_string_as_time", "macro.dbt.default__snapshot_string_as_time", "macro.dbt.snapshot_check_all_get_existing_columns", "macro.dbt.snapshot_check_strategy"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/snapshot/snapshot.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/snapshot/snapshot.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "3f8c4854169daa7257c62bb2ecf4ee532d0e87b59ed2151382e6c4728b259cce"}, "nodes": [], "docs": [], "macros": ["macro.dbt.create_columns", "macro.dbt.default__create_columns", "macro.dbt.post_snapshot", "macro.dbt.default__post_snapshot", "macro.dbt.snapshot_staging_table_inserts", "macro.dbt.snapshot_staging_table_updates", "macro.dbt.build_snapshot_table", "macro.dbt.get_or_create_relation", "macro.dbt.build_snapshot_staging_table", "macro.dbt.materialization_snapshot_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/seed/seed.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/seed/seed.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "3108894047b1bbf22594ec0e7e1cc9769c58bf3caa4f699b6827aa67dcdbc5dd"}, "nodes": [], "docs": [], "macros": ["macro.dbt.create_csv_table", "macro.dbt.reset_csv_table", "macro.dbt.load_csv_rows", "macro.dbt.default__create_csv_table", "macro.dbt.default__reset_csv_table", "macro.dbt.get_seed_column_quoted_csv", "macro.dbt.basic_load_csv_rows", "macro.dbt.default__load_csv_rows", "macro.dbt.materialization_seed_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/incremental/helpers.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/incremental/helpers.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "c37f9127e9c8a575db6ac76470aa8e4bea07d5d8c714511349a74607e32306e1"}, "nodes": [], "docs": [], "macros": ["macro.dbt.incremental_upsert"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/incremental/incremental.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/incremental/incremental.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "f29fd9555f8f24be85b629603b4499e3eac7dde2e52d92343921b6506fad07c7"}, "nodes": [], "docs": [], "macros": ["macro.dbt.materialization_incremental_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/common/merge.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/common/merge.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "6f9ce33fdf66a2fa542434570298490548047e6e0ae845d82424bac51bba2322"}, "nodes": [], "docs": [], "macros": ["macro.dbt.get_merge_sql", "macro.dbt.get_delete_insert_merge_sql", "macro.dbt.get_insert_overwrite_merge_sql", "macro.dbt.default__get_merge_sql", "macro.dbt.get_quoted_csv", "macro.dbt.common_get_delete_insert_merge_sql", "macro.dbt.default__get_delete_insert_merge_sql", "macro.dbt.default__get_insert_overwrite_merge_sql"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/table/table.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/table/table.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "7532a98937b3f467b639610ab7d68b121f94f2570576e84ebb285e326c52d93f"}, "nodes": [], "docs": [], "macros": ["macro.dbt.materialization_table_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/view/view.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/view/view.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "495441a9fa472aa6e369a9e87c469e3e82bd2f5cdf90605a3e574b6bfcf9a999"}, "nodes": [], "docs": [], "macros": ["macro.dbt.materialization_view_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/view/create_or_replace_view.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/view/create_or_replace_view.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "f248f585af455af494d885fb929bcca529e44e080670740feb2c792674599eba"}, "nodes": [], "docs": [], "macros": ["macro.dbt.handle_existing_table", "macro.dbt.default__handle_existing_table", "macro.dbt.create_or_replace_view"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/get_custom_alias.sql": {"path": {"searched_path": "macros", "relative_path": "etc/get_custom_alias.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "a5e6fbf352700a021e2a4726818beb8b164bb8f29d664fbb68aa8fe142ec589e"}, "nodes": [], "docs": [], "macros": ["macro.dbt.generate_alias_name"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/query.sql": {"path": {"searched_path": "macros", "relative_path": "etc/query.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "332f51dd1615c90e372c87aeb65651c2a66a6f8313be34dfae1e91eb7c5e1316"}, "nodes": [], "docs": [], "macros": ["macro.dbt.run_query"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/is_incremental.sql": {"path": {"searched_path": "macros", "relative_path": "etc/is_incremental.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "08a74e7b1a42476e996dedbd89c97ffb47e95c864b9fec6ddad6e9771eeeb7f1"}, "nodes": [], "docs": [], "macros": ["macro.dbt.is_incremental"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/get_relation_comment.sql": {"path": {"searched_path": "macros", "relative_path": "etc/get_relation_comment.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "653267a61c95a535c6d47f8baea9dbbc533fcb3c671e6cd1d8ac5419d218da26"}, "nodes": [], "docs": [], "macros": ["macro.dbt.table_options", "macro.dbt.get_relation_comment"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/datetime.sql": {"path": {"searched_path": "macros", "relative_path": "etc/datetime.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "0ebb8f28f68f1506962974dd513917a68a196f0cabf70ce3a43d9a72159ddc6c"}, "nodes": [], "docs": [], "macros": ["macro.dbt.convert_datetime", "macro.dbt.dates_in_range", "macro.dbt.partition_range", "macro.dbt.py_current_timestring"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/get_custom_schema.sql": {"path": {"searched_path": "macros", "relative_path": "etc/get_custom_schema.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "3a7d4b9d5105010dd92327027f81c9e079b9a5cd68098b02682fedde376fa5de"}, "nodes": [], "docs": [], "macros": ["macro.dbt.generate_schema_name", "macro.dbt.generate_schema_name_for_env"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/get_custom_database.sql": {"path": {"searched_path": "macros", "relative_path": "etc/get_custom_database.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "2b76c8cc7aede4270f5e37d5623788978688e5c382f4dc4e222453a592b0b532"}, "nodes": [], "docs": [], "macros": ["macro.dbt.generate_database_name"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/adapters/common.sql": {"path": {"searched_path": "macros", "relative_path": "adapters/common.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "b20f3411a1cb7997bdbbe6df7867d993d405230b63c8bf14710eb9fefd96ca56"}, "nodes": [], "docs": [], "macros": ["macro.dbt.adapter_macro", "macro.dbt.get_columns_in_query", "macro.dbt.default__get_columns_in_query", "macro.dbt.create_schema", "macro.dbt.default__create_schema", "macro.dbt.drop_schema", "macro.dbt.default__drop_schema", "macro.dbt.create_table_as", "macro.dbt.default__create_table_as", "macro.dbt.create_view_as", "macro.dbt.default__create_view_as", "macro.dbt.get_catalog", "macro.dbt.default__get_catalog", "macro.dbt.get_columns_in_relation", "macro.dbt.sql_convert_columns_in_relation", "macro.dbt.default__get_columns_in_relation", "macro.dbt.alter_column_type", "macro.dbt.default__alter_column_type", "macro.dbt.drop_relation", "macro.dbt.default__drop_relation", "macro.dbt.truncate_relation", "macro.dbt.default__truncate_relation", "macro.dbt.rename_relation", "macro.dbt.default__rename_relation", "macro.dbt.information_schema_name", "macro.dbt.default__information_schema_name", "macro.dbt.list_schemas", "macro.dbt.default__list_schemas", "macro.dbt.check_schema_exists", "macro.dbt.default__check_schema_exists", "macro.dbt.list_relations_without_caching", "macro.dbt.default__list_relations_without_caching", "macro.dbt.current_timestamp", "macro.dbt.default__current_timestamp", "macro.dbt.collect_freshness", "macro.dbt.default__collect_freshness", "macro.dbt.make_temp_relation", "macro.dbt.default__make_temp_relation", "macro.dbt.set_sql_header"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/schema_tests/relationships.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/relationships.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "4f50036d55fcfe56fbe7d283b8d29b6af935ca7e9abffa57043e20e5680609be"}, "nodes": [], "docs": [], "macros": ["macro.dbt.test_relationships"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/schema_tests/not_null.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/not_null.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "a7fd6f2e1f9645059f33cd6a94598a2d72a7bf9c5d568eefc604b1824640efc7"}, "nodes": [], "docs": [], "macros": ["macro.dbt.test_not_null"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/schema_tests/unique.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/unique.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "a4d53f54a4fa7e846d347418471ebf00e364f4e850f2655e3ce8c6fb49e83bf4"}, "nodes": [], "docs": [], "macros": ["macro.dbt.test_unique"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/schema_tests/accepted_values.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/accepted_values.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "b7c3adabeeb96b9e19e19a8fe0e9f56dcc5af20804a613f71f100eba8ae520a9"}, "nodes": [], "docs": [], "macros": ["macro.dbt.test_accepted_values"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery/macros/etc.sql": {"path": {"searched_path": "macros", "relative_path": "etc.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery"}, "checksum": {"name": "sha256", "checksum": "467d7832ff07676e804823f64e0073122622192f90066f38333800f504e5187f"}, "nodes": [], "docs": [], "macros": ["macro.dbt_bigquery.date_sharded_table"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery/macros/catalog.sql": {"path": {"searched_path": "macros", "relative_path": "catalog.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery"}, "checksum": {"name": "sha256", "checksum": "01c0386cbd628f9fbb8288ce344618c1d0880e3556d435370b18707f45a6eee1"}, "nodes": [], "docs": [], "macros": ["macro.dbt_bigquery.bigquery__get_catalog"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery/macros/adapters.sql": {"path": {"searched_path": "macros", "relative_path": "adapters.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery"}, "checksum": {"name": "sha256", "checksum": "d5d4cc4fac4666ae32973f6f219006e6764a5d472a20343803bfb94f347f5d7e"}, "nodes": [], "docs": [], "macros": ["macro.dbt_bigquery.partition_by", "macro.dbt_bigquery.cluster_by", "macro.dbt_bigquery.bigquery_table_options", "macro.dbt_bigquery.bigquery__create_table_as", "macro.dbt_bigquery.bigquery__create_view_as", "macro.dbt_bigquery.bigquery__create_schema", "macro.dbt_bigquery.bigquery__drop_schema", "macro.dbt_bigquery.bigquery__drop_relation", "macro.dbt_bigquery.bigquery__get_columns_in_relation", "macro.dbt_bigquery.bigquery__list_relations_without_caching", "macro.dbt_bigquery.bigquery__current_timestamp", "macro.dbt_bigquery.bigquery__snapshot_string_as_time", "macro.dbt_bigquery.bigquery__list_schemas", "macro.dbt_bigquery.bigquery__check_schema_exists"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery/macros/materializations/seed.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/seed.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery"}, "checksum": {"name": "sha256", "checksum": "760cff0cd2f3ba0a563a859fca7bc62ecd4853a91eabb55422a66f2f72490d27"}, "nodes": [], "docs": [], "macros": ["macro.dbt_bigquery.bigquery__create_csv_table", "macro.dbt_bigquery.bigquery__reset_csv_table", "macro.dbt_bigquery.bigquery__load_csv_rows"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery/macros/materializations/view.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/view.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery"}, "checksum": {"name": "sha256", "checksum": "2385f26809c0ed29003fe1f0731ecf418ce6bea7a1352067b2ff965b2b54c965"}, "nodes": [], "docs": [], "macros": ["macro.dbt_bigquery.bigquery__handle_existing_table", "macro.dbt_bigquery.materialization_view_bigquery"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery/macros/materializations/table.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/table.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery"}, "checksum": {"name": "sha256", "checksum": "b035cc45417cec1f1975d43afac5c2ab596edcf648ae73ae8f8aca8f3cff3c66"}, "nodes": [], "docs": [], "macros": ["macro.dbt_bigquery.make_date_partitioned_table", "macro.dbt_bigquery.materialization_table_bigquery"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery/macros/materializations/incremental.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/incremental.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery"}, "checksum": {"name": "sha256", "checksum": "7be372d709c2d0e144eb7315f2322a06ac9c1a084459605745d22089cffb3ea8"}, "nodes": [], "docs": [], "macros": ["macro.dbt_bigquery.dbt_bigquery_validate_get_incremental_strategy", "macro.dbt_bigquery.bq_insert_overwrite", "macro.dbt_bigquery.materialization_incremental_bigquery"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery/macros/materializations/snapshot.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/snapshot.sql", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/bigquery"}, "checksum": {"name": "sha256", "checksum": "5e904dbcef06e71b534b0c95c4b4c82ecf8cabc4df637ea6c67be62aed53c028"}, "nodes": [], "docs": [], "macros": ["macro.dbt_bigquery.bigquery__snapshot_hash_arguments", "macro.dbt_bigquery.bigquery__create_columns", "macro.dbt_bigquery.bigquery__post_snapshot"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/except.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/except.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6695ddb45bb31cebda6ddbd4d41b18552cf74cf5752c8a3c4ecaee4304274fa4"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.except", "macro.dbt_utils.default__except", "macro.dbt_utils.bigquery__except"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/replace.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/replace.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "31b87b44de1b4c36337a04baf357b92aaec9968c4b24361e65f345097c6106b8"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.replace", "macro.dbt_utils.default__replace"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/concat.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/concat.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "d19c295900c2c74c9baff4ce07f70102b0f282ae09fa3979a16bbe8f62e9d04a"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.concat", "macro.dbt_utils.default__concat", "macro.dbt_utils.alternative_concat", "macro.dbt_utils.redshift__concat", "macro.dbt_utils.snowflake__concat"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/identifer.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/identifer.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "bdaaf100faa62e971a7e2b766f21127cb9d9fd0aa11412c2840dc66f1355aaae"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.identifier", "macro.dbt_utils.default__identifier", "macro.dbt_utils.bigquery__identifier"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/datatypes.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/datatypes.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "4845d6c9a9e47dadfc39aa4e1bdd47c0b68152def7e3825cb700a1831015ab11"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.type_string", "macro.dbt_utils.default__type_string", "macro.dbt_utils.redshift__type_string", "macro.dbt_utils.postgres__type_string", "macro.dbt_utils.snowflake__type_string", "macro.dbt_utils.type_timestamp", "macro.dbt_utils.default__type_timestamp", "macro.dbt_utils.snowflake__type_timestamp", "macro.dbt_utils.type_float", "macro.dbt_utils.default__type_float", "macro.dbt_utils.bigquery__type_float", "macro.dbt_utils.type_numeric", "macro.dbt_utils.default__type_numeric", "macro.dbt_utils.bigquery__type_numeric", "macro.dbt_utils.type_bigint", "macro.dbt_utils.default__type_bigint", "macro.dbt_utils.bigquery__type_bigint", "macro.dbt_utils.type_int", "macro.dbt_utils.default__type_int", "macro.dbt_utils.bigquery__type_int"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/_is_relation.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/_is_relation.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "9d37d4547affe42d0f29d215fa3b68bfe00ab075aa8d988de70093b55ad6a68b"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils._is_relation"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/length.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/length.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "85f8613d4e8d7c7dbf5c2a0ff64723e6d756913271277d875683b54cece3b6b0"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.length", "macro.dbt_utils.default__length", "macro.dbt_utils.redshift__length"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/dateadd.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/dateadd.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "4463f081c3275fcf5e9e5e8af182fb2e81fafd9ac3e09d77035ea6473c843b7d"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.default__dateadd", "macro.dbt_utils.bigquery__dateadd", "macro.dbt_utils.postgres__dateadd"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/intersect.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/intersect.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "f5abb85f0b7d9e80b24ed0b3b11dd6a91b6b5b4caf0dbf0c21a070353b5b1d82"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.intersect", "macro.dbt_utils.default__intersect", "macro.dbt_utils.bigquery__intersect"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/right.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/right.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "ce8b346909fc377f131b8de6e40e49dc822da29ccd5d3add77079608a198a375"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.right", "macro.dbt_utils.default__right", "macro.dbt_utils.bigquery__right", "macro.dbt_utils.snowflake__right"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/datediff.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/datediff.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "ce3e4aecff7027028cfb3b91a6da561b63a4ec6c77320572abf20d7c4c086937"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.datediff", "macro.dbt_utils.default__datediff", "macro.dbt_utils.bigquery__datediff", "macro.dbt_utils.postgres__datediff"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/safe_cast.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/safe_cast.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1ad027695168ced61cdba224ddca8f07e861d32aab95efd30008a0bce76241ac"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.safe_cast", "macro.dbt_utils.default__safe_cast", "macro.dbt_utils.snowflake__safe_cast", "macro.dbt_utils.bigquery__safe_cast"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/hash.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/hash.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "9ac8186a8bfa84a019a05caf6fbb6ecbdd15f9965ea4739dc565115df4c20cb4"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.hash", "macro.dbt_utils.default__hash", "macro.dbt_utils.bigquery__hash"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/position.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/position.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b5d4dde3fa181616bcd106ae094cb6c75b21d14503e76c0d736d0dc65d92ceeb"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.position", "macro.dbt_utils.default__position", "macro.dbt_utils.bigquery__position"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/literal.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/literal.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "21185e8340fe4f9a3669930768bd3e2aa43c82bb83df847cfe8ed06290337402"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.string_literal", "macro.dbt_utils.default__string_literal"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/current_timestamp.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/current_timestamp.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "44bcef771179c7dcf83807fa51c5869c501272329d99eff232efe23c98eb2e7d"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.current_timestamp", "macro.dbt_utils.default__current_timestamp", "macro.dbt_utils.redshift__current_timestamp", "macro.dbt_utils.bigquery__current_timestamp", "macro.dbt_utils.current_timestamp_in_utc", "macro.dbt_utils.default__current_timestamp_in_utc", "macro.dbt_utils.snowflake__current_timestamp_in_utc", "macro.dbt_utils.postgres__current_timestamp_in_utc"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/width_bucket.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/width_bucket.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "287296cc63427c7bd046e85aed1de4aa7fc73ebb3223b7f59e4ba68a20f23de1"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.width_bucket", "macro.dbt_utils.default__width_bucket", "macro.dbt_utils.redshift__width_bucket", "macro.dbt_utils.snowflake__width_bucket"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/last_day.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/last_day.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1e207372f905a7d14f800b518761d85fedec738444b4e9ed7be02b9aeb5bbbfe"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.last_day", "macro.dbt_utils.default_last_day", "macro.dbt_utils.default__last_day", "macro.dbt_utils.postgres__last_day"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/split_part.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/split_part.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "ec1d9db903a2a00b513f90c8345682c076800e99e109228dce881b67c0e00cf7"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.split_part", "macro.dbt_utils.default__split_part", "macro.dbt_utils.bigquery__split_part"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/cross_db_utils/date_trunc.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/date_trunc.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "cb8034ac256db959d79d38e1df73845a0182a6bb66705eb4ab179158a2debb65"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.date_trunc", "macro.dbt_utils.default__date_trunc", "macro.dbt_utils.bigquery__date_trunc"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/materializations/insert_by_period_materialization.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/insert_by_period_materialization.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6f4e65d6de0fe33a5f5259507b234831a288c563f56df9eaa70ef3eb5dd3b1b8"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_period_boundaries", "macro.dbt_utils.get_period_sql", "macro.dbt_utils.materialization_insert_by_period_default"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/logger/pretty_log_format.sql": {"path": {"searched_path": "macros", "relative_path": "logger/pretty_log_format.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "788092f1026c7d2fd3398f31870caf4f81d43b686c4af633a57fafd1aeef304a"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.pretty_log_format"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/logger/pretty_time.sql": {"path": {"searched_path": "macros", "relative_path": "logger/pretty_time.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "d5cdb4ceb135e1d855367d2ecb54e63b1fd01d3c9aa074852a553de789f45e5f"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.pretty_time"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/logger/log_info.sql": {"path": {"searched_path": "macros", "relative_path": "logger/log_info.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6a0420dcc9a03bb7748026162ababb6e877a0e45d7697f77d8b228fd7c6cf717"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.log_info"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/datetime/date_spine.sql": {"path": {"searched_path": "macros", "relative_path": "datetime/date_spine.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6e164f9e7198e71e4c2f18b0478b69405288b2a5cf8958596271eee490131575"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_intervals_between", "macro.dbt_utils.date_spine"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/web/get_url_host.sql": {"path": {"searched_path": "macros", "relative_path": "web/get_url_host.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "75246509db12e34e95190175211e0331063c8ed017a0bfac1dcbfd5da79c6ce8"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_url_host"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/web/get_url_path.sql": {"path": {"searched_path": "macros", "relative_path": "web/get_url_path.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b976b094bc2a26a7b553431dc93fdefe28b129abd7155d8846e254046f02a39c"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_url_path"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/web/get_url_parameter.sql": {"path": {"searched_path": "macros", "relative_path": "web/get_url_parameter.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b10234d9d0b1030a402a6a72a94f78a0d2293661a32cec604b0ef48c50511a56"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_url_parameter"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/geo/haversine_distance.sql": {"path": {"searched_path": "macros", "relative_path": "geo/haversine_distance.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b5f48844bc062e5ad283aedbd9dd11d68863db6b0f81efbc767b384115079d62"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.haversine_distance"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/equal_rowcount.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/equal_rowcount.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "7163ce75cb298af96172c41a0ba73a184d9116a92d63889573d24a12e551f560"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_equal_rowcount"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/relationships_where.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/relationships_where.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "48c6eb8de34d6925bccf56ce59ee7d3d8dc2c1426f951b15f8ca4560125005b9"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_relationships_where"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/recency.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/recency.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b2542d28abc4e53309c744b111fb1f2f4be2cfcf4f611b4a31b37aba0fed6bc2"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_recency"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/not_constant.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/not_constant.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "8710079ef29da7534dcb9728407af27814a247fa8d17080f5d1d4c39eee44023"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_not_constant"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/at_least_one.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/at_least_one.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "cc5c686c96681f67f0e97f49cc987b6d65115e8aaf51ea487e39f7865e3d335d"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_at_least_one"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/unique_combination_of_columns.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/unique_combination_of_columns.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "785bbaca0448f809197823afd810753c6a55124ece7bec7d4befe4dbd9eb39dd"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_unique_combination_of_columns"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/cardinality_equality.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/cardinality_equality.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "e037e4539e2f94632db24ca2526fc06a489dd60663bfbb5246e1d24ac4fdcae7"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_cardinality_equality"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/expression_is_true.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/expression_is_true.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "be92c446fea64c14d543c9b9944cf725d28161cf459fa3a17ce9f7be91cb1cac"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_expression_is_true"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/equality.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/equality.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1bdac20b6a7592fe91748dfa489c964dbd433c1e1a9e9839937396b0b297a864"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_equality"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/schema_tests/mutually_exclusive_ranges.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/mutually_exclusive_ranges.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6d92959cd620e418f5faed654e21e126c956f1b370ca932675a5a7a53ace2539"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_mutually_exclusive_ranges"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/nullcheck_table.sql": {"path": {"searched_path": "macros", "relative_path": "sql/nullcheck_table.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "9fd89ad3b49bf05c5ea4769e84687510cafcf255f7e3579613d1f8588ceb19cc"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.nullcheck_table"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/generate_series.sql": {"path": {"searched_path": "macros", "relative_path": "sql/generate_series.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1ca1782077c9ffef4532460d20b9f9f7a94495cff99f1342c48e46f2cd3c070b"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_powers_of_two", "macro.dbt_utils.generate_series"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/get_relations_by_prefix.sql": {"path": {"searched_path": "macros", "relative_path": "sql/get_relations_by_prefix.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "55f34499c4fbbcb6297ea7d6d3f724a477d864221ef52b3b17f5af0275074b20"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_relations_by_prefix", "macro.dbt_utils.get_tables_by_prefix"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/get_tables_by_prefix_sql.sql": {"path": {"searched_path": "macros", "relative_path": "sql/get_tables_by_prefix_sql.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "e4eb8a02c7d6051e583231bd2f516f799611de36febf68599f8a7a74f883f08c"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_tables_by_prefix_sql", "macro.dbt_utils.default__get_tables_by_prefix_sql", "macro.dbt_utils.bigquery__get_tables_by_prefix_sql"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/star.sql": {"path": {"searched_path": "macros", "relative_path": "sql/star.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "8c0fd7e5f0dba7ca12fae6baa5532685c5bbdf3aa1489b54253f95494fc6344b"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.star"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/unpivot.sql": {"path": {"searched_path": "macros", "relative_path": "sql/unpivot.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "9568311da478ae66fbd5f56e8702c87cbaba29a76842c32d48beb8f5616ba718"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.unpivot"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/union.sql": {"path": {"searched_path": "macros", "relative_path": "sql/union.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "918da1516dd2eaf0522e2c787118bf6440d3159bdf3b9c63ade993084ed784ae"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.union_relations", "macro.dbt_utils.union_tables"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/groupby.sql": {"path": {"searched_path": "macros", "relative_path": "sql/groupby.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "ee3fb695561e40aeeed2d05a0dbea10331be8f039b07bd771e6a5741e02adead"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.group_by"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/surrogate_key.sql": {"path": {"searched_path": "macros", "relative_path": "sql/surrogate_key.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6b14db4eb5749dfb19febe1e74349b36c95dd10e6dbd174e3c2b4e6180f072bd"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.surrogate_key"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/safe_add.sql": {"path": {"searched_path": "macros", "relative_path": "sql/safe_add.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "7f544c77ed9402d2c130aa1883ab2419215bac58405ab2ec1d2d70229a94737b"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.safe_add"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/nullcheck.sql": {"path": {"searched_path": "macros", "relative_path": "sql/nullcheck.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "d2cd945bca708f6660ea54685dc57ee4abaa1266306dfb3d2e84e04174058c68"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.nullcheck"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/get_column_values.sql": {"path": {"searched_path": "macros", "relative_path": "sql/get_column_values.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "ab0317329a6a695608746064c7a1cccca7d45e908b5f796bcb30cb53fea006fc"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_column_values"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/pivot.sql": {"path": {"searched_path": "macros", "relative_path": "sql/pivot.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "d9ee0399b76d4b7c575a7dad9ba1ad0c2a2c20f9531edec2e2e4233b7d35a9f2"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.pivot"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils/macros/sql/get_query_results_as_dict.sql": {"path": {"searched_path": "macros", "relative_path": "sql/get_query_results_as_dict.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "9b4b370b1667d3a3a0fd3cf2bdebcd04d2223bbc020f929132a99022589da2d5"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_query_results_as_dict"], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/salesforce_sales_snapshot.sql": {"path": {"searched_path": "models", "relative_path": "salesforce_sales_snapshot.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "ee639b4da327e97c9e55c29017b8a6c3cd160fbdf9d4e7ddcbc741dd8922f40c"}, "nodes": ["model.salesforce.salesforce_sales_snapshot"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/salesforce_owner_performance.sql": {"path": {"searched_path": "models", "relative_path": "salesforce_owner_performance.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "9804691fd00e590abda514cbd0a825319327273db0a5669d31bcfd86cc6bbea5"}, "nodes": ["model.salesforce.salesforce_owner_performance"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/salesforce_manager_performance.sql": {"path": {"searched_path": "models", "relative_path": "salesforce_manager_performance.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "51b9f7856cebad8f9a46dbc2dcaa82dbdc94e857d8459fdedcc1e11fe7fe4ef0"}, "nodes": ["model.salesforce.salesforce_manager_performance"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/salesforce_opportunity_enhanced.sql": {"path": {"searched_path": "models", "relative_path": "salesforce_opportunity_enhanced.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "2e1c40d7643f57a5be23fdab91f6e8c6621be366f4cbcb1fe3d57121dc60a43c"}, "nodes": ["model.salesforce.salesforce_opportunity_enhanced"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/intermediate/opportunity_aggregation_by_owner.sql": {"path": {"searched_path": "models", "relative_path": "intermediate/opportunity_aggregation_by_owner.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "f5f5a7ef463c5b0cb199203c1f2cc644c1e79fa9aa996102b135b9abb077b5da"}, "nodes": ["model.salesforce.opportunity_aggregation_by_owner"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/base/stg_salesforce_opportunity.sql": {"path": {"searched_path": "models", "relative_path": "base/stg_salesforce_opportunity.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "837e5e3af26814bf0b7c8d67f67e5e77c5f111ca3d5523d9eae41b40aa813617"}, "nodes": ["model.salesforce.stg_salesforce_opportunity"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/base/stg_salesforce_user.sql": {"path": {"searched_path": "models", "relative_path": "base/stg_salesforce_user.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "c34620379fdd62ace055d4a17d93a14d2717829872b64b8858c345abc558858a"}, "nodes": ["model.salesforce.stg_salesforce_user"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/base/stg_salesforce_user_role.sql": {"path": {"searched_path": "models", "relative_path": "base/stg_salesforce_user_role.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "74f7c76e18476f3f3f737490efb116325d848c449da998ddea39f1dd19a6d644"}, "nodes": ["model.salesforce.stg_salesforce_user_role"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/base/stg_salesforce_account.sql": {"path": {"searched_path": "models", "relative_path": "base/stg_salesforce_account.sql", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "5d1ebd749b198755397bf1210a4b5a6d7262c36d368313fbb835401b55687fb6"}, "nodes": ["model.salesforce.stg_salesforce_account"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/salesforce.yml": {"path": {"searched_path": "models", "relative_path": "salesforce.yml", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "57ec41e33c6364337d1675a00bfc83e68e4fd19518e5652173abc282077ee363"}, "nodes": [], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/kristin/Documents/Github/dbt_salesforce/models/base/schema.yml": {"path": {"searched_path": "models", "relative_path": "base/schema.yml", "project_root": "/Users/kristin/Documents/Github/dbt_salesforce"}, "checksum": {"name": "sha256", "checksum": "8b7f9030321446d2c6ba3a7091617b5f7ef86579fa5471d7e37b4bdb438cbbc7"}, "nodes": ["test.salesforce.not_null_stg_salesforce_account_account_id", "test.salesforce.unique_stg_salesforce_account_account_id", "test.salesforce.not_null_stg_salesforce_opportunity_opportunity_id", "test.salesforce.unique_stg_salesforce_opportunity_opportunity_id", "test.salesforce.not_null_stg_salesforce_user_user_id", "test.salesforce.unique_stg_salesforce_user_user_id", "test.salesforce.not_null_stg_salesforce_user_role_user_role_id", "test.salesforce.unique_stg_salesforce_user_role_user_role_id"], "docs": [], "macros": [], "sources": [], "patches": ["stg_salesforce_account", "stg_salesforce_opportunity", "stg_salesforce_user", "stg_salesforce_user_role"], "macro_patches": []}, "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/docs/overview.md": {"path": {"searched_path": "docs", "relative_path": "overview.md", "project_root": "/usr/local/Cellar/dbt/0.16.0_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "66db3d93aa0f4fa15a61ea3441e71b887d93e11c626bb000d73b6da808231747"}, "nodes": [], "docs": ["dbt.__overview__"], "macros": [], "sources": [], "patches": [], "macro_patches": []}}}